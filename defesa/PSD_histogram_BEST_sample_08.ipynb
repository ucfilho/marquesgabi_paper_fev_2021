{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PSD_histogram_BEST_sample_08.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ucfilho/marquesgabi_paper_fev_2021/blob/main/defesa/PSD_histogram_BEST_sample_08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sog7Z9pyhUD_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import zipfile\n",
        "#import random\n",
        "from random import randint\n",
        "from PIL import Image\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "#import scikit-image\n",
        "import skimage\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
        "from sklearn.metrics import r2_score\n",
        "from google.colab import files"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsqQZIu-mEfi"
      },
      "source": [
        "Repetir = 40"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwc7AZrXRyqk"
      },
      "source": [
        "# New version change routine inside MarquesGabi_Routines\n",
        "# Try to improve segmentation \n",
        "# New routine is called Segment_Filter_revisited_One... Two,Three, etc\n",
        "# this exemple threshold 0.4\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZEvJvfoibE4"
      },
      "source": [
        "#!pip install mahotas"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UZ30b1EVQhq"
      },
      "source": [
        "def BlackWhite(Transfere,Size):\n",
        "\n",
        "  img_name=[]\n",
        "  xw=[]\n",
        "  ww=[]\n",
        "\n",
        "  with zipfile.ZipFile(Transfere, \"r\") as f:\n",
        "    for name in f.namelist():\n",
        "      img_name.append(name)\n",
        "      #xw.append(cv2.imread(name))\n",
        "      xw.append(cv2.resize(cv2.imread(name),(Size,Size)))\n",
        "\n",
        "  nrow=len(img_name)\n",
        "  ncol=Size*Size\n",
        "  pw=np.zeros((nrow,ncol))\n",
        "  #pw=[]\n",
        "  for i in range(nrow):\n",
        "    ww.append(cv2.cvtColor(np.array(xw[i]), cv2.COLOR_BGR2GRAY))\n",
        "    pw[i,:]=ww[i].ravel()\n",
        "  return ww,img_name"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v7SRrc8mH2N",
        "outputId": "c8caaff0-86a3-438d-e79d-c4004b017387"
      },
      "source": [
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "%cd Doutorado\n",
        "\n",
        "Transfere='Fotos_Grandes_3cdAmostra.zip' \n",
        "file_name = zipfile.ZipFile(Transfere, 'r')\n",
        "file_name.extractall()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Doutorado'...\n",
            "remote: Enumerating objects: 464, done.\u001b[K\n",
            "remote: Counting objects: 100% (214/214), done.\u001b[K\n",
            "remote: Compressing objects: 100% (213/213), done.\u001b[K\n",
            "remote: Total 464 (delta 102), reused 0 (delta 0), pack-reused 250\u001b[K\n",
            "Receiving objects: 100% (464/464), 166.11 MiB | 29.54 MiB/s, done.\n",
            "Resolving deltas: 100% (225/225), done.\n",
            "/content/Doutorado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqIYzUcnrdMp",
        "outputId": "d92f8170-cc1a-471b-89e8-4c8de7055350"
      },
      "source": [
        "labels =[]\n",
        "with zipfile.ZipFile(Transfere, \"r\") as f:\n",
        "  for f in f.namelist():\n",
        "    labels.append(f)\n",
        "print(labels)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Fotos_Grandes-3cdAmostra/Q6-8-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-8-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-8-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-4.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kA4IWSmasoD"
      },
      "source": [
        "Size=1200 # tamanho da foto\n",
        "ww,img_name=BlackWhite(Transfere,Size) #Pegamos a primeira foto Grande\n",
        "# this is the big image we want to segment \n",
        "# ww[0], change it if you want to segment another picture"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHgqAnaFyCjp",
        "outputId": "919736dd-6366-4965-90a2-d83ff56a9339"
      },
      "source": [
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MarquesGabi_Routines'...\n",
            "remote: Enumerating objects: 201, done.\u001b[K\n",
            "remote: Counting objects: 100% (201/201), done.\u001b[K\n",
            "remote: Compressing objects: 100% (198/198), done.\u001b[K\n",
            "remote: Total 201 (delta 86), reused 3 (delta 1), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (201/201), 211.75 MiB | 24.09 MiB/s, done.\n",
            "Resolving deltas: 100% (86/86), done.\n",
            "Checking out files: 100% (52/52), done.\n",
            "/content/Doutorado/MarquesGabi_Routines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc4rFvzkyWCi"
      },
      "source": [
        "from Segment_Filter_Revival import Segmenta  # got image provided segmented"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR2emP4rNjQy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88fe456c-362d-4edc-fc08-0aade8ad4afb"
      },
      "source": [
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MarquesGabi_Routines'...\n",
            "remote: Enumerating objects: 201, done.\u001b[K\n",
            "remote: Counting objects: 100% (201/201), done.\u001b[K\n",
            "remote: Compressing objects: 100% (198/198), done.\u001b[K\n",
            "remote: Total 201 (delta 86), reused 3 (delta 1), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (201/201), 211.75 MiB | 23.04 MiB/s, done.\n",
            "Resolving deltas: 100% (86/86), done.\n",
            "Checking out files: 100% (52/52), done.\n",
            "/content/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6cMHOrlNliO"
      },
      "source": [
        "# leitura dos dados\n",
        "df=pd.read_excel(\"FotosTreinoRede.xlsx\")\n",
        "y = df['y']\n",
        "df.drop(['Unnamed: 0','y'], axis='columns', inplace=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQO8d2QbNqj0"
      },
      "source": [
        "X =np.array(df.copy())/255.0 \n",
        "\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIFPGE_-vx3T"
      },
      "source": [
        "Img_Size = 28"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23iKv6bDPWQl"
      },
      "source": [
        "# helper\n",
        "def ynindicator(Y):\n",
        "  N = len(Y)\n",
        "  K = len(set(Y))\n",
        "  I = np.zeros((N, K))\n",
        "  I[np.arange(N), Y] = 1\n",
        "  return I\n",
        "\n",
        "def yback(Y_test):\n",
        "  nrow, ncol = Y_test.shape\n",
        "  y_class = np.zeros(nrow,dtype=int)\n",
        "  y_resp = Y_test\n",
        "  for k in range(nrow):\n",
        "    for kk in range(K):\n",
        "      if(y_resp[k,kk] == 1):\n",
        "        y_class[k] = kk\n",
        "  Y_test = y_class.copy()\n",
        "  return Y_test\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train)\n",
        "K = len(set(Y_train))\n",
        "\n",
        "X_train = X_train.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "Y_train = Y_train.astype(np.int32)\n",
        "Y_train = ynindicator(Y_train)\n",
        "\n",
        "X_test = np.array(X_test )\n",
        "Y_test = np.array(Y_test)\n",
        "X_test = X_test.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "Y_test = Y_test.astype(np.int32)\n",
        "Y_test = ynindicator(Y_test)\n",
        "\n",
        "# the model will be a sequence of layers\n",
        "\n",
        "Description = '3 layers of Convolution: 64, 128, 256 '\n",
        "N1 = 20\n",
        "N2 = 20\n",
        "\n",
        "# make the CNN\n",
        "model = Sequential()\n",
        "model.add(Conv2D(input_shape=(Img_Size, Img_Size, 1), filters=64, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=N1))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=N2))\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(units=K))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "# list of losses: https://keras.io/losses/\n",
        "# list of optimizers: https://keras.io/optimizers/\n",
        "# list of metrics: https://keras.io/metrics/\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpbPQ1FSRG6A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4749eca4-b1a4-47bf-f9f1-090e9d81b3d3"
      },
      "source": [
        "# training the model\n",
        "r = model.fit(X_train, Y_train, validation_data=(X_test,Y_test), \n",
        "              epochs=200, batch_size=32)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "11/11 [==============================] - 3s 151ms/step - loss: 0.7274 - accuracy: 0.7347 - val_loss: 0.6931 - val_accuracy: 0.5102\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 0.3936 - accuracy: 0.8017 - val_loss: 0.6929 - val_accuracy: 0.5102\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 0.3122 - accuracy: 0.8688 - val_loss: 0.6930 - val_accuracy: 0.5102\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.2133 - accuracy: 0.9300 - val_loss: 0.6931 - val_accuracy: 0.4898\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.1614 - accuracy: 0.9329 - val_loss: 0.6934 - val_accuracy: 0.4898\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0894 - accuracy: 0.9679 - val_loss: 0.6935 - val_accuracy: 0.4898\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0814 - accuracy: 0.9679 - val_loss: 0.6932 - val_accuracy: 0.4898\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0711 - accuracy: 0.9796 - val_loss: 0.6927 - val_accuracy: 0.4898\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0489 - accuracy: 0.9854 - val_loss: 0.6925 - val_accuracy: 0.5102\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0637 - accuracy: 0.9796 - val_loss: 0.6923 - val_accuracy: 0.5102\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0675 - accuracy: 0.9767 - val_loss: 0.6920 - val_accuracy: 0.5102\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0389 - accuracy: 0.9854 - val_loss: 0.6920 - val_accuracy: 0.5102\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0348 - accuracy: 0.9883 - val_loss: 0.6936 - val_accuracy: 0.5102\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.0739 - accuracy: 0.9767 - val_loss: 0.6924 - val_accuracy: 0.5102\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0527 - accuracy: 0.9825 - val_loss: 0.6985 - val_accuracy: 0.5102\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0456 - accuracy: 0.9796 - val_loss: 0.6960 - val_accuracy: 0.5102\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0186 - accuracy: 0.9971 - val_loss: 0.6937 - val_accuracy: 0.5102\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0159 - accuracy: 0.9942 - val_loss: 0.7056 - val_accuracy: 0.5102\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.7199 - val_accuracy: 0.5102\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 0.0085 - accuracy: 0.9971 - val_loss: 0.7099 - val_accuracy: 0.5102\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.7086 - val_accuracy: 0.5102\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.7138 - val_accuracy: 0.5102\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.7215 - val_accuracy: 0.5102\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7312 - val_accuracy: 0.5102\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 7.6580e-04 - accuracy: 1.0000 - val_loss: 0.7379 - val_accuracy: 0.5102\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 9.4841e-04 - accuracy: 1.0000 - val_loss: 0.7494 - val_accuracy: 0.5102\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7636 - val_accuracy: 0.5102\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7905 - val_accuracy: 0.5102\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 4.1684e-04 - accuracy: 1.0000 - val_loss: 0.8258 - val_accuracy: 0.5102\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 4.4900e-04 - accuracy: 1.0000 - val_loss: 0.8601 - val_accuracy: 0.5102\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 7.1613e-04 - accuracy: 1.0000 - val_loss: 0.8927 - val_accuracy: 0.5102\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 7.6921e-04 - accuracy: 1.0000 - val_loss: 0.9283 - val_accuracy: 0.5102\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.9394 - val_accuracy: 0.5102\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 8.0661e-04 - accuracy: 1.0000 - val_loss: 0.9764 - val_accuracy: 0.5102\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 7.6376e-04 - accuracy: 1.0000 - val_loss: 0.9938 - val_accuracy: 0.5102\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.0058 - val_accuracy: 0.5102\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 7.5245e-04 - accuracy: 1.0000 - val_loss: 1.0134 - val_accuracy: 0.5102\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 5.0404e-04 - accuracy: 1.0000 - val_loss: 1.0080 - val_accuracy: 0.5102\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.9770 - val_accuracy: 0.5102\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.1631 - val_accuracy: 0.5102\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.2927 - val_accuracy: 0.5102\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.0753 - val_accuracy: 0.5102\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 9.3869e-04 - accuracy: 1.0000 - val_loss: 2.8990 - val_accuracy: 0.5102\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0323 - accuracy: 0.9883 - val_loss: 3.5990 - val_accuracy: 0.5102\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0116 - accuracy: 0.9942 - val_loss: 11.1777 - val_accuracy: 0.5102\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 0.0097 - accuracy: 0.9971 - val_loss: 12.6556 - val_accuracy: 0.5102\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 0.0433 - accuracy: 0.9854 - val_loss: 14.8228 - val_accuracy: 0.5102\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0760 - accuracy: 0.9796 - val_loss: 20.2991 - val_accuracy: 0.5102\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 0.0141 - accuracy: 0.9971 - val_loss: 23.0245 - val_accuracy: 0.5102\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 27.0515 - val_accuracy: 0.5102\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 0.0074 - accuracy: 0.9971 - val_loss: 25.5973 - val_accuracy: 0.5102\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 0.0223 - accuracy: 0.9942 - val_loss: 23.9818 - val_accuracy: 0.5102\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0152 - accuracy: 0.9971 - val_loss: 23.8885 - val_accuracy: 0.5102\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 19.7611 - val_accuracy: 0.5102\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 25.2407 - val_accuracy: 0.5102\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 25.8253 - val_accuracy: 0.5102\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0073 - accuracy: 0.9971 - val_loss: 18.7488 - val_accuracy: 0.5102\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.0156 - accuracy: 0.9942 - val_loss: 17.4025 - val_accuracy: 0.5102\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 16.1628 - val_accuracy: 0.5102\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0141 - accuracy: 0.9942 - val_loss: 17.1874 - val_accuracy: 0.5102\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0061 - accuracy: 0.9971 - val_loss: 12.5030 - val_accuracy: 0.5102\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0208 - accuracy: 0.9913 - val_loss: 14.8382 - val_accuracy: 0.5102\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 15.4749 - val_accuracy: 0.5102\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 14.8977 - val_accuracy: 0.5102\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 13.9674 - val_accuracy: 0.5102\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 15.2856 - val_accuracy: 0.5102\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 14.3154 - val_accuracy: 0.5102\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 2.8290e-04 - accuracy: 1.0000 - val_loss: 13.2220 - val_accuracy: 0.5102\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 5.4420e-04 - accuracy: 1.0000 - val_loss: 11.9878 - val_accuracy: 0.5102\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 4.6602e-04 - accuracy: 1.0000 - val_loss: 10.8261 - val_accuracy: 0.5102\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 2.6450e-04 - accuracy: 1.0000 - val_loss: 9.6312 - val_accuracy: 0.5102\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0031 - accuracy: 0.9971 - val_loss: 8.5006 - val_accuracy: 0.5102\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0040 - accuracy: 0.9971 - val_loss: 4.9598 - val_accuracy: 0.5102\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 3.3850 - val_accuracy: 0.5102\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0072 - accuracy: 0.9971 - val_loss: 3.5959 - val_accuracy: 0.5102\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 5.3661 - val_accuracy: 0.5102\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 6.1650 - val_accuracy: 0.5102\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 5.7935 - val_accuracy: 0.5102\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 6.8056 - val_accuracy: 0.5102\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 8.2437e-04 - accuracy: 1.0000 - val_loss: 6.9875 - val_accuracy: 0.5102\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 20.1809 - val_accuracy: 0.5102\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 33.2877 - val_accuracy: 0.5102\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0044 - accuracy: 0.9971 - val_loss: 33.2451 - val_accuracy: 0.5102\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0037 - accuracy: 0.9971 - val_loss: 31.9213 - val_accuracy: 0.5102\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 31.1377 - val_accuracy: 0.5102\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 35.1177 - val_accuracy: 0.5102\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0233 - accuracy: 0.9942 - val_loss: 51.3505 - val_accuracy: 0.5102\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.0453 - accuracy: 0.9854 - val_loss: 41.6678 - val_accuracy: 0.5102\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0160 - accuracy: 0.9942 - val_loss: 94.4646 - val_accuracy: 0.5102\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 152.0586 - val_accuracy: 0.5102\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.0165 - accuracy: 0.9913 - val_loss: 138.3271 - val_accuracy: 0.5102\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0709 - accuracy: 0.9796 - val_loss: 78.6939 - val_accuracy: 0.5102\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.0146 - accuracy: 0.9942 - val_loss: 1.1097 - val_accuracy: 0.6122\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.0348 - accuracy: 0.9854 - val_loss: 30.8632 - val_accuracy: 0.5102\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 0.0129 - accuracy: 0.9971 - val_loss: 3.4156 - val_accuracy: 0.5102\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.0105 - accuracy: 0.9942 - val_loss: 21.1493 - val_accuracy: 0.5102\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0346 - accuracy: 0.9854 - val_loss: 27.7491 - val_accuracy: 0.5102\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0144 - accuracy: 0.9942 - val_loss: 28.4551 - val_accuracy: 0.5102\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 4.9232 - val_accuracy: 0.5102\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 13.4099 - val_accuracy: 0.5102\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 18.6628 - val_accuracy: 0.5102\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 18.1081 - val_accuracy: 0.5102\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 4.7953e-04 - accuracy: 1.0000 - val_loss: 17.5502 - val_accuracy: 0.5102\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 2.3924e-04 - accuracy: 1.0000 - val_loss: 16.0610 - val_accuracy: 0.5102\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 1.9122e-04 - accuracy: 1.0000 - val_loss: 14.5380 - val_accuracy: 0.5102\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 2.9312e-04 - accuracy: 1.0000 - val_loss: 12.8422 - val_accuracy: 0.5102\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 12.5529 - val_accuracy: 0.5102\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 6.2074e-04 - accuracy: 1.0000 - val_loss: 11.9316 - val_accuracy: 0.5102\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 5.7117e-04 - accuracy: 1.0000 - val_loss: 10.6397 - val_accuracy: 0.5102\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 6.2838e-04 - accuracy: 1.0000 - val_loss: 9.4215 - val_accuracy: 0.5102\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 3.1919e-04 - accuracy: 1.0000 - val_loss: 8.4410 - val_accuracy: 0.5102\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 5.7712e-04 - accuracy: 1.0000 - val_loss: 8.4541 - val_accuracy: 0.5102\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 5.3775 - val_accuracy: 0.5102\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 2.4168e-04 - accuracy: 1.0000 - val_loss: 4.0644 - val_accuracy: 0.5102\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 2.9690e-04 - accuracy: 1.0000 - val_loss: 3.8266 - val_accuracy: 0.5102\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 2.1713e-04 - accuracy: 1.0000 - val_loss: 3.5499 - val_accuracy: 0.5102\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 3.1184e-04 - accuracy: 1.0000 - val_loss: 3.0828 - val_accuracy: 0.5102\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 4.4363 - val_accuracy: 0.5102\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 5.1417e-04 - accuracy: 1.0000 - val_loss: 13.0686 - val_accuracy: 0.5102\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 2.1074e-04 - accuracy: 1.0000 - val_loss: 15.7111 - val_accuracy: 0.5102\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0311 - accuracy: 0.9913 - val_loss: 11.5945 - val_accuracy: 0.5102\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 49.2943 - val_accuracy: 0.5102\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 47.7933 - val_accuracy: 0.5102\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 41.8006 - val_accuracy: 0.5102\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 7.1078e-04 - accuracy: 1.0000 - val_loss: 35.0565 - val_accuracy: 0.5102\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 2.3046e-04 - accuracy: 1.0000 - val_loss: 30.3021 - val_accuracy: 0.5102\n",
            "Epoch 127/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 3.1679e-04 - accuracy: 1.0000 - val_loss: 26.7697 - val_accuracy: 0.5102\n",
            "Epoch 128/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 3.5974e-04 - accuracy: 1.0000 - val_loss: 24.4699 - val_accuracy: 0.5102\n",
            "Epoch 129/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 2.2671e-04 - accuracy: 1.0000 - val_loss: 22.3232 - val_accuracy: 0.5102\n",
            "Epoch 130/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 2.3077e-04 - accuracy: 1.0000 - val_loss: 20.3504 - val_accuracy: 0.5102\n",
            "Epoch 131/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 1.8239e-04 - accuracy: 1.0000 - val_loss: 18.7145 - val_accuracy: 0.5102\n",
            "Epoch 132/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 1.5450e-04 - accuracy: 1.0000 - val_loss: 17.1028 - val_accuracy: 0.5102\n",
            "Epoch 133/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 4.3128e-04 - accuracy: 1.0000 - val_loss: 15.6060 - val_accuracy: 0.5102\n",
            "Epoch 134/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 1.8095e-04 - accuracy: 1.0000 - val_loss: 13.9230 - val_accuracy: 0.5102\n",
            "Epoch 135/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 1.9903e-04 - accuracy: 1.0000 - val_loss: 12.5341 - val_accuracy: 0.5102\n",
            "Epoch 136/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 1.0469e-04 - accuracy: 1.0000 - val_loss: 11.3220 - val_accuracy: 0.5102\n",
            "Epoch 137/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 5.5383e-05 - accuracy: 1.0000 - val_loss: 10.1658 - val_accuracy: 0.5102\n",
            "Epoch 138/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 1.1906e-04 - accuracy: 1.0000 - val_loss: 8.9479 - val_accuracy: 0.5102\n",
            "Epoch 139/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 1.6694e-04 - accuracy: 1.0000 - val_loss: 7.9652 - val_accuracy: 0.5102\n",
            "Epoch 140/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 1.9800e-04 - accuracy: 1.0000 - val_loss: 7.0554 - val_accuracy: 0.5102\n",
            "Epoch 141/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 1.7750e-04 - accuracy: 1.0000 - val_loss: 5.2044 - val_accuracy: 0.5102\n",
            "Epoch 142/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 8.3678e-05 - accuracy: 1.0000 - val_loss: 4.1949 - val_accuracy: 0.5102\n",
            "Epoch 143/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 1.9197e-04 - accuracy: 1.0000 - val_loss: 3.5279 - val_accuracy: 0.5102\n",
            "Epoch 144/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 1.8849e-04 - accuracy: 1.0000 - val_loss: 3.0170 - val_accuracy: 0.5102\n",
            "Epoch 145/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 4.8656e-05 - accuracy: 1.0000 - val_loss: 2.5507 - val_accuracy: 0.5170\n",
            "Epoch 146/200\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 2.0690e-04 - accuracy: 1.0000 - val_loss: 1.9207 - val_accuracy: 0.5374\n",
            "Epoch 147/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 8.2684e-05 - accuracy: 1.0000 - val_loss: 1.4536 - val_accuracy: 0.5918\n",
            "Epoch 148/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 1.0011e-04 - accuracy: 1.0000 - val_loss: 0.9869 - val_accuracy: 0.6667\n",
            "Epoch 149/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 3.6191e-05 - accuracy: 1.0000 - val_loss: 0.6851 - val_accuracy: 0.7551\n",
            "Epoch 150/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 6.3445e-05 - accuracy: 1.0000 - val_loss: 0.4153 - val_accuracy: 0.8299\n",
            "Epoch 151/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 4.8668e-05 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.8980\n",
            "Epoch 152/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 7.4540e-05 - accuracy: 1.0000 - val_loss: 0.1798 - val_accuracy: 0.9456\n",
            "Epoch 153/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 2.5190e-04 - accuracy: 1.0000 - val_loss: 0.1565 - val_accuracy: 0.9524\n",
            "Epoch 154/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 8.3991e-05 - accuracy: 1.0000 - val_loss: 0.1675 - val_accuracy: 0.9592\n",
            "Epoch 155/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 2.9409e-05 - accuracy: 1.0000 - val_loss: 0.1706 - val_accuracy: 0.9660\n",
            "Epoch 156/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 5.6202e-05 - accuracy: 1.0000 - val_loss: 0.1811 - val_accuracy: 0.9728\n",
            "Epoch 157/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 1.3599e-04 - accuracy: 1.0000 - val_loss: 0.2138 - val_accuracy: 0.9796\n",
            "Epoch 158/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 2.0761e-04 - accuracy: 1.0000 - val_loss: 0.2912 - val_accuracy: 0.9388\n",
            "Epoch 159/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 7.9415e-05 - accuracy: 1.0000 - val_loss: 0.3188 - val_accuracy: 0.9320\n",
            "Epoch 160/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 3.0066e-04 - accuracy: 1.0000 - val_loss: 0.3297 - val_accuracy: 0.9252\n",
            "Epoch 161/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 7.9861e-05 - accuracy: 1.0000 - val_loss: 0.3267 - val_accuracy: 0.9252\n",
            "Epoch 162/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 3.1297e-05 - accuracy: 1.0000 - val_loss: 0.3320 - val_accuracy: 0.9252\n",
            "Epoch 163/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 2.6150e-05 - accuracy: 1.0000 - val_loss: 0.3382 - val_accuracy: 0.9252\n",
            "Epoch 164/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 3.8676e-05 - accuracy: 1.0000 - val_loss: 0.3273 - val_accuracy: 0.9320\n",
            "Epoch 165/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 1.5941e-04 - accuracy: 1.0000 - val_loss: 0.3072 - val_accuracy: 0.9524\n",
            "Epoch 166/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 5.4508e-05 - accuracy: 1.0000 - val_loss: 0.2792 - val_accuracy: 0.9660\n",
            "Epoch 167/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 4.7995e-05 - accuracy: 1.0000 - val_loss: 0.3024 - val_accuracy: 0.9592\n",
            "Epoch 168/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 4.9859e-05 - accuracy: 1.0000 - val_loss: 0.2992 - val_accuracy: 0.9592\n",
            "Epoch 169/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 5.5977e-05 - accuracy: 1.0000 - val_loss: 0.3007 - val_accuracy: 0.9592\n",
            "Epoch 170/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 7.9504e-05 - accuracy: 1.0000 - val_loss: 0.3255 - val_accuracy: 0.9456\n",
            "Epoch 171/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 6.3609e-05 - accuracy: 1.0000 - val_loss: 0.2954 - val_accuracy: 0.9660\n",
            "Epoch 172/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 3.0164e-05 - accuracy: 1.0000 - val_loss: 0.3030 - val_accuracy: 0.9592\n",
            "Epoch 173/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 3.1635e-04 - accuracy: 1.0000 - val_loss: 0.2728 - val_accuracy: 0.9592\n",
            "Epoch 174/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 7.6995e-05 - accuracy: 1.0000 - val_loss: 0.2540 - val_accuracy: 0.9728\n",
            "Epoch 175/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 2.5711e-05 - accuracy: 1.0000 - val_loss: 0.2548 - val_accuracy: 0.9728\n",
            "Epoch 176/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 1.3883e-04 - accuracy: 1.0000 - val_loss: 0.4888 - val_accuracy: 0.9048\n",
            "Epoch 177/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 4.6266e-05 - accuracy: 1.0000 - val_loss: 0.8965 - val_accuracy: 0.8163\n",
            "Epoch 178/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 3.3394e-05 - accuracy: 1.0000 - val_loss: 0.8130 - val_accuracy: 0.8231\n",
            "Epoch 179/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 4.7765e-05 - accuracy: 1.0000 - val_loss: 0.6702 - val_accuracy: 0.8367\n",
            "Epoch 180/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 2.1412e-05 - accuracy: 1.0000 - val_loss: 0.5720 - val_accuracy: 0.8639\n",
            "Epoch 181/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 6.3316e-04 - accuracy: 1.0000 - val_loss: 0.4099 - val_accuracy: 0.8980\n",
            "Epoch 182/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 5.3603e-05 - accuracy: 1.0000 - val_loss: 0.2255 - val_accuracy: 0.9660\n",
            "Epoch 183/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 1.4458e-04 - accuracy: 1.0000 - val_loss: 0.3962 - val_accuracy: 0.8980\n",
            "Epoch 184/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 3.3630e-05 - accuracy: 1.0000 - val_loss: 0.4714 - val_accuracy: 0.8844\n",
            "Epoch 185/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 1.8136e-04 - accuracy: 1.0000 - val_loss: 0.3076 - val_accuracy: 0.9184\n",
            "Epoch 186/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0031 - accuracy: 0.9971 - val_loss: 0.9811 - val_accuracy: 0.6395\n",
            "Epoch 187/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 1.4250e-04 - accuracy: 1.0000 - val_loss: 17.1326 - val_accuracy: 0.5102\n",
            "Epoch 188/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0050 - accuracy: 0.9971 - val_loss: 17.4283 - val_accuracy: 0.5102\n",
            "Epoch 189/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 2.6007e-04 - accuracy: 1.0000 - val_loss: 13.1021 - val_accuracy: 0.5102\n",
            "Epoch 190/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 4.5800e-04 - accuracy: 1.0000 - val_loss: 11.3458 - val_accuracy: 0.5102\n",
            "Epoch 191/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 5.7280e-04 - accuracy: 1.0000 - val_loss: 11.0661 - val_accuracy: 0.5102\n",
            "Epoch 192/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.0106 - accuracy: 0.9971 - val_loss: 9.5347 - val_accuracy: 0.5102\n",
            "Epoch 193/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 1.2125e-04 - accuracy: 1.0000 - val_loss: 17.0562 - val_accuracy: 0.5102\n",
            "Epoch 194/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0160 - accuracy: 0.9942 - val_loss: 2.5919 - val_accuracy: 0.4898\n",
            "Epoch 195/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 0.0104 - accuracy: 0.9971 - val_loss: 1.6444 - val_accuracy: 0.4898\n",
            "Epoch 196/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 37.3537 - val_accuracy: 0.5102\n",
            "Epoch 197/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.0160 - accuracy: 0.9913 - val_loss: 119.4690 - val_accuracy: 0.5102\n",
            "Epoch 198/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 0.0243 - accuracy: 0.9883 - val_loss: 56.9332 - val_accuracy: 0.5102\n",
            "Epoch 199/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.0081 - accuracy: 0.9971 - val_loss: 68.8522 - val_accuracy: 0.5102\n",
            "Epoch 200/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 83.2840 - val_accuracy: 0.5102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSTlOSUBWMpj"
      },
      "source": [
        "Y_test = yback(Y_test)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDVY6HbxMOlH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bab0fee1-1a4e-4553-bd19-ead94181ccd8"
      },
      "source": [
        "# pred_test= model.predict_classes(X_test)\n",
        "pred_test = np.argmax(model.predict(X_test), axis=-1)\n",
        "\n",
        "data = {'y_true': Y_test,'y_predict': pred_test}  # este dado esta no formato de dicionario\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_true','y_predict'])\n",
        "\n",
        "\n",
        "confusion_matrix = pd.crosstab(df['y_true'], df['y_predict'], rownames=['Actual'], colnames=['Predict'])\n",
        "print(confusion_matrix)\n",
        "\n",
        "y_true = df['y_true']\n",
        "y_pred = df['y_predict']\n",
        "\n",
        "  \n",
        "METRICS=sklearn.metrics.classification_report(y_true, y_pred)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predict   1\n",
            "Actual     \n",
            "0        72\n",
            "1        75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7pT2q7traXg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "233afebb-d574-4ffd-dd6f-6816e770a8a1"
      },
      "source": [
        "print(METRICS)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        72\n",
            "           1       0.51      1.00      0.68        75\n",
            "\n",
            "    accuracy                           0.51       147\n",
            "   macro avg       0.26      0.50      0.34       147\n",
            "weighted avg       0.26      0.51      0.34       147\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iFNNrlWV9tH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d146e51c-3048-4272-e8ab-17a1e2dfccdf"
      },
      "source": [
        "pred_test"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8ofkAXlS-0F"
      },
      "source": [
        "Sample3 =[0, 3, 9] # \n",
        "# [2, 5, 17] sample 7---  [4,13,25] sample 3----[0, 3, 9] sample 8\n",
        "\n",
        "for i in range(Repetir):\n",
        "  k = 0\n",
        "  for i in Sample3:\n",
        "    img=ww[i]\n",
        "    if( k > 0):\n",
        "      df_old = df_ann.copy()\n",
        "    df_ann=Segmenta(img)\n",
        "    if(k > 0):\n",
        "      df_ann = pd.concat( [df_ann, df_old], ignore_index = True)\n",
        "    k = k + 1\n",
        "#df_ann = df.copy\n",
        "\n",
        "df_teste = np.array(df_ann)\n",
        "names = df_ann.columns\n",
        "df_teste = pd.DataFrame(df_teste,columns=names)\n",
        "Width = df_ann['Width']\n",
        "#del df_ann['Width']\n",
        "names = df_ann.columns\n",
        "del df_ann['Width']\n",
        "result = np.array(df_ann)\n",
        "result = result.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "prediction= np.argmax(model.predict(result), axis=-1)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kfx72YkUYiz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "d6caf6e1-311b-409d-d196-a46eeb282658"
      },
      "source": [
        "df_ann"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "      <th>769</th>\n",
              "      <th>770</th>\n",
              "      <th>771</th>\n",
              "      <th>772</th>\n",
              "      <th>773</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>99.082436</td>\n",
              "      <td>100.500847</td>\n",
              "      <td>103.527435</td>\n",
              "      <td>106.663185</td>\n",
              "      <td>111.310974</td>\n",
              "      <td>117.033173</td>\n",
              "      <td>119.828094</td>\n",
              "      <td>114.582550</td>\n",
              "      <td>68.404053</td>\n",
              "      <td>60.649975</td>\n",
              "      <td>59.055763</td>\n",
              "      <td>60.614456</td>\n",
              "      <td>56.032204</td>\n",
              "      <td>47.257103</td>\n",
              "      <td>47.631493</td>\n",
              "      <td>50.638077</td>\n",
              "      <td>51.917465</td>\n",
              "      <td>51.787895</td>\n",
              "      <td>51.810616</td>\n",
              "      <td>52.059269</td>\n",
              "      <td>52.060070</td>\n",
              "      <td>52.757591</td>\n",
              "      <td>53.150517</td>\n",
              "      <td>53.902035</td>\n",
              "      <td>56.495098</td>\n",
              "      <td>56.419323</td>\n",
              "      <td>54.643150</td>\n",
              "      <td>50.673424</td>\n",
              "      <td>99.359131</td>\n",
              "      <td>99.250084</td>\n",
              "      <td>101.213036</td>\n",
              "      <td>104.688515</td>\n",
              "      <td>109.137482</td>\n",
              "      <td>117.710312</td>\n",
              "      <td>122.831337</td>\n",
              "      <td>109.231873</td>\n",
              "      <td>64.814491</td>\n",
              "      <td>63.233025</td>\n",
              "      <td>61.645828</td>\n",
              "      <td>63.234455</td>\n",
              "      <td>...</td>\n",
              "      <td>107.815186</td>\n",
              "      <td>108.771988</td>\n",
              "      <td>110.397903</td>\n",
              "      <td>112.749870</td>\n",
              "      <td>112.828957</td>\n",
              "      <td>120.650467</td>\n",
              "      <td>148.355789</td>\n",
              "      <td>69.616158</td>\n",
              "      <td>61.206318</td>\n",
              "      <td>65.829124</td>\n",
              "      <td>66.029228</td>\n",
              "      <td>65.357307</td>\n",
              "      <td>84.239403</td>\n",
              "      <td>89.281731</td>\n",
              "      <td>92.936615</td>\n",
              "      <td>97.178581</td>\n",
              "      <td>102.640282</td>\n",
              "      <td>105.690147</td>\n",
              "      <td>107.432449</td>\n",
              "      <td>113.008659</td>\n",
              "      <td>122.065025</td>\n",
              "      <td>119.903831</td>\n",
              "      <td>106.700317</td>\n",
              "      <td>95.411278</td>\n",
              "      <td>95.358818</td>\n",
              "      <td>103.384132</td>\n",
              "      <td>102.865845</td>\n",
              "      <td>101.790558</td>\n",
              "      <td>108.787498</td>\n",
              "      <td>110.436066</td>\n",
              "      <td>110.247940</td>\n",
              "      <td>112.010246</td>\n",
              "      <td>114.632629</td>\n",
              "      <td>116.383636</td>\n",
              "      <td>140.436630</td>\n",
              "      <td>86.821274</td>\n",
              "      <td>60.481468</td>\n",
              "      <td>66.202072</td>\n",
              "      <td>65.385246</td>\n",
              "      <td>66.737305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>36.432102</td>\n",
              "      <td>38.111111</td>\n",
              "      <td>36.345676</td>\n",
              "      <td>36.246910</td>\n",
              "      <td>37.641975</td>\n",
              "      <td>35.666664</td>\n",
              "      <td>34.987656</td>\n",
              "      <td>36.049385</td>\n",
              "      <td>36.765430</td>\n",
              "      <td>37.061729</td>\n",
              "      <td>35.950619</td>\n",
              "      <td>36.987656</td>\n",
              "      <td>38.543213</td>\n",
              "      <td>40.469143</td>\n",
              "      <td>41.518517</td>\n",
              "      <td>42.753086</td>\n",
              "      <td>42.543213</td>\n",
              "      <td>51.827164</td>\n",
              "      <td>99.407417</td>\n",
              "      <td>112.641968</td>\n",
              "      <td>109.444443</td>\n",
              "      <td>104.530869</td>\n",
              "      <td>104.012344</td>\n",
              "      <td>104.456787</td>\n",
              "      <td>106.024696</td>\n",
              "      <td>110.765434</td>\n",
              "      <td>118.086411</td>\n",
              "      <td>123.567902</td>\n",
              "      <td>42.160496</td>\n",
              "      <td>40.728401</td>\n",
              "      <td>37.728394</td>\n",
              "      <td>36.790123</td>\n",
              "      <td>36.802471</td>\n",
              "      <td>35.123459</td>\n",
              "      <td>34.345680</td>\n",
              "      <td>34.765430</td>\n",
              "      <td>35.802467</td>\n",
              "      <td>36.740738</td>\n",
              "      <td>36.814819</td>\n",
              "      <td>37.802475</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.197531</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.098765</td>\n",
              "      <td>0.074074</td>\n",
              "      <td>0.148148</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.086420</td>\n",
              "      <td>2.209877</td>\n",
              "      <td>3.320988</td>\n",
              "      <td>0.358025</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.098765</td>\n",
              "      <td>0.345679</td>\n",
              "      <td>0.123457</td>\n",
              "      <td>0.839506</td>\n",
              "      <td>0.098765</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>91.396652</td>\n",
              "      <td>92.909775</td>\n",
              "      <td>93.514503</td>\n",
              "      <td>93.410477</td>\n",
              "      <td>93.036758</td>\n",
              "      <td>94.323814</td>\n",
              "      <td>93.569366</td>\n",
              "      <td>92.953079</td>\n",
              "      <td>98.692909</td>\n",
              "      <td>108.433273</td>\n",
              "      <td>115.749428</td>\n",
              "      <td>129.652130</td>\n",
              "      <td>150.474136</td>\n",
              "      <td>162.989838</td>\n",
              "      <td>177.554291</td>\n",
              "      <td>63.723511</td>\n",
              "      <td>26.682137</td>\n",
              "      <td>38.446560</td>\n",
              "      <td>39.231277</td>\n",
              "      <td>38.348473</td>\n",
              "      <td>37.245888</td>\n",
              "      <td>36.866745</td>\n",
              "      <td>38.684181</td>\n",
              "      <td>38.771431</td>\n",
              "      <td>42.885719</td>\n",
              "      <td>48.261753</td>\n",
              "      <td>61.897682</td>\n",
              "      <td>67.156067</td>\n",
              "      <td>93.771568</td>\n",
              "      <td>95.176544</td>\n",
              "      <td>95.550079</td>\n",
              "      <td>93.589470</td>\n",
              "      <td>91.263474</td>\n",
              "      <td>92.194664</td>\n",
              "      <td>94.838982</td>\n",
              "      <td>95.244827</td>\n",
              "      <td>97.046005</td>\n",
              "      <td>107.218399</td>\n",
              "      <td>116.606186</td>\n",
              "      <td>131.989761</td>\n",
              "      <td>...</td>\n",
              "      <td>135.666473</td>\n",
              "      <td>140.420654</td>\n",
              "      <td>144.519455</td>\n",
              "      <td>148.642151</td>\n",
              "      <td>151.641037</td>\n",
              "      <td>154.187515</td>\n",
              "      <td>158.245163</td>\n",
              "      <td>154.799469</td>\n",
              "      <td>150.937210</td>\n",
              "      <td>148.613861</td>\n",
              "      <td>141.266785</td>\n",
              "      <td>100.929543</td>\n",
              "      <td>23.564480</td>\n",
              "      <td>29.890739</td>\n",
              "      <td>42.342590</td>\n",
              "      <td>72.177338</td>\n",
              "      <td>94.809311</td>\n",
              "      <td>103.633682</td>\n",
              "      <td>105.594429</td>\n",
              "      <td>107.819565</td>\n",
              "      <td>106.955978</td>\n",
              "      <td>108.849045</td>\n",
              "      <td>111.200882</td>\n",
              "      <td>114.212708</td>\n",
              "      <td>117.945000</td>\n",
              "      <td>121.121826</td>\n",
              "      <td>127.844803</td>\n",
              "      <td>131.857101</td>\n",
              "      <td>132.926575</td>\n",
              "      <td>140.566864</td>\n",
              "      <td>144.376297</td>\n",
              "      <td>149.467987</td>\n",
              "      <td>151.615387</td>\n",
              "      <td>152.456284</td>\n",
              "      <td>153.047333</td>\n",
              "      <td>154.015930</td>\n",
              "      <td>156.087723</td>\n",
              "      <td>156.850616</td>\n",
              "      <td>156.172852</td>\n",
              "      <td>153.181381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100.830452</td>\n",
              "      <td>102.103806</td>\n",
              "      <td>108.089958</td>\n",
              "      <td>107.356407</td>\n",
              "      <td>106.380623</td>\n",
              "      <td>104.761246</td>\n",
              "      <td>97.076126</td>\n",
              "      <td>87.712807</td>\n",
              "      <td>87.456749</td>\n",
              "      <td>86.709343</td>\n",
              "      <td>85.903114</td>\n",
              "      <td>79.972321</td>\n",
              "      <td>68.505196</td>\n",
              "      <td>64.768166</td>\n",
              "      <td>61.792389</td>\n",
              "      <td>62.498272</td>\n",
              "      <td>65.173012</td>\n",
              "      <td>68.294121</td>\n",
              "      <td>69.965401</td>\n",
              "      <td>71.515572</td>\n",
              "      <td>72.162636</td>\n",
              "      <td>70.529411</td>\n",
              "      <td>69.418678</td>\n",
              "      <td>71.474052</td>\n",
              "      <td>73.858131</td>\n",
              "      <td>76.051910</td>\n",
              "      <td>78.702423</td>\n",
              "      <td>74.128029</td>\n",
              "      <td>106.837364</td>\n",
              "      <td>104.470589</td>\n",
              "      <td>112.366776</td>\n",
              "      <td>125.460197</td>\n",
              "      <td>107.847755</td>\n",
              "      <td>104.166092</td>\n",
              "      <td>97.608994</td>\n",
              "      <td>89.685120</td>\n",
              "      <td>88.072662</td>\n",
              "      <td>87.214539</td>\n",
              "      <td>84.269897</td>\n",
              "      <td>78.048447</td>\n",
              "      <td>...</td>\n",
              "      <td>31.069206</td>\n",
              "      <td>32.453285</td>\n",
              "      <td>34.754326</td>\n",
              "      <td>37.349483</td>\n",
              "      <td>39.159168</td>\n",
              "      <td>40.868515</td>\n",
              "      <td>41.546715</td>\n",
              "      <td>41.138409</td>\n",
              "      <td>40.664360</td>\n",
              "      <td>39.743942</td>\n",
              "      <td>38.961937</td>\n",
              "      <td>36.782009</td>\n",
              "      <td>57.384087</td>\n",
              "      <td>54.782009</td>\n",
              "      <td>55.498268</td>\n",
              "      <td>55.920418</td>\n",
              "      <td>57.217991</td>\n",
              "      <td>58.837368</td>\n",
              "      <td>61.581314</td>\n",
              "      <td>63.955017</td>\n",
              "      <td>58.854675</td>\n",
              "      <td>31.788929</td>\n",
              "      <td>15.615916</td>\n",
              "      <td>15.636678</td>\n",
              "      <td>16.546715</td>\n",
              "      <td>21.377165</td>\n",
              "      <td>27.598616</td>\n",
              "      <td>32.262978</td>\n",
              "      <td>33.290657</td>\n",
              "      <td>33.913498</td>\n",
              "      <td>36.359863</td>\n",
              "      <td>39.231834</td>\n",
              "      <td>41.110725</td>\n",
              "      <td>42.252594</td>\n",
              "      <td>41.975780</td>\n",
              "      <td>41.276817</td>\n",
              "      <td>41.335640</td>\n",
              "      <td>40.788929</td>\n",
              "      <td>38.823532</td>\n",
              "      <td>37.723186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>54.351616</td>\n",
              "      <td>73.844467</td>\n",
              "      <td>87.849373</td>\n",
              "      <td>99.285072</td>\n",
              "      <td>98.535522</td>\n",
              "      <td>95.945152</td>\n",
              "      <td>93.682770</td>\n",
              "      <td>81.470634</td>\n",
              "      <td>46.668465</td>\n",
              "      <td>52.288353</td>\n",
              "      <td>57.668293</td>\n",
              "      <td>74.432190</td>\n",
              "      <td>82.122566</td>\n",
              "      <td>85.040756</td>\n",
              "      <td>83.370895</td>\n",
              "      <td>83.167206</td>\n",
              "      <td>83.159729</td>\n",
              "      <td>85.841347</td>\n",
              "      <td>89.677048</td>\n",
              "      <td>93.253700</td>\n",
              "      <td>99.899612</td>\n",
              "      <td>83.089920</td>\n",
              "      <td>7.013200</td>\n",
              "      <td>6.488531</td>\n",
              "      <td>16.629332</td>\n",
              "      <td>40.221115</td>\n",
              "      <td>45.161648</td>\n",
              "      <td>45.303902</td>\n",
              "      <td>84.472771</td>\n",
              "      <td>92.097023</td>\n",
              "      <td>93.706604</td>\n",
              "      <td>97.327354</td>\n",
              "      <td>97.010719</td>\n",
              "      <td>85.776161</td>\n",
              "      <td>81.309074</td>\n",
              "      <td>64.834129</td>\n",
              "      <td>52.001030</td>\n",
              "      <td>57.288223</td>\n",
              "      <td>71.707596</td>\n",
              "      <td>84.875099</td>\n",
              "      <td>...</td>\n",
              "      <td>31.156693</td>\n",
              "      <td>24.479603</td>\n",
              "      <td>14.432313</td>\n",
              "      <td>11.485670</td>\n",
              "      <td>12.014953</td>\n",
              "      <td>39.671154</td>\n",
              "      <td>67.243027</td>\n",
              "      <td>66.495796</td>\n",
              "      <td>64.108421</td>\n",
              "      <td>65.209793</td>\n",
              "      <td>68.492378</td>\n",
              "      <td>71.197754</td>\n",
              "      <td>54.765945</td>\n",
              "      <td>60.509804</td>\n",
              "      <td>58.711227</td>\n",
              "      <td>47.895382</td>\n",
              "      <td>38.751976</td>\n",
              "      <td>37.651890</td>\n",
              "      <td>37.242214</td>\n",
              "      <td>36.169979</td>\n",
              "      <td>34.573330</td>\n",
              "      <td>31.120724</td>\n",
              "      <td>31.395407</td>\n",
              "      <td>30.562305</td>\n",
              "      <td>29.509378</td>\n",
              "      <td>32.353325</td>\n",
              "      <td>40.821735</td>\n",
              "      <td>44.265881</td>\n",
              "      <td>43.228035</td>\n",
              "      <td>38.198341</td>\n",
              "      <td>25.381865</td>\n",
              "      <td>9.980692</td>\n",
              "      <td>13.410912</td>\n",
              "      <td>51.429970</td>\n",
              "      <td>70.944939</td>\n",
              "      <td>70.828918</td>\n",
              "      <td>65.401344</td>\n",
              "      <td>63.700714</td>\n",
              "      <td>67.391167</td>\n",
              "      <td>69.894577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>45.002838</td>\n",
              "      <td>42.762218</td>\n",
              "      <td>43.546391</td>\n",
              "      <td>44.322357</td>\n",
              "      <td>46.999523</td>\n",
              "      <td>50.401524</td>\n",
              "      <td>55.629768</td>\n",
              "      <td>59.514862</td>\n",
              "      <td>58.528580</td>\n",
              "      <td>60.165253</td>\n",
              "      <td>62.346977</td>\n",
              "      <td>63.215412</td>\n",
              "      <td>62.203445</td>\n",
              "      <td>60.239082</td>\n",
              "      <td>61.555553</td>\n",
              "      <td>63.836262</td>\n",
              "      <td>66.070381</td>\n",
              "      <td>67.135193</td>\n",
              "      <td>62.385147</td>\n",
              "      <td>57.610889</td>\n",
              "      <td>53.712185</td>\n",
              "      <td>53.961563</td>\n",
              "      <td>54.736706</td>\n",
              "      <td>54.892788</td>\n",
              "      <td>52.760918</td>\n",
              "      <td>46.019424</td>\n",
              "      <td>32.173729</td>\n",
              "      <td>97.762726</td>\n",
              "      <td>50.680481</td>\n",
              "      <td>48.934647</td>\n",
              "      <td>47.091965</td>\n",
              "      <td>46.294655</td>\n",
              "      <td>47.805511</td>\n",
              "      <td>51.286587</td>\n",
              "      <td>55.660683</td>\n",
              "      <td>56.416744</td>\n",
              "      <td>55.991447</td>\n",
              "      <td>56.338295</td>\n",
              "      <td>48.140896</td>\n",
              "      <td>48.197464</td>\n",
              "      <td>...</td>\n",
              "      <td>113.358566</td>\n",
              "      <td>108.451286</td>\n",
              "      <td>100.509216</td>\n",
              "      <td>105.352211</td>\n",
              "      <td>116.672073</td>\n",
              "      <td>115.678741</td>\n",
              "      <td>107.413254</td>\n",
              "      <td>113.839027</td>\n",
              "      <td>122.299965</td>\n",
              "      <td>148.686478</td>\n",
              "      <td>172.731796</td>\n",
              "      <td>210.196045</td>\n",
              "      <td>89.328857</td>\n",
              "      <td>76.448517</td>\n",
              "      <td>77.652550</td>\n",
              "      <td>83.255630</td>\n",
              "      <td>93.615227</td>\n",
              "      <td>105.818710</td>\n",
              "      <td>103.280113</td>\n",
              "      <td>58.217640</td>\n",
              "      <td>57.224102</td>\n",
              "      <td>57.864231</td>\n",
              "      <td>60.692078</td>\n",
              "      <td>60.705894</td>\n",
              "      <td>90.432854</td>\n",
              "      <td>115.670227</td>\n",
              "      <td>121.875519</td>\n",
              "      <td>120.964325</td>\n",
              "      <td>112.936562</td>\n",
              "      <td>106.426590</td>\n",
              "      <td>104.637733</td>\n",
              "      <td>110.185623</td>\n",
              "      <td>119.946648</td>\n",
              "      <td>116.916725</td>\n",
              "      <td>110.420815</td>\n",
              "      <td>116.017616</td>\n",
              "      <td>127.009300</td>\n",
              "      <td>150.962662</td>\n",
              "      <td>179.189743</td>\n",
              "      <td>206.051590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>44.115376</td>\n",
              "      <td>61.581688</td>\n",
              "      <td>69.918396</td>\n",
              "      <td>72.297073</td>\n",
              "      <td>66.837334</td>\n",
              "      <td>62.646763</td>\n",
              "      <td>60.106491</td>\n",
              "      <td>60.286396</td>\n",
              "      <td>62.146847</td>\n",
              "      <td>61.507198</td>\n",
              "      <td>64.872185</td>\n",
              "      <td>67.680000</td>\n",
              "      <td>69.206223</td>\n",
              "      <td>71.200180</td>\n",
              "      <td>73.346497</td>\n",
              "      <td>75.838211</td>\n",
              "      <td>80.172806</td>\n",
              "      <td>84.180275</td>\n",
              "      <td>86.350929</td>\n",
              "      <td>93.267563</td>\n",
              "      <td>95.200890</td>\n",
              "      <td>93.740265</td>\n",
              "      <td>88.773338</td>\n",
              "      <td>74.634308</td>\n",
              "      <td>54.312180</td>\n",
              "      <td>48.592709</td>\n",
              "      <td>87.592537</td>\n",
              "      <td>95.819740</td>\n",
              "      <td>61.838753</td>\n",
              "      <td>70.448181</td>\n",
              "      <td>76.627029</td>\n",
              "      <td>77.903473</td>\n",
              "      <td>76.454056</td>\n",
              "      <td>66.612267</td>\n",
              "      <td>59.667019</td>\n",
              "      <td>61.486042</td>\n",
              "      <td>62.708981</td>\n",
              "      <td>61.383114</td>\n",
              "      <td>62.055470</td>\n",
              "      <td>64.344887</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.472889</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.087822</td>\n",
              "      <td>0.596267</td>\n",
              "      <td>0.152178</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.019911</td>\n",
              "      <td>1.676622</td>\n",
              "      <td>2.353956</td>\n",
              "      <td>0.143289</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.054756</td>\n",
              "      <td>0.084622</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>62.900227</td>\n",
              "      <td>65.058960</td>\n",
              "      <td>62.532887</td>\n",
              "      <td>58.405895</td>\n",
              "      <td>56.902496</td>\n",
              "      <td>54.467117</td>\n",
              "      <td>54.217686</td>\n",
              "      <td>51.346943</td>\n",
              "      <td>50.018139</td>\n",
              "      <td>48.616783</td>\n",
              "      <td>49.301598</td>\n",
              "      <td>56.553291</td>\n",
              "      <td>59.167805</td>\n",
              "      <td>62.337872</td>\n",
              "      <td>62.557827</td>\n",
              "      <td>59.265305</td>\n",
              "      <td>55.936504</td>\n",
              "      <td>56.149662</td>\n",
              "      <td>68.301590</td>\n",
              "      <td>74.578232</td>\n",
              "      <td>73.904762</td>\n",
              "      <td>71.287987</td>\n",
              "      <td>73.514740</td>\n",
              "      <td>80.947838</td>\n",
              "      <td>93.970528</td>\n",
              "      <td>96.201813</td>\n",
              "      <td>86.394569</td>\n",
              "      <td>79.832199</td>\n",
              "      <td>68.673477</td>\n",
              "      <td>71.476196</td>\n",
              "      <td>66.410439</td>\n",
              "      <td>60.514744</td>\n",
              "      <td>59.764175</td>\n",
              "      <td>59.868481</td>\n",
              "      <td>55.229023</td>\n",
              "      <td>52.140594</td>\n",
              "      <td>52.108849</td>\n",
              "      <td>50.925171</td>\n",
              "      <td>51.006805</td>\n",
              "      <td>56.798187</td>\n",
              "      <td>...</td>\n",
              "      <td>78.578232</td>\n",
              "      <td>76.287987</td>\n",
              "      <td>74.303856</td>\n",
              "      <td>74.040817</td>\n",
              "      <td>75.324265</td>\n",
              "      <td>80.884361</td>\n",
              "      <td>88.721092</td>\n",
              "      <td>92.485268</td>\n",
              "      <td>86.473923</td>\n",
              "      <td>92.945580</td>\n",
              "      <td>93.945580</td>\n",
              "      <td>94.489799</td>\n",
              "      <td>45.641724</td>\n",
              "      <td>47.356010</td>\n",
              "      <td>48.158730</td>\n",
              "      <td>47.814060</td>\n",
              "      <td>44.428574</td>\n",
              "      <td>44.564629</td>\n",
              "      <td>44.659866</td>\n",
              "      <td>45.585037</td>\n",
              "      <td>46.421768</td>\n",
              "      <td>48.553291</td>\n",
              "      <td>53.374153</td>\n",
              "      <td>59.405899</td>\n",
              "      <td>69.083908</td>\n",
              "      <td>76.049896</td>\n",
              "      <td>82.324265</td>\n",
              "      <td>87.117905</td>\n",
              "      <td>89.947845</td>\n",
              "      <td>95.294792</td>\n",
              "      <td>83.845810</td>\n",
              "      <td>71.691612</td>\n",
              "      <td>70.770981</td>\n",
              "      <td>75.405899</td>\n",
              "      <td>85.845802</td>\n",
              "      <td>103.034012</td>\n",
              "      <td>129.063492</td>\n",
              "      <td>91.362816</td>\n",
              "      <td>77.301598</td>\n",
              "      <td>86.435379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>47.025150</td>\n",
              "      <td>43.486694</td>\n",
              "      <td>39.828407</td>\n",
              "      <td>34.353554</td>\n",
              "      <td>22.892014</td>\n",
              "      <td>9.300297</td>\n",
              "      <td>4.695267</td>\n",
              "      <td>4.196746</td>\n",
              "      <td>6.807693</td>\n",
              "      <td>9.989646</td>\n",
              "      <td>12.761835</td>\n",
              "      <td>29.038464</td>\n",
              "      <td>44.383137</td>\n",
              "      <td>47.319530</td>\n",
              "      <td>48.792908</td>\n",
              "      <td>50.736694</td>\n",
              "      <td>52.874268</td>\n",
              "      <td>52.610954</td>\n",
              "      <td>55.571014</td>\n",
              "      <td>56.257401</td>\n",
              "      <td>56.341721</td>\n",
              "      <td>56.331364</td>\n",
              "      <td>56.529591</td>\n",
              "      <td>52.934917</td>\n",
              "      <td>51.801781</td>\n",
              "      <td>50.353558</td>\n",
              "      <td>50.698231</td>\n",
              "      <td>50.973381</td>\n",
              "      <td>48.332840</td>\n",
              "      <td>43.491127</td>\n",
              "      <td>36.522194</td>\n",
              "      <td>29.500004</td>\n",
              "      <td>16.076925</td>\n",
              "      <td>7.426036</td>\n",
              "      <td>4.192308</td>\n",
              "      <td>3.202663</td>\n",
              "      <td>4.232249</td>\n",
              "      <td>6.621303</td>\n",
              "      <td>9.247042</td>\n",
              "      <td>14.267754</td>\n",
              "      <td>...</td>\n",
              "      <td>85.853561</td>\n",
              "      <td>85.699707</td>\n",
              "      <td>84.038475</td>\n",
              "      <td>84.285515</td>\n",
              "      <td>83.642014</td>\n",
              "      <td>82.579880</td>\n",
              "      <td>81.035507</td>\n",
              "      <td>80.594688</td>\n",
              "      <td>79.386108</td>\n",
              "      <td>78.908295</td>\n",
              "      <td>79.621315</td>\n",
              "      <td>78.319534</td>\n",
              "      <td>72.929001</td>\n",
              "      <td>75.976334</td>\n",
              "      <td>75.949715</td>\n",
              "      <td>75.575447</td>\n",
              "      <td>75.455620</td>\n",
              "      <td>75.406815</td>\n",
              "      <td>75.167168</td>\n",
              "      <td>73.646454</td>\n",
              "      <td>74.477821</td>\n",
              "      <td>76.773674</td>\n",
              "      <td>79.139069</td>\n",
              "      <td>81.039948</td>\n",
              "      <td>82.618347</td>\n",
              "      <td>83.803268</td>\n",
              "      <td>84.679001</td>\n",
              "      <td>85.727821</td>\n",
              "      <td>86.022194</td>\n",
              "      <td>85.693794</td>\n",
              "      <td>84.597641</td>\n",
              "      <td>82.772194</td>\n",
              "      <td>83.757401</td>\n",
              "      <td>82.735214</td>\n",
              "      <td>82.578407</td>\n",
              "      <td>81.085800</td>\n",
              "      <td>80.963028</td>\n",
              "      <td>80.850601</td>\n",
              "      <td>80.578415</td>\n",
              "      <td>80.051781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>110.093765</td>\n",
              "      <td>100.672707</td>\n",
              "      <td>91.884232</td>\n",
              "      <td>75.135178</td>\n",
              "      <td>66.955017</td>\n",
              "      <td>51.445248</td>\n",
              "      <td>38.050751</td>\n",
              "      <td>36.358208</td>\n",
              "      <td>38.501892</td>\n",
              "      <td>42.118145</td>\n",
              "      <td>43.424511</td>\n",
              "      <td>43.364101</td>\n",
              "      <td>41.892670</td>\n",
              "      <td>43.913795</td>\n",
              "      <td>45.487686</td>\n",
              "      <td>45.126469</td>\n",
              "      <td>48.398018</td>\n",
              "      <td>53.252930</td>\n",
              "      <td>57.366596</td>\n",
              "      <td>62.545345</td>\n",
              "      <td>72.929153</td>\n",
              "      <td>81.727242</td>\n",
              "      <td>88.323135</td>\n",
              "      <td>89.801788</td>\n",
              "      <td>89.554184</td>\n",
              "      <td>89.305481</td>\n",
              "      <td>92.234566</td>\n",
              "      <td>94.496574</td>\n",
              "      <td>129.183945</td>\n",
              "      <td>126.835388</td>\n",
              "      <td>125.411140</td>\n",
              "      <td>126.681412</td>\n",
              "      <td>126.153488</td>\n",
              "      <td>119.169800</td>\n",
              "      <td>87.790146</td>\n",
              "      <td>35.846851</td>\n",
              "      <td>37.615875</td>\n",
              "      <td>40.698883</td>\n",
              "      <td>40.596611</td>\n",
              "      <td>39.975040</td>\n",
              "      <td>...</td>\n",
              "      <td>59.283974</td>\n",
              "      <td>62.001152</td>\n",
              "      <td>64.367615</td>\n",
              "      <td>64.730370</td>\n",
              "      <td>65.296318</td>\n",
              "      <td>65.880257</td>\n",
              "      <td>65.750977</td>\n",
              "      <td>58.641346</td>\n",
              "      <td>52.965511</td>\n",
              "      <td>52.785027</td>\n",
              "      <td>81.577087</td>\n",
              "      <td>94.969475</td>\n",
              "      <td>86.565697</td>\n",
              "      <td>56.846142</td>\n",
              "      <td>42.816254</td>\n",
              "      <td>46.568069</td>\n",
              "      <td>49.105667</td>\n",
              "      <td>54.876675</td>\n",
              "      <td>59.584579</td>\n",
              "      <td>62.535362</td>\n",
              "      <td>66.263748</td>\n",
              "      <td>67.447235</td>\n",
              "      <td>63.161476</td>\n",
              "      <td>62.064899</td>\n",
              "      <td>61.487682</td>\n",
              "      <td>62.132549</td>\n",
              "      <td>62.405060</td>\n",
              "      <td>61.157322</td>\n",
              "      <td>62.350723</td>\n",
              "      <td>65.027718</td>\n",
              "      <td>67.729286</td>\n",
              "      <td>67.905411</td>\n",
              "      <td>67.765060</td>\n",
              "      <td>68.294724</td>\n",
              "      <td>69.219650</td>\n",
              "      <td>62.570305</td>\n",
              "      <td>54.060165</td>\n",
              "      <td>49.628807</td>\n",
              "      <td>70.568329</td>\n",
              "      <td>88.765068</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows  784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0           1           2    ...         781         782         783\n",
              "0     99.082436  100.500847  103.527435  ...   66.202072   65.385246   66.737305\n",
              "1     36.432102   38.111111   36.345676  ...    0.000000    0.000000    0.000000\n",
              "2     91.396652   92.909775   93.514503  ...  156.850616  156.172852  153.181381\n",
              "3    100.830452  102.103806  108.089958  ...   40.788929   38.823532   37.723186\n",
              "4     54.351616   73.844467   87.849373  ...   63.700714   67.391167   69.894577\n",
              "..          ...         ...         ...  ...         ...         ...         ...\n",
              "145   45.002838   42.762218   43.546391  ...  150.962662  179.189743  206.051590\n",
              "146   44.115376   61.581688   69.918396  ...    0.000000    0.000000    0.000000\n",
              "147   62.900227   65.058960   62.532887  ...   91.362816   77.301598   86.435379\n",
              "148   47.025150   43.486694   39.828407  ...   80.850601   80.578415   80.051781\n",
              "149  110.093765  100.672707   91.884232  ...   49.628807   70.568329   88.765068\n",
              "\n",
              "[150 rows x 784 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31usb3UnY7lD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9851124-e9b1-4fe7-f768-0a061d4ed50e"
      },
      "source": [
        "df_teste.shape # por que esta saindo 100 ???????"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 785)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVHUUaL8XXs-"
      },
      "source": [
        "#df_ann"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QBV18nYTaNE"
      },
      "source": [
        "img_graos = []\n",
        "Width_new = []\n",
        "k = 0\n",
        "for i in prediction:\n",
        "  if( i == 0):\n",
        "    img_graos.append(df_teste.iloc[k,:])\n",
        "    Width_new.append(Width.iloc[k])\n",
        "\n",
        "  k = k +1\n",
        "\n",
        "img_graos = pd.DataFrame(img_graos, columns=names )\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMCLCNQobH-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "986f0eca-63b5-4a29-ce61-dacf73e4580b"
      },
      "source": [
        "img_graos.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(109, 785)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "touLevDmbBx5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1684ce64-db8e-45aa-b1a4-1b3709b2f41f"
      },
      "source": [
        "prediction"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
              "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4RSVgX4UhbC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e38f0bf-0236-4a94-f887-9d7f5a45cace"
      },
      "source": [
        "img_graos.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(109, 785)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LkA4vHp-f6_"
      },
      "source": [
        "Width=np.array(Width_new)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjRbWgmX_LFH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1797d58-b7c3-4d02-d1af-bc85c4c161ea"
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_paper_fev_2021\n",
        "%cd marquesgabi_paper_fev_2021\n",
        "\n",
        "from Get_PSDArea_Revival import PSDArea\n",
        "from histogram_fev_2021 import PSD\n",
        "#from GetBetterSegm import GetBetter"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'marquesgabi_paper_fev_2021'...\n",
            "remote: Enumerating objects: 839, done.\u001b[K\n",
            "remote: Counting objects: 100% (600/600), done.\u001b[K\n",
            "remote: Compressing objects: 100% (598/598), done.\u001b[K\n",
            "remote: Total 839 (delta 392), reused 0 (delta 0), pack-reused 239\u001b[K\n",
            "Receiving objects: 100% (839/839), 6.27 MiB | 10.79 MiB/s, done.\n",
            "Resolving deltas: 100% (529/529), done.\n",
            "/content/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines/marquesgabi_paper_fev_2021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAG_I6FwCvFr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "d40e490a-1cd2-4be1-af50-509547448797"
      },
      "source": [
        "#https://github.com/marquesgabi/Doutorado/blob/master/Amostra7.csv\n",
        "#!git clone https://github.com/ucfilho/marquesgabi_out_2020\n",
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "#%cd marquesgabi_out_2020\n",
        "%cd Doutorado\n",
        "PSD_imageJ = 'Amostra8.csv' \n",
        "#PSD_new = pd.read_csv(PSD_imageJ,sep=';')\n",
        "#encoding='utf8'\n",
        "\n",
        "#PSD_imageJ = 'Areas_ImageJ.csv'\n",
        "PSD_new = pd.read_csv(PSD_imageJ)\n",
        "print(PSD_new.head(3))\n",
        "''''''"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Doutorado'...\n",
            "remote: Enumerating objects: 464, done.\u001b[K\n",
            "remote: Counting objects: 100% (214/214), done.\u001b[K\n",
            "remote: Compressing objects: 100% (210/210), done.\u001b[K\n",
            "remote: Total 464 (delta 102), reused 4 (delta 3), pack-reused 250\u001b[K\n",
            "Receiving objects: 100% (464/464), 166.12 MiB | 30.54 MiB/s, done.\n",
            "Resolving deltas: 100% (225/225), done.\n",
            "/content/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines/marquesgabi_paper_fev_2021/Doutorado\n",
            "     ;Area\n",
            "0  1;0.807\n",
            "1  2;1.407\n",
            "2  3;1.177\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_1WIM8w7poO"
      },
      "source": [
        "Area_All, Diameter_All=PSDArea(img_graos) "
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB3gOFPeDtoH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09998ae1-7f34-4920-cff4-dc4122b892dd"
      },
      "source": [
        "Width.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(109,)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nO6cSz2dIqb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c0f9745-5199-421d-8c21-4452e95c8c7e"
      },
      "source": [
        "img_graos.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(109, 785)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PekBHQOT_6CP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "1e17d775-c9ab-4317-f3e6-f90abe414498"
      },
      "source": [
        "img_graos.head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Width</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "      <th>769</th>\n",
              "      <th>770</th>\n",
              "      <th>771</th>\n",
              "      <th>772</th>\n",
              "      <th>773</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>173.0</td>\n",
              "      <td>99.082436</td>\n",
              "      <td>100.500847</td>\n",
              "      <td>103.527435</td>\n",
              "      <td>106.663185</td>\n",
              "      <td>111.310974</td>\n",
              "      <td>117.033173</td>\n",
              "      <td>119.828094</td>\n",
              "      <td>114.582550</td>\n",
              "      <td>68.404053</td>\n",
              "      <td>60.649975</td>\n",
              "      <td>59.055763</td>\n",
              "      <td>60.614456</td>\n",
              "      <td>56.032204</td>\n",
              "      <td>47.257103</td>\n",
              "      <td>47.631493</td>\n",
              "      <td>50.638077</td>\n",
              "      <td>51.917465</td>\n",
              "      <td>51.787895</td>\n",
              "      <td>51.810616</td>\n",
              "      <td>52.059269</td>\n",
              "      <td>52.060070</td>\n",
              "      <td>52.757591</td>\n",
              "      <td>53.150517</td>\n",
              "      <td>53.902035</td>\n",
              "      <td>56.495098</td>\n",
              "      <td>56.419323</td>\n",
              "      <td>54.643150</td>\n",
              "      <td>50.673424</td>\n",
              "      <td>99.359131</td>\n",
              "      <td>99.250084</td>\n",
              "      <td>101.213036</td>\n",
              "      <td>104.688515</td>\n",
              "      <td>109.137482</td>\n",
              "      <td>117.710312</td>\n",
              "      <td>122.831337</td>\n",
              "      <td>109.231873</td>\n",
              "      <td>64.814491</td>\n",
              "      <td>63.233025</td>\n",
              "      <td>61.645828</td>\n",
              "      <td>...</td>\n",
              "      <td>107.815186</td>\n",
              "      <td>108.771988</td>\n",
              "      <td>110.397903</td>\n",
              "      <td>112.749870</td>\n",
              "      <td>112.828957</td>\n",
              "      <td>120.650467</td>\n",
              "      <td>148.355789</td>\n",
              "      <td>69.616158</td>\n",
              "      <td>61.206318</td>\n",
              "      <td>65.829124</td>\n",
              "      <td>66.029228</td>\n",
              "      <td>65.357307</td>\n",
              "      <td>84.239403</td>\n",
              "      <td>89.281731</td>\n",
              "      <td>92.936615</td>\n",
              "      <td>97.178581</td>\n",
              "      <td>102.640282</td>\n",
              "      <td>105.690147</td>\n",
              "      <td>107.432449</td>\n",
              "      <td>113.008659</td>\n",
              "      <td>122.065025</td>\n",
              "      <td>119.903831</td>\n",
              "      <td>106.700317</td>\n",
              "      <td>95.411278</td>\n",
              "      <td>95.358818</td>\n",
              "      <td>103.384132</td>\n",
              "      <td>102.865845</td>\n",
              "      <td>101.790558</td>\n",
              "      <td>108.787498</td>\n",
              "      <td>110.436066</td>\n",
              "      <td>110.247940</td>\n",
              "      <td>112.010246</td>\n",
              "      <td>114.632629</td>\n",
              "      <td>116.383636</td>\n",
              "      <td>140.436630</td>\n",
              "      <td>86.821274</td>\n",
              "      <td>60.481468</td>\n",
              "      <td>66.202072</td>\n",
              "      <td>65.385246</td>\n",
              "      <td>66.737305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>119.0</td>\n",
              "      <td>100.830452</td>\n",
              "      <td>102.103806</td>\n",
              "      <td>108.089958</td>\n",
              "      <td>107.356407</td>\n",
              "      <td>106.380623</td>\n",
              "      <td>104.761246</td>\n",
              "      <td>97.076126</td>\n",
              "      <td>87.712807</td>\n",
              "      <td>87.456749</td>\n",
              "      <td>86.709343</td>\n",
              "      <td>85.903114</td>\n",
              "      <td>79.972321</td>\n",
              "      <td>68.505196</td>\n",
              "      <td>64.768166</td>\n",
              "      <td>61.792389</td>\n",
              "      <td>62.498272</td>\n",
              "      <td>65.173012</td>\n",
              "      <td>68.294121</td>\n",
              "      <td>69.965401</td>\n",
              "      <td>71.515572</td>\n",
              "      <td>72.162636</td>\n",
              "      <td>70.529411</td>\n",
              "      <td>69.418678</td>\n",
              "      <td>71.474052</td>\n",
              "      <td>73.858131</td>\n",
              "      <td>76.051910</td>\n",
              "      <td>78.702423</td>\n",
              "      <td>74.128029</td>\n",
              "      <td>106.837364</td>\n",
              "      <td>104.470589</td>\n",
              "      <td>112.366776</td>\n",
              "      <td>125.460197</td>\n",
              "      <td>107.847755</td>\n",
              "      <td>104.166092</td>\n",
              "      <td>97.608994</td>\n",
              "      <td>89.685120</td>\n",
              "      <td>88.072662</td>\n",
              "      <td>87.214539</td>\n",
              "      <td>84.269897</td>\n",
              "      <td>...</td>\n",
              "      <td>31.069206</td>\n",
              "      <td>32.453285</td>\n",
              "      <td>34.754326</td>\n",
              "      <td>37.349483</td>\n",
              "      <td>39.159168</td>\n",
              "      <td>40.868515</td>\n",
              "      <td>41.546715</td>\n",
              "      <td>41.138409</td>\n",
              "      <td>40.664360</td>\n",
              "      <td>39.743942</td>\n",
              "      <td>38.961937</td>\n",
              "      <td>36.782009</td>\n",
              "      <td>57.384087</td>\n",
              "      <td>54.782009</td>\n",
              "      <td>55.498268</td>\n",
              "      <td>55.920418</td>\n",
              "      <td>57.217991</td>\n",
              "      <td>58.837368</td>\n",
              "      <td>61.581314</td>\n",
              "      <td>63.955017</td>\n",
              "      <td>58.854675</td>\n",
              "      <td>31.788929</td>\n",
              "      <td>15.615916</td>\n",
              "      <td>15.636678</td>\n",
              "      <td>16.546715</td>\n",
              "      <td>21.377165</td>\n",
              "      <td>27.598616</td>\n",
              "      <td>32.262978</td>\n",
              "      <td>33.290657</td>\n",
              "      <td>33.913498</td>\n",
              "      <td>36.359863</td>\n",
              "      <td>39.231834</td>\n",
              "      <td>41.110725</td>\n",
              "      <td>42.252594</td>\n",
              "      <td>41.975780</td>\n",
              "      <td>41.276817</td>\n",
              "      <td>41.335640</td>\n",
              "      <td>40.788929</td>\n",
              "      <td>38.823532</td>\n",
              "      <td>37.723186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>153.0</td>\n",
              "      <td>54.351616</td>\n",
              "      <td>73.844467</td>\n",
              "      <td>87.849373</td>\n",
              "      <td>99.285072</td>\n",
              "      <td>98.535522</td>\n",
              "      <td>95.945152</td>\n",
              "      <td>93.682770</td>\n",
              "      <td>81.470634</td>\n",
              "      <td>46.668465</td>\n",
              "      <td>52.288353</td>\n",
              "      <td>57.668293</td>\n",
              "      <td>74.432190</td>\n",
              "      <td>82.122566</td>\n",
              "      <td>85.040756</td>\n",
              "      <td>83.370895</td>\n",
              "      <td>83.167206</td>\n",
              "      <td>83.159729</td>\n",
              "      <td>85.841347</td>\n",
              "      <td>89.677048</td>\n",
              "      <td>93.253700</td>\n",
              "      <td>99.899612</td>\n",
              "      <td>83.089920</td>\n",
              "      <td>7.013200</td>\n",
              "      <td>6.488531</td>\n",
              "      <td>16.629332</td>\n",
              "      <td>40.221115</td>\n",
              "      <td>45.161648</td>\n",
              "      <td>45.303902</td>\n",
              "      <td>84.472771</td>\n",
              "      <td>92.097023</td>\n",
              "      <td>93.706604</td>\n",
              "      <td>97.327354</td>\n",
              "      <td>97.010719</td>\n",
              "      <td>85.776161</td>\n",
              "      <td>81.309074</td>\n",
              "      <td>64.834129</td>\n",
              "      <td>52.001030</td>\n",
              "      <td>57.288223</td>\n",
              "      <td>71.707596</td>\n",
              "      <td>...</td>\n",
              "      <td>31.156693</td>\n",
              "      <td>24.479603</td>\n",
              "      <td>14.432313</td>\n",
              "      <td>11.485670</td>\n",
              "      <td>12.014953</td>\n",
              "      <td>39.671154</td>\n",
              "      <td>67.243027</td>\n",
              "      <td>66.495796</td>\n",
              "      <td>64.108421</td>\n",
              "      <td>65.209793</td>\n",
              "      <td>68.492378</td>\n",
              "      <td>71.197754</td>\n",
              "      <td>54.765945</td>\n",
              "      <td>60.509804</td>\n",
              "      <td>58.711227</td>\n",
              "      <td>47.895382</td>\n",
              "      <td>38.751976</td>\n",
              "      <td>37.651890</td>\n",
              "      <td>37.242214</td>\n",
              "      <td>36.169979</td>\n",
              "      <td>34.573330</td>\n",
              "      <td>31.120724</td>\n",
              "      <td>31.395407</td>\n",
              "      <td>30.562305</td>\n",
              "      <td>29.509378</td>\n",
              "      <td>32.353325</td>\n",
              "      <td>40.821735</td>\n",
              "      <td>44.265881</td>\n",
              "      <td>43.228035</td>\n",
              "      <td>38.198341</td>\n",
              "      <td>25.381865</td>\n",
              "      <td>9.980692</td>\n",
              "      <td>13.410912</td>\n",
              "      <td>51.429970</td>\n",
              "      <td>70.944939</td>\n",
              "      <td>70.828918</td>\n",
              "      <td>65.401344</td>\n",
              "      <td>63.700714</td>\n",
              "      <td>67.391167</td>\n",
              "      <td>69.894577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>195.0</td>\n",
              "      <td>81.250374</td>\n",
              "      <td>79.305641</td>\n",
              "      <td>78.144989</td>\n",
              "      <td>78.895439</td>\n",
              "      <td>80.518501</td>\n",
              "      <td>75.964661</td>\n",
              "      <td>65.282349</td>\n",
              "      <td>55.765396</td>\n",
              "      <td>65.510773</td>\n",
              "      <td>79.849968</td>\n",
              "      <td>80.573311</td>\n",
              "      <td>81.428589</td>\n",
              "      <td>83.644661</td>\n",
              "      <td>83.810028</td>\n",
              "      <td>84.614632</td>\n",
              "      <td>86.975975</td>\n",
              "      <td>87.970078</td>\n",
              "      <td>93.917854</td>\n",
              "      <td>100.895554</td>\n",
              "      <td>104.049423</td>\n",
              "      <td>99.261757</td>\n",
              "      <td>98.055550</td>\n",
              "      <td>97.303589</td>\n",
              "      <td>65.942017</td>\n",
              "      <td>53.909592</td>\n",
              "      <td>51.989590</td>\n",
              "      <td>53.987564</td>\n",
              "      <td>56.167767</td>\n",
              "      <td>80.957191</td>\n",
              "      <td>81.017044</td>\n",
              "      <td>80.258644</td>\n",
              "      <td>79.540802</td>\n",
              "      <td>73.402138</td>\n",
              "      <td>66.129242</td>\n",
              "      <td>45.977837</td>\n",
              "      <td>41.929184</td>\n",
              "      <td>57.260517</td>\n",
              "      <td>72.767891</td>\n",
              "      <td>77.093605</td>\n",
              "      <td>...</td>\n",
              "      <td>97.920670</td>\n",
              "      <td>101.223328</td>\n",
              "      <td>107.412735</td>\n",
              "      <td>111.715698</td>\n",
              "      <td>114.784912</td>\n",
              "      <td>114.262245</td>\n",
              "      <td>113.648331</td>\n",
              "      <td>106.231628</td>\n",
              "      <td>114.675789</td>\n",
              "      <td>127.392502</td>\n",
              "      <td>130.704422</td>\n",
              "      <td>71.230385</td>\n",
              "      <td>66.962349</td>\n",
              "      <td>60.348118</td>\n",
              "      <td>53.733810</td>\n",
              "      <td>48.982307</td>\n",
              "      <td>45.550041</td>\n",
              "      <td>38.514820</td>\n",
              "      <td>37.163712</td>\n",
              "      <td>33.410549</td>\n",
              "      <td>31.856255</td>\n",
              "      <td>40.843342</td>\n",
              "      <td>45.285339</td>\n",
              "      <td>57.374969</td>\n",
              "      <td>83.004211</td>\n",
              "      <td>88.840172</td>\n",
              "      <td>88.046867</td>\n",
              "      <td>93.126740</td>\n",
              "      <td>96.797462</td>\n",
              "      <td>101.055069</td>\n",
              "      <td>103.849823</td>\n",
              "      <td>107.065170</td>\n",
              "      <td>110.620758</td>\n",
              "      <td>114.921448</td>\n",
              "      <td>117.264893</td>\n",
              "      <td>113.079849</td>\n",
              "      <td>118.823654</td>\n",
              "      <td>135.256317</td>\n",
              "      <td>103.476067</td>\n",
              "      <td>57.606659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>145.0</td>\n",
              "      <td>55.403519</td>\n",
              "      <td>58.154625</td>\n",
              "      <td>62.224781</td>\n",
              "      <td>74.458969</td>\n",
              "      <td>80.401283</td>\n",
              "      <td>83.168655</td>\n",
              "      <td>85.176453</td>\n",
              "      <td>87.205467</td>\n",
              "      <td>86.794670</td>\n",
              "      <td>86.361855</td>\n",
              "      <td>87.393814</td>\n",
              "      <td>88.226830</td>\n",
              "      <td>86.486176</td>\n",
              "      <td>81.156906</td>\n",
              "      <td>78.640572</td>\n",
              "      <td>71.440002</td>\n",
              "      <td>67.940979</td>\n",
              "      <td>60.377689</td>\n",
              "      <td>53.286659</td>\n",
              "      <td>50.818359</td>\n",
              "      <td>65.889610</td>\n",
              "      <td>72.512581</td>\n",
              "      <td>71.684662</td>\n",
              "      <td>71.036766</td>\n",
              "      <td>74.230820</td>\n",
              "      <td>74.214836</td>\n",
              "      <td>73.702110</td>\n",
              "      <td>71.507393</td>\n",
              "      <td>51.481804</td>\n",
              "      <td>55.870205</td>\n",
              "      <td>64.340363</td>\n",
              "      <td>77.208649</td>\n",
              "      <td>83.330559</td>\n",
              "      <td>86.689789</td>\n",
              "      <td>85.740829</td>\n",
              "      <td>87.979485</td>\n",
              "      <td>89.581169</td>\n",
              "      <td>89.365608</td>\n",
              "      <td>91.421875</td>\n",
              "      <td>...</td>\n",
              "      <td>101.275818</td>\n",
              "      <td>104.139351</td>\n",
              "      <td>113.983871</td>\n",
              "      <td>110.481377</td>\n",
              "      <td>92.911491</td>\n",
              "      <td>90.780502</td>\n",
              "      <td>82.901062</td>\n",
              "      <td>77.831390</td>\n",
              "      <td>74.889084</td>\n",
              "      <td>73.918236</td>\n",
              "      <td>76.524567</td>\n",
              "      <td>80.748672</td>\n",
              "      <td>55.559193</td>\n",
              "      <td>58.662643</td>\n",
              "      <td>60.745026</td>\n",
              "      <td>59.343159</td>\n",
              "      <td>57.473198</td>\n",
              "      <td>55.337265</td>\n",
              "      <td>55.026447</td>\n",
              "      <td>58.203136</td>\n",
              "      <td>60.298317</td>\n",
              "      <td>61.618362</td>\n",
              "      <td>72.965942</td>\n",
              "      <td>88.452271</td>\n",
              "      <td>100.130417</td>\n",
              "      <td>103.383011</td>\n",
              "      <td>105.228012</td>\n",
              "      <td>109.655121</td>\n",
              "      <td>105.774734</td>\n",
              "      <td>102.376976</td>\n",
              "      <td>101.655701</td>\n",
              "      <td>98.036011</td>\n",
              "      <td>88.377548</td>\n",
              "      <td>79.159386</td>\n",
              "      <td>74.375977</td>\n",
              "      <td>72.507256</td>\n",
              "      <td>69.201477</td>\n",
              "      <td>69.491226</td>\n",
              "      <td>72.700348</td>\n",
              "      <td>77.060501</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Width           0           1  ...         781         782        783\n",
              "0  173.0   99.082436  100.500847  ...   66.202072   65.385246  66.737305\n",
              "3  119.0  100.830452  102.103806  ...   40.788929   38.823532  37.723186\n",
              "4  153.0   54.351616   73.844467  ...   63.700714   67.391167  69.894577\n",
              "5  195.0   81.250374   79.305641  ...  135.256317  103.476067  57.606659\n",
              "6  145.0   55.403519   58.154625  ...   69.491226   72.700348  77.060501\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaZPe_AxNBK9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbb5096c-621e-46dc-930b-5805bc20c57e"
      },
      "source": [
        "PSD_new.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(99, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vmhG2LgCabC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "963bfb86-c955-4cbd-c4dc-7fa244c730dd"
      },
      "source": [
        "Diam1 =[]\n",
        "'''\n",
        "# \n",
        "Area = df_ImgJ['Area'].values\n",
        "# Area = np.concatenate( (Area, [lost_value] ) )\n",
        "\n",
        "Diam1 = [ (4*A/np.pi)**0.5 for A in Area]\n",
        "'''\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n# \\nArea = df_ImgJ['Area'].values\\n# Area = np.concatenate( (Area, [lost_value] ) )\\n\\nDiam1 = [ (4*A/np.pi)**0.5 for A in Area]\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79MY9ZHxBW37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6198a777-f022-4e2b-a12d-842e83a99c30"
      },
      "source": [
        "len(Diameter_All)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "109"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KooHVpH5k2mZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dc9c789-77f4-42d7-f5d8-4f78948592f3"
      },
      "source": [
        "A=PSD_new[';Area'].values\n",
        "k = 0\n",
        "Area2 = []\n",
        "for i in A:\n",
        "  if(A[k][2] == ';'):\n",
        "    Area2.append(float(A[k][3:]))\n",
        "  else:\n",
        "      Area2.append(float(A[k][2:]))  \n",
        "  k = k +1\n",
        "print(Area2)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.807, 1.407, 1.177, 1.289, 1.743, 1.425, 2.553, 0.968, 1.43, 0.722, 1.235, 1.058, 1.342, 1.207, 1.682, 1.474, 1.997, 1.187, 2.082, 2.877, 1.386, 1.176, 0.96, 1.147, 1.02, 1.249, 1.704, 1.602, 1.303, 1.707, 2.264, 1.233, 0.84, 1.105, 1.343, 0.811, 2.03, 1.844, 2.266, 1.472, 1.009, 1.851, 0.941, 2.252, 1.269, 1.082, 1.065, 1.995, 2.063, 0.969, 1.389, 1.721, 1.355, 1.178, 1.529, 1.371, 1.423, 2.756, 0.854, 0.811, 0.69, 1.752, 0.978, 1.108, 1.149, 0.994, 1.594, 1.492, 1.322, 1.564, 1.29, 1.057, 1.193, 1.413, 1.477, 2.21, 1.27, 1.865, 1.088, 2.316, 1.855, 0.882, 1.587, 1.075, 2.179, 1.749, 0.957, 1.24, 1.586, 2.507, 1.864, 1.281, 2.137, 1.282, 2.097, 1.871, 1.315, 1.034, 2.095]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvda6sN-9voL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e98440ac-83bd-4b31-a398-0f2189b6a9a6"
      },
      "source": [
        "len(Area2)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "99"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPWCPPf7bzsf"
      },
      "source": [
        "#lost_value = float(PSD_new.columns[1])\n",
        "#Area2 = np.array(PSD_new.iloc[:,1])\n",
        "#Area2 = np.concatenate( (Area2, [lost_value] ) )\n",
        "\n",
        "for A in Area2:\n",
        "  Diam1.append((4*A/np.pi)**0.5) \n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfk_fNXGDK5_"
      },
      "source": [
        "wt1 = np.ones(len(Diam1)) / len(Diam1)*100\n",
        "wt2 = np.ones(len(Diameter_All)) / len(Diameter_All)*100\n",
        "X = pd.DataFrame([Diam1,Diameter_All])\n",
        "wts = pd.DataFrame([wt1,wt2])\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWf2nmnEp6yX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "9338e786-5952-4a99-fa37-2b80286af068"
      },
      "source": [
        "X"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>100</th>\n",
              "      <th>101</th>\n",
              "      <th>102</th>\n",
              "      <th>103</th>\n",
              "      <th>104</th>\n",
              "      <th>105</th>\n",
              "      <th>106</th>\n",
              "      <th>107</th>\n",
              "      <th>108</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.013659</td>\n",
              "      <td>1.338450</td>\n",
              "      <td>1.224174</td>\n",
              "      <td>1.281096</td>\n",
              "      <td>1.489717</td>\n",
              "      <td>1.346984</td>\n",
              "      <td>1.802937</td>\n",
              "      <td>1.110178</td>\n",
              "      <td>1.349345</td>\n",
              "      <td>0.958790</td>\n",
              "      <td>1.253974</td>\n",
              "      <td>1.160641</td>\n",
              "      <td>1.307168</td>\n",
              "      <td>1.239677</td>\n",
              "      <td>1.463417</td>\n",
              "      <td>1.369947</td>\n",
              "      <td>1.594572</td>\n",
              "      <td>1.229364</td>\n",
              "      <td>1.628154</td>\n",
              "      <td>1.913925</td>\n",
              "      <td>1.328424</td>\n",
              "      <td>1.223654</td>\n",
              "      <td>1.105581</td>\n",
              "      <td>1.208472</td>\n",
              "      <td>1.139607</td>\n",
              "      <td>1.261062</td>\n",
              "      <td>1.472956</td>\n",
              "      <td>1.428191</td>\n",
              "      <td>1.288034</td>\n",
              "      <td>1.474252</td>\n",
              "      <td>1.697826</td>\n",
              "      <td>1.252958</td>\n",
              "      <td>1.034177</td>\n",
              "      <td>1.186141</td>\n",
              "      <td>1.307655</td>\n",
              "      <td>1.016168</td>\n",
              "      <td>1.607693</td>\n",
              "      <td>1.532271</td>\n",
              "      <td>1.698576</td>\n",
              "      <td>1.369017</td>\n",
              "      <td>...</td>\n",
              "      <td>1.411151</td>\n",
              "      <td>1.281592</td>\n",
              "      <td>1.160092</td>\n",
              "      <td>1.232467</td>\n",
              "      <td>1.341301</td>\n",
              "      <td>1.371341</td>\n",
              "      <td>1.677456</td>\n",
              "      <td>1.271619</td>\n",
              "      <td>1.540971</td>\n",
              "      <td>1.176981</td>\n",
              "      <td>1.717214</td>\n",
              "      <td>1.536834</td>\n",
              "      <td>1.059716</td>\n",
              "      <td>1.421489</td>\n",
              "      <td>1.169928</td>\n",
              "      <td>1.665650</td>\n",
              "      <td>1.492279</td>\n",
              "      <td>1.103852</td>\n",
              "      <td>1.256510</td>\n",
              "      <td>1.421041</td>\n",
              "      <td>1.78662</td>\n",
              "      <td>1.540558</td>\n",
              "      <td>1.277114</td>\n",
              "      <td>1.649519</td>\n",
              "      <td>1.277612</td>\n",
              "      <td>1.634008</td>\n",
              "      <td>1.543448</td>\n",
              "      <td>1.293951</td>\n",
              "      <td>1.147401</td>\n",
              "      <td>1.633229</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.209467</td>\n",
              "      <td>1.037028</td>\n",
              "      <td>0.781547</td>\n",
              "      <td>1.141569</td>\n",
              "      <td>0.898074</td>\n",
              "      <td>1.130326</td>\n",
              "      <td>0.781060</td>\n",
              "      <td>1.228702</td>\n",
              "      <td>0.961150</td>\n",
              "      <td>1.070606</td>\n",
              "      <td>1.302114</td>\n",
              "      <td>0.647039</td>\n",
              "      <td>1.263625</td>\n",
              "      <td>1.415682</td>\n",
              "      <td>1.323955</td>\n",
              "      <td>1.350608</td>\n",
              "      <td>0.999381</td>\n",
              "      <td>0.794729</td>\n",
              "      <td>1.029396</td>\n",
              "      <td>0.864306</td>\n",
              "      <td>1.171428</td>\n",
              "      <td>0.939337</td>\n",
              "      <td>0.974736</td>\n",
              "      <td>0.989464</td>\n",
              "      <td>1.178034</td>\n",
              "      <td>0.739896</td>\n",
              "      <td>0.731973</td>\n",
              "      <td>0.781648</td>\n",
              "      <td>0.869379</td>\n",
              "      <td>0.871113</td>\n",
              "      <td>0.584037</td>\n",
              "      <td>1.127664</td>\n",
              "      <td>1.105319</td>\n",
              "      <td>0.812586</td>\n",
              "      <td>0.882299</td>\n",
              "      <td>1.396361</td>\n",
              "      <td>1.070458</td>\n",
              "      <td>0.816894</td>\n",
              "      <td>1.075517</td>\n",
              "      <td>1.208600</td>\n",
              "      <td>...</td>\n",
              "      <td>1.005652</td>\n",
              "      <td>1.125674</td>\n",
              "      <td>1.022247</td>\n",
              "      <td>1.106080</td>\n",
              "      <td>1.155834</td>\n",
              "      <td>1.432723</td>\n",
              "      <td>0.992501</td>\n",
              "      <td>1.131798</td>\n",
              "      <td>1.432112</td>\n",
              "      <td>1.112039</td>\n",
              "      <td>1.091280</td>\n",
              "      <td>0.694080</td>\n",
              "      <td>0.851882</td>\n",
              "      <td>1.059973</td>\n",
              "      <td>0.966324</td>\n",
              "      <td>0.904946</td>\n",
              "      <td>0.934945</td>\n",
              "      <td>0.973499</td>\n",
              "      <td>0.903701</td>\n",
              "      <td>1.407110</td>\n",
              "      <td>0.63030</td>\n",
              "      <td>1.291639</td>\n",
              "      <td>0.813230</td>\n",
              "      <td>0.797967</td>\n",
              "      <td>1.399889</td>\n",
              "      <td>1.538036</td>\n",
              "      <td>0.770811</td>\n",
              "      <td>0.533226</td>\n",
              "      <td>1.308829</td>\n",
              "      <td>0.947557</td>\n",
              "      <td>0.952326</td>\n",
              "      <td>1.012197</td>\n",
              "      <td>1.317333</td>\n",
              "      <td>1.467121</td>\n",
              "      <td>1.277627</td>\n",
              "      <td>1.322137</td>\n",
              "      <td>1.048671</td>\n",
              "      <td>1.240992</td>\n",
              "      <td>0.74567</td>\n",
              "      <td>0.958572</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows  109 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2    ...       106      107       108\n",
              "0  1.013659  1.338450  1.224174  ...       NaN      NaN       NaN\n",
              "1  1.209467  1.037028  0.781547  ...  1.240992  0.74567  0.958572\n",
              "\n",
              "[2 rows x 109 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzFRjY4BLtbh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef96e050-5aa5-4e4b-c966-305274c3e7ad"
      },
      "source": [
        "Diameter_All"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.2094672444454106,\n",
              " 1.0370278315520283,\n",
              " 0.7815467782613417,\n",
              " 1.1415688046567898,\n",
              " 0.8980742876170839,\n",
              " 1.1303257272452458,\n",
              " 0.7810600295379171,\n",
              " 1.2287024134580757,\n",
              " 0.9611500150100337,\n",
              " 1.070605580567782,\n",
              " 1.3021137077177298,\n",
              " 0.6470388789280935,\n",
              " 1.263624603683756,\n",
              " 1.4156821688529266,\n",
              " 1.3239549927632115,\n",
              " 1.350608314791452,\n",
              " 0.9993813079917083,\n",
              " 0.7947288311248363,\n",
              " 1.029395902719949,\n",
              " 0.8643058013395672,\n",
              " 1.171428480963255,\n",
              " 0.9393368439457506,\n",
              " 0.9747358199592148,\n",
              " 0.9894635459375722,\n",
              " 1.178033664916224,\n",
              " 0.7398957563362759,\n",
              " 0.7319729593862689,\n",
              " 0.7816476789909745,\n",
              " 0.8693794612898934,\n",
              " 0.8711131444048813,\n",
              " 0.5840373748905395,\n",
              " 1.1276635494994995,\n",
              " 1.1053192422464135,\n",
              " 0.8125861331245107,\n",
              " 0.8822994936135099,\n",
              " 1.3963613873207665,\n",
              " 1.070457608288839,\n",
              " 0.8168941604639937,\n",
              " 1.0755173482627605,\n",
              " 1.2086000244299997,\n",
              " 0.614029090092124,\n",
              " 1.1567544760645625,\n",
              " 0.9209519808477531,\n",
              " 0.7669000687694331,\n",
              " 0.7301498607661364,\n",
              " 0.7278726253637513,\n",
              " 1.1362686168298148,\n",
              " 1.4299306616140384,\n",
              " 0.8246943755741686,\n",
              " 1.196731109547093,\n",
              " 1.0062636276491628,\n",
              " 0.9139762991759832,\n",
              " 0.9974015646882359,\n",
              " 1.1662098195197943,\n",
              " 1.0328514366466144,\n",
              " 0.9152294691640157,\n",
              " 0.9369212752133954,\n",
              " 0.5824854457570907,\n",
              " 1.1501596532611602,\n",
              " 0.8528811978513291,\n",
              " 0.7509822899620013,\n",
              " 0.8735064991879201,\n",
              " 1.5154318347201103,\n",
              " 1.1722891473476609,\n",
              " 0.7042778571426642,\n",
              " 1.118504431075224,\n",
              " 1.2942563583569417,\n",
              " 0.9982634369101671,\n",
              " 0.5961648648804055,\n",
              " 1.0056516496805683,\n",
              " 1.1256743312744242,\n",
              " 1.0222471412964678,\n",
              " 1.1060803034634423,\n",
              " 1.1558337238408987,\n",
              " 1.4327226512329156,\n",
              " 0.9925006075579975,\n",
              " 1.1317977079112524,\n",
              " 1.4321124769686049,\n",
              " 1.1120391199238604,\n",
              " 1.0912797091224296,\n",
              " 0.6940800960683975,\n",
              " 0.8518815071154494,\n",
              " 1.0599728117952787,\n",
              " 0.9663242701283808,\n",
              " 0.9049457557229702,\n",
              " 0.9349447555824861,\n",
              " 0.973499343867005,\n",
              " 0.9037014888564048,\n",
              " 1.407109901159947,\n",
              " 0.6303003071570922,\n",
              " 1.2916387561368274,\n",
              " 0.81323002081122,\n",
              " 0.7979671691275227,\n",
              " 1.399889317210721,\n",
              " 1.5380364613272726,\n",
              " 0.770811008247091,\n",
              " 0.5332260654678256,\n",
              " 1.3088292284385705,\n",
              " 0.9475566333582899,\n",
              " 0.9523264658776959,\n",
              " 1.012196666598154,\n",
              " 1.3173333610397027,\n",
              " 1.467120645731423,\n",
              " 1.2776274934835852,\n",
              " 1.3221369578425453,\n",
              " 1.0486710211954426,\n",
              " 1.2409921221537321,\n",
              " 0.745669620716816,\n",
              " 0.9585717629229964]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OieAXw_by3nz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "2392e15b-98ad-43bc-8fd2-56be9e73993a"
      },
      "source": [
        "A = plt.hist(X,weights=wts,bins=7)\n",
        "plt.legend(['True','CNN'])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f9890dc4750>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WryLryB9ovi3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69e695e7-9ff8-4531-f90a-d2c452c5f040"
      },
      "source": [
        "print('ImgJ:','media=',np.mean(np.array(Diam1)),'desvio=',np.std(np.array(Diam1)),'pontos=',len(Diam1))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ImgJ: media= 1.3505581526276078 desvio= 0.2150949058846736 pontos= 99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_Nyv-Nopbkc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83932bc2-bb9d-4270-d837-4a6b2b70c292"
      },
      "source": [
        "print('Software:','media=',np.mean(np.array(Diameter_All)),'desvio=',np.std(np.array(Diameter_All)),'pontos=',len(Diameter_All))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Software: media= 1.0212658413938398 desvio= 0.23241404739536053 pontos= 109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eE6PjA0SZ8ZQ"
      },
      "source": [
        "# Software: media= 1.3185563233999378 desvio= 0.2728642468732428 pontos= 66 theshold =0.8 e repete=80\n",
        "# Software: media= 1.2650227960747715 desvio= 0.22942393421076387 pontos= 20 theshold =0.5 e repete=40"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpdrvEySy8Ij",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "175b641f-349b-4f7b-88be-295041536b2b"
      },
      "source": [
        "np.mean(np.array(Diameter_All))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0212658413938398"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMK89w-fzCVe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "f7c2c3b6-e6f4-4120-a2a8-8357b81334b0"
      },
      "source": [
        "# Freq1 = [19.12043703, 29.22484843, 19.35872174, 20.82190224, 11.47409056] # avarage 4 samples\n",
        "Freq1 = [20.69301557, 28.55598044, 18.50768331, 22.7106327, 8.905907357] # avarage 10 samples\n",
        "#Freq2 = [16.93792791, 31.38008965, 24.93810752, 18.56158392, 6.233810752, 0.4]\n",
        "Freq2 = [16.93792791, 31.38008965, 24.93810752, 18.56158392, 6.633810752]\n",
        "Freq3 = [22.22489, 30.15078, 25.10463, 19.30926, 2.810434]\n",
        "barWidth = 0.25\n",
        "\n",
        "br1 = range(len(Freq1))\n",
        "# Set position of bar on X axis\n",
        "br2 = [x + barWidth for x in br1]\n",
        "br3 = [x + barWidth for x in br2]\n",
        "# labels = [0.8, 1.0, 1.2, 1.4, 1.6, 1.8]\n",
        "labels = [0.8, 1.0, 1.2, 1.4, 1.6]\n",
        "\n",
        "xx=[]\n",
        "for a in labels:\n",
        "  xx.append(str(a))\n",
        "plt.bar(br1, Freq1 , color=\"green\", align=\"center\", width=0.3, tick_label= xx) \n",
        "plt.bar(br2, Freq2 , color=\"red\", align=\"center\", width=0.3, tick_label= xx)\n",
        "plt.bar(br3, Freq3 , color=\"blue\", align=\"center\", width=0.3, tick_label= xx)\n",
        "plt.legend(['CNN 1','CNN 2','True'])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f9891671f50>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}