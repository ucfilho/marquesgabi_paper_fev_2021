{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PSD_histogram_BEST_sample_07.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ucfilho/marquesgabi_paper_fev_2021/blob/main/defesa/PSD_histogram_BEST_sample_07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sog7Z9pyhUD_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import zipfile\n",
        "#import random\n",
        "from random import randint\n",
        "from PIL import Image\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "#import scikit-image\n",
        "import skimage\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
        "from sklearn.metrics import r2_score\n",
        "from google.colab import files"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsqQZIu-mEfi"
      },
      "source": [
        "Repetir = 40"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwc7AZrXRyqk"
      },
      "source": [
        "# New version change routine inside MarquesGabi_Routines\n",
        "# Try to improve segmentation \n",
        "# New routine is called Segment_Filter_revisited_One... Two,Three, etc\n",
        "# this exemple threshold 0.4\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZEvJvfoibE4"
      },
      "source": [
        "#!pip install mahotas"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UZ30b1EVQhq"
      },
      "source": [
        "def BlackWhite(Transfere,Size):\n",
        "\n",
        "  img_name=[]\n",
        "  xw=[]\n",
        "  ww=[]\n",
        "\n",
        "  with zipfile.ZipFile(Transfere, \"r\") as f:\n",
        "    for name in f.namelist():\n",
        "      img_name.append(name)\n",
        "      #xw.append(cv2.imread(name))\n",
        "      xw.append(cv2.resize(cv2.imread(name),(Size,Size)))\n",
        "\n",
        "  nrow=len(img_name)\n",
        "  ncol=Size*Size\n",
        "  pw=np.zeros((nrow,ncol))\n",
        "  #pw=[]\n",
        "  for i in range(nrow):\n",
        "    ww.append(cv2.cvtColor(np.array(xw[i]), cv2.COLOR_BGR2GRAY))\n",
        "    pw[i,:]=ww[i].ravel()\n",
        "  return ww,img_name"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v7SRrc8mH2N",
        "outputId": "6bd14fb2-d2c5-46d5-85cb-21781cb6bf44"
      },
      "source": [
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "%cd Doutorado\n",
        "\n",
        "Transfere='Fotos_Grandes_3cdAmostra.zip' \n",
        "file_name = zipfile.ZipFile(Transfere, 'r')\n",
        "file_name.extractall()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Doutorado' already exists and is not an empty directory.\n",
            "/content/Doutorado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqIYzUcnrdMp",
        "outputId": "562aa842-af3f-4a49-b169-7da1f391df04"
      },
      "source": [
        "labels =[]\n",
        "with zipfile.ZipFile(Transfere, \"r\") as f:\n",
        "  for f in f.namelist():\n",
        "    labels.append(f)\n",
        "print(labels)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Fotos_Grandes-3cdAmostra/Q6-8-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-8-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-8-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-4.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kA4IWSmasoD"
      },
      "source": [
        "Size=1200 # tamanho da foto\n",
        "ww,img_name=BlackWhite(Transfere,Size) #Pegamos a primeira foto Grande\n",
        "# this is the big image we want to segment \n",
        "# ww[0], change it if you want to segment another picture"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHgqAnaFyCjp",
        "outputId": "95c1782a-0906-4e97-9a9d-12a841032359"
      },
      "source": [
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MarquesGabi_Routines' already exists and is not an empty directory.\n",
            "/content/Doutorado/MarquesGabi_Routines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDEGUiuubwuZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "e3e3127d-4529-48b9-8254-bb6617b7edb3"
      },
      "source": [
        "'''\n",
        "FILE='SugarSample03.zip'\n",
        "img_name=[]\n",
        "x_original = [] \n",
        "\n",
        "data_file ='xls'\n",
        "\n",
        "\n",
        "file_name = zipfile.ZipFile(FILE, 'r')\n",
        "file_name.extractall()\n",
        "\n",
        "k = 0\n",
        "with zipfile.ZipFile(FILE, \"r\") as f:\n",
        "    for name in f.namelist():\n",
        "      if(name[-3:] == data_file):\n",
        "        #df =pd.read_csv(name)\n",
        "        if( k > 0):\n",
        "          df_old = df_ImgJ.copy()\n",
        "        df_ImgJ = pd.read_excel(name)\n",
        "        df_ImgJ = df_ImgJ.drop(labels=[0], axis=0)\n",
        "        if(k > 0):\n",
        "          df_ImgJ = pd.concat( [df_ImgJ, df_old], ignore_index = True)\n",
        "        k = k + 1\n",
        "'''"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nFILE=\\'SugarSample03.zip\\'\\nimg_name=[]\\nx_original = [] \\n\\ndata_file =\\'xls\\'\\n\\n\\nfile_name = zipfile.ZipFile(FILE, \\'r\\')\\nfile_name.extractall()\\n\\nk = 0\\nwith zipfile.ZipFile(FILE, \"r\") as f:\\n    for name in f.namelist():\\n      if(name[-3:] == data_file):\\n        #df =pd.read_csv(name)\\n        if( k > 0):\\n          df_old = df_ImgJ.copy()\\n        df_ImgJ = pd.read_excel(name)\\n        df_ImgJ = df_ImgJ.drop(labels=[0], axis=0)\\n        if(k > 0):\\n          df_ImgJ = pd.concat( [df_ImgJ, df_old], ignore_index = True)\\n        k = k + 1\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbQ0tal0etXx"
      },
      "source": [
        "#f.namelist()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSYrykxxGJ5d"
      },
      "source": [
        "#df_ImgJ.shape"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KDJn09lGTBD"
      },
      "source": [
        "#df_ImgJ.head()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc4rFvzkyWCi"
      },
      "source": [
        "from Segment_Filter_Revival import Segmenta  # got image provided segmented"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR2emP4rNjQy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0625f516-0e0f-4db2-e532-63c4225b423b"
      },
      "source": [
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MarquesGabi_Routines' already exists and is not an empty directory.\n",
            "/content/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6cMHOrlNliO"
      },
      "source": [
        "# leitura dos dados\n",
        "df=pd.read_excel(\"FotosTreinoRede.xlsx\")\n",
        "y = df['y']\n",
        "df.drop(['Unnamed: 0','y'], axis='columns', inplace=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQO8d2QbNqj0"
      },
      "source": [
        "X =np.array(df.copy())/255.0 \n",
        "\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIFPGE_-vx3T"
      },
      "source": [
        "Img_Size = 28"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23iKv6bDPWQl"
      },
      "source": [
        "# helper\n",
        "def ynindicator(Y):\n",
        "  N = len(Y)\n",
        "  K = len(set(Y))\n",
        "  I = np.zeros((N, K))\n",
        "  I[np.arange(N), Y] = 1\n",
        "  return I\n",
        "\n",
        "def yback(Y_test):\n",
        "  nrow, ncol = Y_test.shape\n",
        "  y_class = np.zeros(nrow,dtype=int)\n",
        "  y_resp = Y_test\n",
        "  for k in range(nrow):\n",
        "    for kk in range(K):\n",
        "      if(y_resp[k,kk] == 1):\n",
        "        y_class[k] = kk\n",
        "  Y_test = y_class.copy()\n",
        "  return Y_test\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train)\n",
        "K = len(set(Y_train))\n",
        "\n",
        "X_train = X_train.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "Y_train = Y_train.astype(np.int32)\n",
        "Y_train = ynindicator(Y_train)\n",
        "\n",
        "X_test = np.array(X_test )\n",
        "Y_test = np.array(Y_test)\n",
        "X_test = X_test.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "Y_test = Y_test.astype(np.int32)\n",
        "Y_test = ynindicator(Y_test)\n",
        "\n",
        "# the model will be a sequence of layers\n",
        "\n",
        "Description = '3 layers of Convolution: 64, 128, 256 '\n",
        "N1 = 20\n",
        "N2 = 20\n",
        "\n",
        "# make the CNN\n",
        "model = Sequential()\n",
        "model.add(Conv2D(input_shape=(Img_Size, Img_Size, 1), filters=64, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=N1))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=N2))\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(units=K))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "# list of losses: https://keras.io/losses/\n",
        "# list of optimizers: https://keras.io/optimizers/\n",
        "# list of metrics: https://keras.io/metrics/\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpbPQ1FSRG6A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dca3ef2-a970-4f4c-e071-154741dc297e"
      },
      "source": [
        "# training the model\n",
        "r = model.fit(X_train, Y_train, validation_data=(X_test,Y_test), \n",
        "              epochs=200, batch_size=32)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 0.5380 - accuracy: 0.7464 - val_loss: 0.6930 - val_accuracy: 0.5102\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.3594 - accuracy: 0.8280 - val_loss: 0.6929 - val_accuracy: 0.5102\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.1960 - accuracy: 0.9300 - val_loss: 0.6931 - val_accuracy: 0.5102\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.1157 - accuracy: 0.9563 - val_loss: 0.6939 - val_accuracy: 0.5102\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 0.1074 - accuracy: 0.9621 - val_loss: 0.6950 - val_accuracy: 0.5102\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 0.1196 - accuracy: 0.9446 - val_loss: 0.6945 - val_accuracy: 0.5102\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 0.0714 - accuracy: 0.9738 - val_loss: 0.6949 - val_accuracy: 0.5102\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 0.0316 - accuracy: 0.9854 - val_loss: 0.6960 - val_accuracy: 0.5102\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 0.0243 - accuracy: 0.9942 - val_loss: 0.6953 - val_accuracy: 0.5102\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 0.0290 - accuracy: 0.9883 - val_loss: 0.6975 - val_accuracy: 0.5102\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.6966 - val_accuracy: 0.5102\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 0.6945 - val_accuracy: 0.5102\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 0.0125 - accuracy: 0.9942 - val_loss: 0.6950 - val_accuracy: 0.5102\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.7006 - val_accuracy: 0.5102\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 0.7005 - val_accuracy: 0.5102\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.7004 - val_accuracy: 0.5102\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7021 - val_accuracy: 0.5102\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 0.0046 - accuracy: 0.9971 - val_loss: 0.7098 - val_accuracy: 0.5102\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 0.0212 - accuracy: 0.9913 - val_loss: 0.7057 - val_accuracy: 0.5102\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.7127 - val_accuracy: 0.5102\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.7237 - val_accuracy: 0.5102\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.7410 - val_accuracy: 0.5102\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.7327 - val_accuracy: 0.5102\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.7525 - val_accuracy: 0.5102\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7877 - val_accuracy: 0.5102\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8063 - val_accuracy: 0.5102\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8078 - val_accuracy: 0.5102\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8223 - val_accuracy: 0.5102\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7906 - val_accuracy: 0.5102\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 8.4636e-04 - accuracy: 1.0000 - val_loss: 0.7847 - val_accuracy: 0.5102\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7695 - val_accuracy: 0.5102\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0052 - accuracy: 0.9971 - val_loss: 0.7511 - val_accuracy: 0.5102\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0158 - accuracy: 0.9971 - val_loss: 1.2865 - val_accuracy: 0.5102\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.3930 - val_accuracy: 0.5102\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.9070 - val_accuracy: 0.5102\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.8889 - val_accuracy: 0.5102\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0136 - accuracy: 0.9942 - val_loss: 3.0325 - val_accuracy: 0.5102\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0394 - accuracy: 0.9913 - val_loss: 7.2647 - val_accuracy: 0.5102\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0257 - accuracy: 0.9913 - val_loss: 5.4232 - val_accuracy: 0.5102\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0343 - accuracy: 0.9825 - val_loss: 20.9592 - val_accuracy: 0.5102\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 0.0361 - accuracy: 0.9796 - val_loss: 8.8398 - val_accuracy: 0.5102\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 0.0369 - accuracy: 0.9854 - val_loss: 12.3109 - val_accuracy: 0.5102\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0105 - accuracy: 0.9971 - val_loss: 10.1280 - val_accuracy: 0.5102\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 11.7783 - val_accuracy: 0.5102\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 12.7929 - val_accuracy: 0.5102\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 12.8444 - val_accuracy: 0.5102\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 13.6492 - val_accuracy: 0.5102\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 8.0379e-04 - accuracy: 1.0000 - val_loss: 13.9600 - val_accuracy: 0.5102\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 8.3228e-04 - accuracy: 1.0000 - val_loss: 15.1393 - val_accuracy: 0.5102\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 3.9971e-04 - accuracy: 1.0000 - val_loss: 15.6039 - val_accuracy: 0.5102\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 4.6122e-04 - accuracy: 1.0000 - val_loss: 15.6218 - val_accuracy: 0.5102\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 7.7774e-04 - accuracy: 1.0000 - val_loss: 15.3678 - val_accuracy: 0.5102\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 14.4636 - val_accuracy: 0.5102\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 3.2260e-04 - accuracy: 1.0000 - val_loss: 13.3414 - val_accuracy: 0.5102\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 10.9393 - val_accuracy: 0.5102\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 10.7804 - val_accuracy: 0.5102\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 17.2593 - val_accuracy: 0.5102\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 2.1053e-04 - accuracy: 1.0000 - val_loss: 21.7779 - val_accuracy: 0.5102\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 3.1372e-04 - accuracy: 1.0000 - val_loss: 21.0843 - val_accuracy: 0.5102\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 18.9804 - val_accuracy: 0.5102\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 16.5084 - val_accuracy: 0.5102\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 2.1876e-04 - accuracy: 1.0000 - val_loss: 13.3142 - val_accuracy: 0.5102\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 3.3023e-04 - accuracy: 1.0000 - val_loss: 11.6454 - val_accuracy: 0.5102\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 12.0703 - val_accuracy: 0.5102\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 1.9445e-04 - accuracy: 1.0000 - val_loss: 12.2011 - val_accuracy: 0.5102\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 1.5310e-04 - accuracy: 1.0000 - val_loss: 11.5047 - val_accuracy: 0.5102\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 3.3242e-04 - accuracy: 1.0000 - val_loss: 10.4087 - val_accuracy: 0.5102\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 1.0218e-04 - accuracy: 1.0000 - val_loss: 9.3728 - val_accuracy: 0.5102\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 1.5190e-04 - accuracy: 1.0000 - val_loss: 8.5774 - val_accuracy: 0.5102\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 1.8684e-04 - accuracy: 1.0000 - val_loss: 7.7320 - val_accuracy: 0.5102\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 1.0959e-04 - accuracy: 1.0000 - val_loss: 7.0539 - val_accuracy: 0.5102\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 1.5781e-04 - accuracy: 1.0000 - val_loss: 6.2518 - val_accuracy: 0.5102\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 7.9090e-05 - accuracy: 1.0000 - val_loss: 5.5760 - val_accuracy: 0.5102\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 3.5560e-04 - accuracy: 1.0000 - val_loss: 4.7832 - val_accuracy: 0.5102\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 9.5380e-04 - accuracy: 1.0000 - val_loss: 3.3702 - val_accuracy: 0.5102\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 2.7603e-04 - accuracy: 1.0000 - val_loss: 2.9829 - val_accuracy: 0.5102\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 8.4005e-04 - accuracy: 1.0000 - val_loss: 2.4570 - val_accuracy: 0.5102\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 1.8283e-04 - accuracy: 1.0000 - val_loss: 2.2033 - val_accuracy: 0.5238\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 9.1494e-05 - accuracy: 1.0000 - val_loss: 1.9625 - val_accuracy: 0.5510\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 1.9088e-04 - accuracy: 1.0000 - val_loss: 2.2236 - val_accuracy: 0.5374\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 1.4493e-04 - accuracy: 1.0000 - val_loss: 2.2964 - val_accuracy: 0.5238\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 1.5474e-04 - accuracy: 1.0000 - val_loss: 1.9911 - val_accuracy: 0.5510\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 1.2769e-04 - accuracy: 1.0000 - val_loss: 1.7921 - val_accuracy: 0.5646\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 8.0317e-05 - accuracy: 1.0000 - val_loss: 1.6578 - val_accuracy: 0.6054\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 2.0491e-04 - accuracy: 1.0000 - val_loss: 1.6188 - val_accuracy: 0.6122\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 1.3269e-04 - accuracy: 1.0000 - val_loss: 1.3128 - val_accuracy: 0.6395\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 9.3066e-05 - accuracy: 1.0000 - val_loss: 1.2207 - val_accuracy: 0.6531\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 5.8415e-05 - accuracy: 1.0000 - val_loss: 1.0125 - val_accuracy: 0.6939\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 3.4674e-05 - accuracy: 1.0000 - val_loss: 0.7934 - val_accuracy: 0.7823\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 3.9267e-05 - accuracy: 1.0000 - val_loss: 0.5848 - val_accuracy: 0.8231\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 1.0550e-04 - accuracy: 1.0000 - val_loss: 0.4102 - val_accuracy: 0.8912\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 7.6621e-05 - accuracy: 1.0000 - val_loss: 0.3437 - val_accuracy: 0.8980\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 6.1335e-05 - accuracy: 1.0000 - val_loss: 0.3703 - val_accuracy: 0.8980\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 8.2908e-05 - accuracy: 1.0000 - val_loss: 0.4181 - val_accuracy: 0.8912\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 1.1766e-04 - accuracy: 1.0000 - val_loss: 0.6777 - val_accuracy: 0.8231\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 1.1560e-04 - accuracy: 1.0000 - val_loss: 1.2905 - val_accuracy: 0.6939\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 7.8113e-05 - accuracy: 1.0000 - val_loss: 1.4846 - val_accuracy: 0.6667\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 6.4189e-05 - accuracy: 1.0000 - val_loss: 2.0420 - val_accuracy: 0.6122\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 9.3445e-05 - accuracy: 1.0000 - val_loss: 2.4038 - val_accuracy: 0.5782\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 3.6384e-05 - accuracy: 1.0000 - val_loss: 2.2439 - val_accuracy: 0.6054\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 3.3709e-05 - accuracy: 1.0000 - val_loss: 1.9667 - val_accuracy: 0.6395\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 1.4758e-04 - accuracy: 1.0000 - val_loss: 1.3840 - val_accuracy: 0.6871\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 1.3814e-04 - accuracy: 1.0000 - val_loss: 0.6816 - val_accuracy: 0.8163\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 2.4351e-04 - accuracy: 1.0000 - val_loss: 3.3851 - val_accuracy: 0.5170\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 1.8066e-04 - accuracy: 1.0000 - val_loss: 11.5354 - val_accuracy: 0.5102\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 6.4735e-04 - accuracy: 1.0000 - val_loss: 12.2380 - val_accuracy: 0.5102\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 1.6447e-04 - accuracy: 1.0000 - val_loss: 11.2304 - val_accuracy: 0.5102\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 4.7267e-04 - accuracy: 1.0000 - val_loss: 16.6680 - val_accuracy: 0.5102\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 7.5278e-05 - accuracy: 1.0000 - val_loss: 17.9879 - val_accuracy: 0.5102\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 17.6964 - val_accuracy: 0.5102\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 1.4471e-04 - accuracy: 1.0000 - val_loss: 15.1226 - val_accuracy: 0.5102\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 7.5076e-05 - accuracy: 1.0000 - val_loss: 13.8051 - val_accuracy: 0.5102\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 2.7936e-04 - accuracy: 1.0000 - val_loss: 12.9201 - val_accuracy: 0.5102\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 4.4639e-05 - accuracy: 1.0000 - val_loss: 11.2873 - val_accuracy: 0.5102\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 2.9555e-04 - accuracy: 1.0000 - val_loss: 6.8634 - val_accuracy: 0.5102\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 6.5669e-05 - accuracy: 1.0000 - val_loss: 3.4874 - val_accuracy: 0.5170\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 4.3584e-05 - accuracy: 1.0000 - val_loss: 2.0026 - val_accuracy: 0.6259\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 1.1156e-04 - accuracy: 1.0000 - val_loss: 1.2558 - val_accuracy: 0.7483\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 7.9796e-05 - accuracy: 1.0000 - val_loss: 1.7253 - val_accuracy: 0.6599\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 5.2799e-05 - accuracy: 1.0000 - val_loss: 1.7302 - val_accuracy: 0.6735\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 5.1758e-05 - accuracy: 1.0000 - val_loss: 1.5641 - val_accuracy: 0.6871\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 9.9617e-05 - accuracy: 1.0000 - val_loss: 1.2763 - val_accuracy: 0.7619\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 9.0538e-04 - accuracy: 1.0000 - val_loss: 1.8701 - val_accuracy: 0.6531\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 3.1957e-04 - accuracy: 1.0000 - val_loss: 10.9439 - val_accuracy: 0.5102\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 0.0253 - accuracy: 0.9913 - val_loss: 8.4097 - val_accuracy: 0.5102\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 0.0668 - accuracy: 0.9738 - val_loss: 104.8617 - val_accuracy: 0.5102\n",
            "Epoch 127/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 0.0448 - accuracy: 0.9796 - val_loss: 593.2986 - val_accuracy: 0.5102\n",
            "Epoch 128/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 0.0276 - accuracy: 0.9883 - val_loss: 1030.3630 - val_accuracy: 0.5102\n",
            "Epoch 129/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 0.0607 - accuracy: 0.9767 - val_loss: 994.2860 - val_accuracy: 0.5102\n",
            "Epoch 130/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 0.0607 - accuracy: 0.9767 - val_loss: 889.9538 - val_accuracy: 0.5102\n",
            "Epoch 131/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 0.0210 - accuracy: 0.9942 - val_loss: 719.8917 - val_accuracy: 0.5102\n",
            "Epoch 132/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 0.0098 - accuracy: 0.9971 - val_loss: 630.1232 - val_accuracy: 0.5102\n",
            "Epoch 133/200\n",
            "11/11 [==============================] - 2s 150ms/step - loss: 0.0049 - accuracy: 0.9971 - val_loss: 514.7359 - val_accuracy: 0.5102\n",
            "Epoch 134/200\n",
            "11/11 [==============================] - 2s 146ms/step - loss: 0.0075 - accuracy: 0.9971 - val_loss: 406.0821 - val_accuracy: 0.5102\n",
            "Epoch 135/200\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 0.0055 - accuracy: 0.9971 - val_loss: 73.3743 - val_accuracy: 0.5102\n",
            "Epoch 136/200\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 18.6868 - val_accuracy: 0.4898\n",
            "Epoch 137/200\n",
            "11/11 [==============================] - 2s 147ms/step - loss: 0.0143 - accuracy: 0.9942 - val_loss: 167.8487 - val_accuracy: 0.5102\n",
            "Epoch 138/200\n",
            "11/11 [==============================] - 2s 150ms/step - loss: 0.0216 - accuracy: 0.9913 - val_loss: 7.8964 - val_accuracy: 0.5102\n",
            "Epoch 139/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 0.0993 - accuracy: 0.9854 - val_loss: 28.3872 - val_accuracy: 0.5102\n",
            "Epoch 140/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 0.0444 - accuracy: 0.9825 - val_loss: 55.4520 - val_accuracy: 0.5102\n",
            "Epoch 141/200\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.0125 - accuracy: 0.9913 - val_loss: 39.3705 - val_accuracy: 0.5102\n",
            "Epoch 142/200\n",
            "11/11 [==============================] - 2s 148ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 44.0988 - val_accuracy: 0.5102\n",
            "Epoch 143/200\n",
            "11/11 [==============================] - 2s 167ms/step - loss: 0.0039 - accuracy: 0.9971 - val_loss: 43.7126 - val_accuracy: 0.5102\n",
            "Epoch 144/200\n",
            "11/11 [==============================] - 2s 162ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 41.7641 - val_accuracy: 0.5102\n",
            "Epoch 145/200\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 7.2370e-04 - accuracy: 1.0000 - val_loss: 35.5390 - val_accuracy: 0.5102\n",
            "Epoch 146/200\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 34.5164 - val_accuracy: 0.5102\n",
            "Epoch 147/200\n",
            "11/11 [==============================] - 2s 157ms/step - loss: 0.0052 - accuracy: 0.9971 - val_loss: 45.5074 - val_accuracy: 0.5102\n",
            "Epoch 148/200\n",
            "11/11 [==============================] - 2s 158ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 61.1736 - val_accuracy: 0.5102\n",
            "Epoch 149/200\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 25.1846 - val_accuracy: 0.5102\n",
            "Epoch 150/200\n",
            "11/11 [==============================] - 2s 150ms/step - loss: 3.7547e-04 - accuracy: 1.0000 - val_loss: 18.3517 - val_accuracy: 0.5102\n",
            "Epoch 151/200\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 8.8027e-04 - accuracy: 1.0000 - val_loss: 15.6404 - val_accuracy: 0.5102\n",
            "Epoch 152/200\n",
            "11/11 [==============================] - 2s 157ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 11.7828 - val_accuracy: 0.5102\n",
            "Epoch 153/200\n",
            "11/11 [==============================] - 2s 158ms/step - loss: 1.3163e-04 - accuracy: 1.0000 - val_loss: 11.2972 - val_accuracy: 0.5102\n",
            "Epoch 154/200\n",
            "11/11 [==============================] - 2s 158ms/step - loss: 6.5425e-04 - accuracy: 1.0000 - val_loss: 11.6379 - val_accuracy: 0.5102\n",
            "Epoch 155/200\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 14.1344 - val_accuracy: 0.5102\n",
            "Epoch 156/200\n",
            "11/11 [==============================] - 2s 167ms/step - loss: 2.1641e-04 - accuracy: 1.0000 - val_loss: 8.2366 - val_accuracy: 0.5102\n",
            "Epoch 157/200\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 5.4224e-04 - accuracy: 1.0000 - val_loss: 7.7155 - val_accuracy: 0.5102\n",
            "Epoch 158/200\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.0065 - accuracy: 0.9971 - val_loss: 12.9268 - val_accuracy: 0.5102\n",
            "Epoch 159/200\n",
            "11/11 [==============================] - 2s 158ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5433 - val_accuracy: 0.7415\n",
            "Epoch 160/200\n",
            "11/11 [==============================] - 2s 167ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.9749 - val_accuracy: 0.5442\n",
            "Epoch 161/200\n",
            "11/11 [==============================] - 2s 157ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.2870 - val_accuracy: 0.6054\n",
            "Epoch 162/200\n",
            "11/11 [==============================] - 2s 158ms/step - loss: 5.1500e-04 - accuracy: 1.0000 - val_loss: 0.9688 - val_accuracy: 0.6735\n",
            "Epoch 163/200\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 3.8533e-04 - accuracy: 1.0000 - val_loss: 0.9503 - val_accuracy: 0.6667\n",
            "Epoch 164/200\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 3.3650e-04 - accuracy: 1.0000 - val_loss: 0.5086 - val_accuracy: 0.7687\n",
            "Epoch 165/200\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 4.1477e-05 - accuracy: 1.0000 - val_loss: 0.2091 - val_accuracy: 0.9184\n",
            "Epoch 166/200\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 1.1062e-04 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.8912\n",
            "Epoch 167/200\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 7.3918e-05 - accuracy: 1.0000 - val_loss: 0.2549 - val_accuracy: 0.8980\n",
            "Epoch 168/200\n",
            "11/11 [==============================] - 2s 161ms/step - loss: 2.3518e-04 - accuracy: 1.0000 - val_loss: 0.2670 - val_accuracy: 0.8912\n",
            "Epoch 169/200\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 9.4057e-05 - accuracy: 1.0000 - val_loss: 0.2809 - val_accuracy: 0.8707\n",
            "Epoch 170/200\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 1.7457e-04 - accuracy: 1.0000 - val_loss: 0.2842 - val_accuracy: 0.8776\n",
            "Epoch 171/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 1.4144e-04 - accuracy: 1.0000 - val_loss: 0.2781 - val_accuracy: 0.8776\n",
            "Epoch 172/200\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 1.2042e-04 - accuracy: 1.0000 - val_loss: 0.2605 - val_accuracy: 0.9048\n",
            "Epoch 173/200\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 8.2822e-05 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9048\n",
            "Epoch 174/200\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 6.0936e-05 - accuracy: 1.0000 - val_loss: 0.2246 - val_accuracy: 0.9116\n",
            "Epoch 175/200\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 3.1367e-05 - accuracy: 1.0000 - val_loss: 0.2106 - val_accuracy: 0.9252\n",
            "Epoch 176/200\n",
            "11/11 [==============================] - 2s 162ms/step - loss: 0.0042 - accuracy: 0.9971 - val_loss: 0.1378 - val_accuracy: 0.9456\n",
            "Epoch 177/200\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 1.1274e-04 - accuracy: 1.0000 - val_loss: 0.2514 - val_accuracy: 0.8844\n",
            "Epoch 178/200\n",
            "11/11 [==============================] - 2s 162ms/step - loss: 6.6561e-04 - accuracy: 1.0000 - val_loss: 0.1366 - val_accuracy: 0.9524\n",
            "Epoch 179/200\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 1.9462e-04 - accuracy: 1.0000 - val_loss: 0.1423 - val_accuracy: 0.9592\n",
            "Epoch 180/200\n",
            "11/11 [==============================] - 2s 168ms/step - loss: 1.1263e-04 - accuracy: 1.0000 - val_loss: 0.1524 - val_accuracy: 0.9456\n",
            "Epoch 181/200\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 1.6240e-04 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9116\n",
            "Epoch 182/200\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0303 - val_accuracy: 0.5850\n",
            "Epoch 183/200\n",
            "11/11 [==============================] - 2s 160ms/step - loss: 2.2937e-04 - accuracy: 1.0000 - val_loss: 3.8355 - val_accuracy: 0.5306\n",
            "Epoch 184/200\n",
            "11/11 [==============================] - 2s 158ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4154 - val_accuracy: 0.8299\n",
            "Epoch 185/200\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 8.9811e-05 - accuracy: 1.0000 - val_loss: 20.3746 - val_accuracy: 0.5102\n",
            "Epoch 186/200\n",
            "11/11 [==============================] - 2s 157ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 32.9687 - val_accuracy: 0.5102\n",
            "Epoch 187/200\n",
            "11/11 [==============================] - 2s 163ms/step - loss: 0.0072 - accuracy: 0.9971 - val_loss: 37.3853 - val_accuracy: 0.5102\n",
            "Epoch 188/200\n",
            "11/11 [==============================] - 2s 164ms/step - loss: 3.6928e-04 - accuracy: 1.0000 - val_loss: 7.9409 - val_accuracy: 0.5102\n",
            "Epoch 189/200\n",
            "11/11 [==============================] - 2s 157ms/step - loss: 0.0042 - accuracy: 0.9971 - val_loss: 11.4653 - val_accuracy: 0.5102\n",
            "Epoch 190/200\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 1.9395e-04 - accuracy: 1.0000 - val_loss: 17.8562 - val_accuracy: 0.5102\n",
            "Epoch 191/200\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.0046 - accuracy: 0.9971 - val_loss: 13.2688 - val_accuracy: 0.5102\n",
            "Epoch 192/200\n",
            "11/11 [==============================] - 2s 150ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 7.9764 - val_accuracy: 0.5102\n",
            "Epoch 193/200\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 20.9077 - val_accuracy: 0.5102\n",
            "Epoch 194/200\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 9.4638e-04 - accuracy: 1.0000 - val_loss: 26.0336 - val_accuracy: 0.5102\n",
            "Epoch 195/200\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 4.3371e-04 - accuracy: 1.0000 - val_loss: 24.4061 - val_accuracy: 0.5102\n",
            "Epoch 196/200\n",
            "11/11 [==============================] - 2s 146ms/step - loss: 4.8376e-04 - accuracy: 1.0000 - val_loss: 20.1637 - val_accuracy: 0.5102\n",
            "Epoch 197/200\n",
            "11/11 [==============================] - 2s 147ms/step - loss: 1.7882e-04 - accuracy: 1.0000 - val_loss: 18.2324 - val_accuracy: 0.5102\n",
            "Epoch 198/200\n",
            "11/11 [==============================] - 2s 148ms/step - loss: 6.6850e-04 - accuracy: 1.0000 - val_loss: 25.8415 - val_accuracy: 0.5102\n",
            "Epoch 199/200\n",
            "11/11 [==============================] - 2s 145ms/step - loss: 1.5001e-04 - accuracy: 1.0000 - val_loss: 26.4391 - val_accuracy: 0.5102\n",
            "Epoch 200/200\n",
            "11/11 [==============================] - 2s 146ms/step - loss: 3.5257e-05 - accuracy: 1.0000 - val_loss: 24.0737 - val_accuracy: 0.5102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSTlOSUBWMpj"
      },
      "source": [
        "Y_test = yback(Y_test)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDVY6HbxMOlH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c553cf2-9442-4635-e024-8191e18e0f1e"
      },
      "source": [
        "# pred_test= model.predict_classes(X_test)\n",
        "pred_test = np.argmax(model.predict(X_test), axis=-1)\n",
        "\n",
        "data = {'y_true': Y_test,'y_predict': pred_test}  # este dado esta no formato de dicionario\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_true','y_predict'])\n",
        "\n",
        "\n",
        "confusion_matrix = pd.crosstab(df['y_true'], df['y_predict'], rownames=['Actual'], colnames=['Predict'])\n",
        "print(confusion_matrix)\n",
        "\n",
        "y_true = df['y_true']\n",
        "y_pred = df['y_predict']\n",
        "\n",
        "  \n",
        "METRICS=sklearn.metrics.classification_report(y_true, y_pred)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predict   1\n",
            "Actual     \n",
            "0        72\n",
            "1        75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7pT2q7traXg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae463017-46f4-46e4-c718-700f9da67c7c"
      },
      "source": [
        "print(METRICS)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        72\n",
            "           1       0.51      1.00      0.68        75\n",
            "\n",
            "    accuracy                           0.51       147\n",
            "   macro avg       0.26      0.50      0.34       147\n",
            "weighted avg       0.26      0.51      0.34       147\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iFNNrlWV9tH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54774646-1d47-4e54-c3ce-1d2ac5345d4a"
      },
      "source": [
        "pred_test"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5pq5z8DHeJ0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f5870634-8c70-4b4d-f9c2-1b31a37b0803"
      },
      "source": [
        "'''\n",
        "img=ww[4] \n",
        "df=Segmenta(img)\n",
        "df.shape\n",
        "'''"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nimg=ww[4] \\ndf=Segmenta(img)\\ndf.shape\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8ofkAXlS-0F"
      },
      "source": [
        "Sample3 =[2, 5, 17] # \n",
        "# [2, 5, 17] sample 7---  [4,13,25] sample 3----[0, 3, 9] sample 8\n",
        "\n",
        "for i in range(Repetir):\n",
        "  k = 0\n",
        "  for i in Sample3:\n",
        "    img=ww[i]\n",
        "    if( k > 0):\n",
        "      df_old = df_ann.copy()\n",
        "    df_ann=Segmenta(img)\n",
        "    if(k > 0):\n",
        "      df_ann = pd.concat( [df_ann, df_old], ignore_index = True)\n",
        "    k = k + 1\n",
        "#df_ann = df.copy\n",
        "\n",
        "df_teste = np.array(df_ann)\n",
        "names = df_ann.columns\n",
        "df_teste = pd.DataFrame(df_teste,columns=names)\n",
        "Width = df_ann['Width']\n",
        "#del df_ann['Width']\n",
        "names = df_ann.columns\n",
        "del df_ann['Width']\n",
        "result = np.array(df_ann)\n",
        "result = result.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "prediction= np.argmax(model.predict(result), axis=-1)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kfx72YkUYiz",
        "outputId": "e98deb3a-6c8d-438b-db03-085481bee52e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "source": [
        "df_ann"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "      <th>769</th>\n",
              "      <th>770</th>\n",
              "      <th>771</th>\n",
              "      <th>772</th>\n",
              "      <th>773</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>174.002792</td>\n",
              "      <td>148.457993</td>\n",
              "      <td>138.614594</td>\n",
              "      <td>125.384926</td>\n",
              "      <td>120.971611</td>\n",
              "      <td>118.701012</td>\n",
              "      <td>116.145355</td>\n",
              "      <td>111.940567</td>\n",
              "      <td>140.646042</td>\n",
              "      <td>174.846130</td>\n",
              "      <td>180.528809</td>\n",
              "      <td>174.460144</td>\n",
              "      <td>172.223618</td>\n",
              "      <td>175.349670</td>\n",
              "      <td>178.146698</td>\n",
              "      <td>178.890030</td>\n",
              "      <td>181.424240</td>\n",
              "      <td>186.851562</td>\n",
              "      <td>193.522369</td>\n",
              "      <td>200.381729</td>\n",
              "      <td>207.017456</td>\n",
              "      <td>210.066330</td>\n",
              "      <td>207.203369</td>\n",
              "      <td>201.292358</td>\n",
              "      <td>184.902267</td>\n",
              "      <td>168.324493</td>\n",
              "      <td>141.712967</td>\n",
              "      <td>126.683067</td>\n",
              "      <td>171.634521</td>\n",
              "      <td>167.965820</td>\n",
              "      <td>164.353729</td>\n",
              "      <td>156.657120</td>\n",
              "      <td>133.760117</td>\n",
              "      <td>117.508095</td>\n",
              "      <td>118.085075</td>\n",
              "      <td>114.871635</td>\n",
              "      <td>120.308487</td>\n",
              "      <td>155.705063</td>\n",
              "      <td>172.954453</td>\n",
              "      <td>173.682831</td>\n",
              "      <td>...</td>\n",
              "      <td>163.029541</td>\n",
              "      <td>165.442856</td>\n",
              "      <td>173.554428</td>\n",
              "      <td>174.472366</td>\n",
              "      <td>171.192581</td>\n",
              "      <td>168.052582</td>\n",
              "      <td>165.559433</td>\n",
              "      <td>161.442505</td>\n",
              "      <td>157.856995</td>\n",
              "      <td>153.647827</td>\n",
              "      <td>141.175751</td>\n",
              "      <td>130.731842</td>\n",
              "      <td>131.728073</td>\n",
              "      <td>135.467850</td>\n",
              "      <td>141.581818</td>\n",
              "      <td>149.125488</td>\n",
              "      <td>153.673141</td>\n",
              "      <td>153.743073</td>\n",
              "      <td>154.937759</td>\n",
              "      <td>154.577835</td>\n",
              "      <td>149.141312</td>\n",
              "      <td>152.203156</td>\n",
              "      <td>155.326385</td>\n",
              "      <td>158.661377</td>\n",
              "      <td>158.427689</td>\n",
              "      <td>158.701294</td>\n",
              "      <td>162.752213</td>\n",
              "      <td>164.001663</td>\n",
              "      <td>162.454605</td>\n",
              "      <td>158.308289</td>\n",
              "      <td>153.472641</td>\n",
              "      <td>137.647659</td>\n",
              "      <td>116.276520</td>\n",
              "      <td>125.177574</td>\n",
              "      <td>134.653992</td>\n",
              "      <td>139.716339</td>\n",
              "      <td>137.266449</td>\n",
              "      <td>127.010803</td>\n",
              "      <td>117.221016</td>\n",
              "      <td>112.785301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>155.358932</td>\n",
              "      <td>160.961517</td>\n",
              "      <td>159.506638</td>\n",
              "      <td>151.296295</td>\n",
              "      <td>141.695633</td>\n",
              "      <td>128.138504</td>\n",
              "      <td>118.093811</td>\n",
              "      <td>130.761658</td>\n",
              "      <td>132.531891</td>\n",
              "      <td>129.297455</td>\n",
              "      <td>126.819229</td>\n",
              "      <td>127.355522</td>\n",
              "      <td>132.373322</td>\n",
              "      <td>134.686676</td>\n",
              "      <td>134.070328</td>\n",
              "      <td>135.798141</td>\n",
              "      <td>140.351105</td>\n",
              "      <td>137.767075</td>\n",
              "      <td>128.642471</td>\n",
              "      <td>103.927925</td>\n",
              "      <td>89.006317</td>\n",
              "      <td>91.321678</td>\n",
              "      <td>93.131294</td>\n",
              "      <td>89.726936</td>\n",
              "      <td>114.258682</td>\n",
              "      <td>143.377243</td>\n",
              "      <td>150.135086</td>\n",
              "      <td>148.180527</td>\n",
              "      <td>158.399948</td>\n",
              "      <td>160.327255</td>\n",
              "      <td>159.430649</td>\n",
              "      <td>161.267029</td>\n",
              "      <td>163.476471</td>\n",
              "      <td>163.483276</td>\n",
              "      <td>155.424454</td>\n",
              "      <td>140.494766</td>\n",
              "      <td>128.891449</td>\n",
              "      <td>126.029663</td>\n",
              "      <td>126.198090</td>\n",
              "      <td>127.881729</td>\n",
              "      <td>...</td>\n",
              "      <td>153.852417</td>\n",
              "      <td>154.010483</td>\n",
              "      <td>147.893967</td>\n",
              "      <td>144.841599</td>\n",
              "      <td>145.816696</td>\n",
              "      <td>146.118439</td>\n",
              "      <td>148.300354</td>\n",
              "      <td>150.802307</td>\n",
              "      <td>156.986252</td>\n",
              "      <td>158.639832</td>\n",
              "      <td>159.691330</td>\n",
              "      <td>141.402496</td>\n",
              "      <td>141.353119</td>\n",
              "      <td>143.604095</td>\n",
              "      <td>144.036377</td>\n",
              "      <td>143.977539</td>\n",
              "      <td>144.690338</td>\n",
              "      <td>146.747147</td>\n",
              "      <td>145.906845</td>\n",
              "      <td>143.048615</td>\n",
              "      <td>138.960632</td>\n",
              "      <td>124.440231</td>\n",
              "      <td>110.482780</td>\n",
              "      <td>114.528984</td>\n",
              "      <td>133.402374</td>\n",
              "      <td>141.143799</td>\n",
              "      <td>143.843719</td>\n",
              "      <td>148.623169</td>\n",
              "      <td>157.091675</td>\n",
              "      <td>157.000763</td>\n",
              "      <td>150.332291</td>\n",
              "      <td>153.832596</td>\n",
              "      <td>156.045456</td>\n",
              "      <td>147.661911</td>\n",
              "      <td>145.052277</td>\n",
              "      <td>150.370544</td>\n",
              "      <td>155.314240</td>\n",
              "      <td>159.090775</td>\n",
              "      <td>162.827057</td>\n",
              "      <td>136.528595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>195.583267</td>\n",
              "      <td>204.749161</td>\n",
              "      <td>215.725769</td>\n",
              "      <td>219.451218</td>\n",
              "      <td>222.041229</td>\n",
              "      <td>223.955048</td>\n",
              "      <td>223.087128</td>\n",
              "      <td>219.036011</td>\n",
              "      <td>209.330261</td>\n",
              "      <td>184.635880</td>\n",
              "      <td>149.031387</td>\n",
              "      <td>122.441673</td>\n",
              "      <td>114.123734</td>\n",
              "      <td>112.783012</td>\n",
              "      <td>113.279167</td>\n",
              "      <td>110.272087</td>\n",
              "      <td>107.463837</td>\n",
              "      <td>106.948593</td>\n",
              "      <td>106.934135</td>\n",
              "      <td>104.865799</td>\n",
              "      <td>101.261612</td>\n",
              "      <td>99.784248</td>\n",
              "      <td>94.296707</td>\n",
              "      <td>89.276085</td>\n",
              "      <td>86.950760</td>\n",
              "      <td>86.318558</td>\n",
              "      <td>80.214836</td>\n",
              "      <td>77.631271</td>\n",
              "      <td>193.364716</td>\n",
              "      <td>199.561096</td>\n",
              "      <td>209.016617</td>\n",
              "      <td>216.788864</td>\n",
              "      <td>220.009216</td>\n",
              "      <td>221.803635</td>\n",
              "      <td>219.995682</td>\n",
              "      <td>182.395828</td>\n",
              "      <td>139.814087</td>\n",
              "      <td>117.186829</td>\n",
              "      <td>109.084328</td>\n",
              "      <td>110.094482</td>\n",
              "      <td>...</td>\n",
              "      <td>141.267471</td>\n",
              "      <td>139.497070</td>\n",
              "      <td>138.149277</td>\n",
              "      <td>137.602661</td>\n",
              "      <td>139.632507</td>\n",
              "      <td>144.701141</td>\n",
              "      <td>145.970154</td>\n",
              "      <td>144.968597</td>\n",
              "      <td>142.821472</td>\n",
              "      <td>140.727310</td>\n",
              "      <td>137.777466</td>\n",
              "      <td>138.343796</td>\n",
              "      <td>126.987076</td>\n",
              "      <td>126.904594</td>\n",
              "      <td>122.310257</td>\n",
              "      <td>120.520775</td>\n",
              "      <td>131.304703</td>\n",
              "      <td>143.293640</td>\n",
              "      <td>148.684525</td>\n",
              "      <td>149.482300</td>\n",
              "      <td>146.701767</td>\n",
              "      <td>144.324402</td>\n",
              "      <td>143.048019</td>\n",
              "      <td>142.209595</td>\n",
              "      <td>141.724533</td>\n",
              "      <td>141.129883</td>\n",
              "      <td>141.375809</td>\n",
              "      <td>140.132965</td>\n",
              "      <td>138.859955</td>\n",
              "      <td>137.322250</td>\n",
              "      <td>135.422897</td>\n",
              "      <td>134.793793</td>\n",
              "      <td>137.239151</td>\n",
              "      <td>142.326263</td>\n",
              "      <td>143.750381</td>\n",
              "      <td>142.849808</td>\n",
              "      <td>141.418579</td>\n",
              "      <td>140.389343</td>\n",
              "      <td>139.654968</td>\n",
              "      <td>137.690063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>118.147942</td>\n",
              "      <td>109.213028</td>\n",
              "      <td>100.142029</td>\n",
              "      <td>125.964508</td>\n",
              "      <td>133.899429</td>\n",
              "      <td>134.207123</td>\n",
              "      <td>134.201202</td>\n",
              "      <td>129.372787</td>\n",
              "      <td>128.390533</td>\n",
              "      <td>126.615395</td>\n",
              "      <td>126.005928</td>\n",
              "      <td>118.881660</td>\n",
              "      <td>114.485222</td>\n",
              "      <td>113.396454</td>\n",
              "      <td>113.408287</td>\n",
              "      <td>112.177521</td>\n",
              "      <td>112.029594</td>\n",
              "      <td>115.106522</td>\n",
              "      <td>124.366867</td>\n",
              "      <td>128.733749</td>\n",
              "      <td>123.727821</td>\n",
              "      <td>109.609482</td>\n",
              "      <td>105.964508</td>\n",
              "      <td>104.710068</td>\n",
              "      <td>102.644981</td>\n",
              "      <td>100.171600</td>\n",
              "      <td>99.639069</td>\n",
              "      <td>101.840240</td>\n",
              "      <td>112.147942</td>\n",
              "      <td>112.065102</td>\n",
              "      <td>107.893501</td>\n",
              "      <td>123.538467</td>\n",
              "      <td>132.869843</td>\n",
              "      <td>135.473389</td>\n",
              "      <td>135.029602</td>\n",
              "      <td>129.183441</td>\n",
              "      <td>128.615387</td>\n",
              "      <td>125.869827</td>\n",
              "      <td>126.301788</td>\n",
              "      <td>123.011848</td>\n",
              "      <td>...</td>\n",
              "      <td>119.538475</td>\n",
              "      <td>120.461555</td>\n",
              "      <td>124.745575</td>\n",
              "      <td>133.810669</td>\n",
              "      <td>146.094681</td>\n",
              "      <td>153.656815</td>\n",
              "      <td>171.455627</td>\n",
              "      <td>173.621323</td>\n",
              "      <td>136.094696</td>\n",
              "      <td>128.520721</td>\n",
              "      <td>130.029587</td>\n",
              "      <td>123.816589</td>\n",
              "      <td>118.041428</td>\n",
              "      <td>118.242615</td>\n",
              "      <td>117.745575</td>\n",
              "      <td>113.177521</td>\n",
              "      <td>111.307693</td>\n",
              "      <td>118.159775</td>\n",
              "      <td>130.686401</td>\n",
              "      <td>132.000015</td>\n",
              "      <td>126.408295</td>\n",
              "      <td>121.733742</td>\n",
              "      <td>121.798828</td>\n",
              "      <td>120.757408</td>\n",
              "      <td>116.284027</td>\n",
              "      <td>110.627228</td>\n",
              "      <td>109.023682</td>\n",
              "      <td>108.609467</td>\n",
              "      <td>112.153854</td>\n",
              "      <td>113.905334</td>\n",
              "      <td>119.349121</td>\n",
              "      <td>122.189369</td>\n",
              "      <td>125.053268</td>\n",
              "      <td>138.556229</td>\n",
              "      <td>159.514801</td>\n",
              "      <td>161.893494</td>\n",
              "      <td>139.171600</td>\n",
              "      <td>133.372803</td>\n",
              "      <td>131.011841</td>\n",
              "      <td>127.686394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>89.959732</td>\n",
              "      <td>91.367691</td>\n",
              "      <td>92.094627</td>\n",
              "      <td>93.921097</td>\n",
              "      <td>89.813759</td>\n",
              "      <td>57.291534</td>\n",
              "      <td>8.609522</td>\n",
              "      <td>2.453586</td>\n",
              "      <td>1.158033</td>\n",
              "      <td>0.383253</td>\n",
              "      <td>0.323175</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>99.899605</td>\n",
              "      <td>109.966408</td>\n",
              "      <td>112.869957</td>\n",
              "      <td>110.598976</td>\n",
              "      <td>111.596916</td>\n",
              "      <td>112.474380</td>\n",
              "      <td>110.715324</td>\n",
              "      <td>107.359352</td>\n",
              "      <td>99.924187</td>\n",
              "      <td>96.736717</td>\n",
              "      <td>94.357857</td>\n",
              "      <td>95.512291</td>\n",
              "      <td>99.032097</td>\n",
              "      <td>104.358406</td>\n",
              "      <td>107.848564</td>\n",
              "      <td>110.329330</td>\n",
              "      <td>112.649658</td>\n",
              "      <td>113.353348</td>\n",
              "      <td>108.739716</td>\n",
              "      <td>95.458801</td>\n",
              "      <td>85.249199</td>\n",
              "      <td>73.449615</td>\n",
              "      <td>59.403267</td>\n",
              "      <td>57.202103</td>\n",
              "      <td>53.442860</td>\n",
              "      <td>42.469692</td>\n",
              "      <td>10.412273</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>103.725464</td>\n",
              "      <td>110.635193</td>\n",
              "      <td>109.793205</td>\n",
              "      <td>110.166634</td>\n",
              "      <td>112.667290</td>\n",
              "      <td>112.364799</td>\n",
              "      <td>109.825104</td>\n",
              "      <td>105.840118</td>\n",
              "      <td>98.853065</td>\n",
              "      <td>96.915375</td>\n",
              "      <td>94.796951</td>\n",
              "      <td>95.365921</td>\n",
              "      <td>...</td>\n",
              "      <td>95.400452</td>\n",
              "      <td>98.234001</td>\n",
              "      <td>101.034531</td>\n",
              "      <td>105.750229</td>\n",
              "      <td>112.467812</td>\n",
              "      <td>114.272659</td>\n",
              "      <td>114.872391</td>\n",
              "      <td>115.404572</td>\n",
              "      <td>106.973351</td>\n",
              "      <td>97.609871</td>\n",
              "      <td>92.128349</td>\n",
              "      <td>92.443604</td>\n",
              "      <td>88.071487</td>\n",
              "      <td>95.796768</td>\n",
              "      <td>100.234947</td>\n",
              "      <td>101.583023</td>\n",
              "      <td>106.666351</td>\n",
              "      <td>112.754547</td>\n",
              "      <td>119.636520</td>\n",
              "      <td>125.738228</td>\n",
              "      <td>129.278290</td>\n",
              "      <td>136.373413</td>\n",
              "      <td>142.952148</td>\n",
              "      <td>152.401184</td>\n",
              "      <td>163.282410</td>\n",
              "      <td>172.503662</td>\n",
              "      <td>178.484695</td>\n",
              "      <td>174.661469</td>\n",
              "      <td>141.404205</td>\n",
              "      <td>100.017822</td>\n",
              "      <td>99.651154</td>\n",
              "      <td>94.840126</td>\n",
              "      <td>105.911995</td>\n",
              "      <td>111.896980</td>\n",
              "      <td>113.153496</td>\n",
              "      <td>105.982170</td>\n",
              "      <td>89.740097</td>\n",
              "      <td>83.869202</td>\n",
              "      <td>89.333076</td>\n",
              "      <td>91.406265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>100.198097</td>\n",
              "      <td>93.689453</td>\n",
              "      <td>96.166962</td>\n",
              "      <td>95.760391</td>\n",
              "      <td>96.678200</td>\n",
              "      <td>93.897064</td>\n",
              "      <td>83.384087</td>\n",
              "      <td>78.914360</td>\n",
              "      <td>76.758659</td>\n",
              "      <td>76.876297</td>\n",
              "      <td>76.980110</td>\n",
              "      <td>74.313156</td>\n",
              "      <td>73.788925</td>\n",
              "      <td>73.217995</td>\n",
              "      <td>76.039795</td>\n",
              "      <td>79.715401</td>\n",
              "      <td>80.968857</td>\n",
              "      <td>81.650528</td>\n",
              "      <td>82.702423</td>\n",
              "      <td>82.705017</td>\n",
              "      <td>83.290657</td>\n",
              "      <td>79.450699</td>\n",
              "      <td>57.776821</td>\n",
              "      <td>25.395330</td>\n",
              "      <td>38.198101</td>\n",
              "      <td>79.474052</td>\n",
              "      <td>95.634079</td>\n",
              "      <td>93.882362</td>\n",
              "      <td>110.778549</td>\n",
              "      <td>110.284615</td>\n",
              "      <td>111.582191</td>\n",
              "      <td>112.169548</td>\n",
              "      <td>112.443779</td>\n",
              "      <td>111.240494</td>\n",
              "      <td>103.396194</td>\n",
              "      <td>83.159180</td>\n",
              "      <td>76.699837</td>\n",
              "      <td>78.099487</td>\n",
              "      <td>78.891869</td>\n",
              "      <td>77.539803</td>\n",
              "      <td>...</td>\n",
              "      <td>103.519905</td>\n",
              "      <td>97.680809</td>\n",
              "      <td>93.756058</td>\n",
              "      <td>104.778549</td>\n",
              "      <td>112.820076</td>\n",
              "      <td>109.441177</td>\n",
              "      <td>87.096024</td>\n",
              "      <td>71.106407</td>\n",
              "      <td>64.750870</td>\n",
              "      <td>64.423874</td>\n",
              "      <td>66.124573</td>\n",
              "      <td>65.859863</td>\n",
              "      <td>127.801041</td>\n",
              "      <td>128.544983</td>\n",
              "      <td>130.675613</td>\n",
              "      <td>133.247421</td>\n",
              "      <td>139.467117</td>\n",
              "      <td>143.416962</td>\n",
              "      <td>142.730972</td>\n",
              "      <td>122.199829</td>\n",
              "      <td>92.732704</td>\n",
              "      <td>86.750862</td>\n",
              "      <td>87.300171</td>\n",
              "      <td>88.491348</td>\n",
              "      <td>91.084778</td>\n",
              "      <td>96.228378</td>\n",
              "      <td>98.840836</td>\n",
              "      <td>101.388412</td>\n",
              "      <td>98.809692</td>\n",
              "      <td>106.340836</td>\n",
              "      <td>157.668686</td>\n",
              "      <td>183.241364</td>\n",
              "      <td>182.493958</td>\n",
              "      <td>179.719727</td>\n",
              "      <td>169.397919</td>\n",
              "      <td>132.157440</td>\n",
              "      <td>77.974052</td>\n",
              "      <td>62.796715</td>\n",
              "      <td>62.978378</td>\n",
              "      <td>63.394463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>76.250145</td>\n",
              "      <td>77.375725</td>\n",
              "      <td>81.507446</td>\n",
              "      <td>86.518738</td>\n",
              "      <td>92.277527</td>\n",
              "      <td>97.306686</td>\n",
              "      <td>95.998810</td>\n",
              "      <td>74.639961</td>\n",
              "      <td>41.943863</td>\n",
              "      <td>43.952595</td>\n",
              "      <td>55.137276</td>\n",
              "      <td>63.337635</td>\n",
              "      <td>70.110687</td>\n",
              "      <td>73.166435</td>\n",
              "      <td>99.964897</td>\n",
              "      <td>123.923233</td>\n",
              "      <td>135.058334</td>\n",
              "      <td>135.987900</td>\n",
              "      <td>133.698288</td>\n",
              "      <td>126.108124</td>\n",
              "      <td>118.086098</td>\n",
              "      <td>115.379890</td>\n",
              "      <td>121.085304</td>\n",
              "      <td>121.847839</td>\n",
              "      <td>117.282486</td>\n",
              "      <td>118.641350</td>\n",
              "      <td>119.303719</td>\n",
              "      <td>119.180328</td>\n",
              "      <td>75.894669</td>\n",
              "      <td>77.625664</td>\n",
              "      <td>80.567543</td>\n",
              "      <td>85.194801</td>\n",
              "      <td>89.818893</td>\n",
              "      <td>95.234482</td>\n",
              "      <td>96.955765</td>\n",
              "      <td>86.274948</td>\n",
              "      <td>51.614166</td>\n",
              "      <td>50.997227</td>\n",
              "      <td>60.961124</td>\n",
              "      <td>68.591751</td>\n",
              "      <td>...</td>\n",
              "      <td>0.591549</td>\n",
              "      <td>0.591549</td>\n",
              "      <td>0.486015</td>\n",
              "      <td>0.141639</td>\n",
              "      <td>0.422138</td>\n",
              "      <td>0.320968</td>\n",
              "      <td>0.867685</td>\n",
              "      <td>0.746281</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.004761</td>\n",
              "      <td>0.942472</td>\n",
              "      <td>0.927792</td>\n",
              "      <td>10.184290</td>\n",
              "      <td>9.345567</td>\n",
              "      <td>9.476097</td>\n",
              "      <td>10.264830</td>\n",
              "      <td>9.509424</td>\n",
              "      <td>9.603849</td>\n",
              "      <td>9.873240</td>\n",
              "      <td>10.103750</td>\n",
              "      <td>9.795478</td>\n",
              "      <td>9.901012</td>\n",
              "      <td>10.178735</td>\n",
              "      <td>9.695498</td>\n",
              "      <td>9.140052</td>\n",
              "      <td>9.476097</td>\n",
              "      <td>9.806388</td>\n",
              "      <td>8.845469</td>\n",
              "      <td>9.270383</td>\n",
              "      <td>10.525690</td>\n",
              "      <td>10.378497</td>\n",
              "      <td>9.300933</td>\n",
              "      <td>9.473122</td>\n",
              "      <td>9.416386</td>\n",
              "      <td>9.985321</td>\n",
              "      <td>9.675064</td>\n",
              "      <td>9.912121</td>\n",
              "      <td>10.250942</td>\n",
              "      <td>9.873240</td>\n",
              "      <td>10.531443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>123.780151</td>\n",
              "      <td>108.040916</td>\n",
              "      <td>99.039444</td>\n",
              "      <td>96.632591</td>\n",
              "      <td>96.607750</td>\n",
              "      <td>98.282692</td>\n",
              "      <td>100.344780</td>\n",
              "      <td>102.030693</td>\n",
              "      <td>102.941566</td>\n",
              "      <td>104.825424</td>\n",
              "      <td>106.878754</td>\n",
              "      <td>108.770638</td>\n",
              "      <td>114.731934</td>\n",
              "      <td>120.233765</td>\n",
              "      <td>116.913811</td>\n",
              "      <td>99.368881</td>\n",
              "      <td>86.558075</td>\n",
              "      <td>86.612862</td>\n",
              "      <td>86.034332</td>\n",
              "      <td>88.581451</td>\n",
              "      <td>86.577789</td>\n",
              "      <td>84.308266</td>\n",
              "      <td>79.316292</td>\n",
              "      <td>69.547844</td>\n",
              "      <td>57.093506</td>\n",
              "      <td>46.821770</td>\n",
              "      <td>42.489407</td>\n",
              "      <td>71.378387</td>\n",
              "      <td>123.830551</td>\n",
              "      <td>110.029953</td>\n",
              "      <td>101.482109</td>\n",
              "      <td>97.195770</td>\n",
              "      <td>98.130020</td>\n",
              "      <td>99.215500</td>\n",
              "      <td>98.632591</td>\n",
              "      <td>99.937180</td>\n",
              "      <td>102.076698</td>\n",
              "      <td>102.900658</td>\n",
              "      <td>103.679329</td>\n",
              "      <td>104.192123</td>\n",
              "      <td>...</td>\n",
              "      <td>143.832733</td>\n",
              "      <td>152.027039</td>\n",
              "      <td>154.808624</td>\n",
              "      <td>156.002930</td>\n",
              "      <td>156.376923</td>\n",
              "      <td>155.978088</td>\n",
              "      <td>155.948151</td>\n",
              "      <td>157.108856</td>\n",
              "      <td>158.310440</td>\n",
              "      <td>157.441208</td>\n",
              "      <td>157.645004</td>\n",
              "      <td>162.151947</td>\n",
              "      <td>103.430984</td>\n",
              "      <td>98.695404</td>\n",
              "      <td>97.430252</td>\n",
              "      <td>99.559547</td>\n",
              "      <td>103.362320</td>\n",
              "      <td>106.060638</td>\n",
              "      <td>108.339668</td>\n",
              "      <td>109.799133</td>\n",
              "      <td>110.006577</td>\n",
              "      <td>109.357208</td>\n",
              "      <td>108.622360</td>\n",
              "      <td>111.032883</td>\n",
              "      <td>118.412720</td>\n",
              "      <td>124.403229</td>\n",
              "      <td>126.971519</td>\n",
              "      <td>131.579269</td>\n",
              "      <td>143.089844</td>\n",
              "      <td>156.802795</td>\n",
              "      <td>159.010971</td>\n",
              "      <td>157.481384</td>\n",
              "      <td>156.360138</td>\n",
              "      <td>154.463120</td>\n",
              "      <td>152.498917</td>\n",
              "      <td>151.304596</td>\n",
              "      <td>153.165100</td>\n",
              "      <td>152.308990</td>\n",
              "      <td>152.731934</td>\n",
              "      <td>157.472626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>0.115226</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.067215</td>\n",
              "      <td>0.282579</td>\n",
              "      <td>0.481481</td>\n",
              "      <td>1.448560</td>\n",
              "      <td>1.460905</td>\n",
              "      <td>1.790123</td>\n",
              "      <td>1.478738</td>\n",
              "      <td>1.078189</td>\n",
              "      <td>1.528121</td>\n",
              "      <td>1.432099</td>\n",
              "      <td>1.270233</td>\n",
              "      <td>1.035665</td>\n",
              "      <td>0.703704</td>\n",
              "      <td>0.703704</td>\n",
              "      <td>0.672154</td>\n",
              "      <td>0.443073</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.032922</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.057613</td>\n",
              "      <td>0.201646</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006859</td>\n",
              "      <td>0.137174</td>\n",
              "      <td>0.048011</td>\n",
              "      <td>0.807956</td>\n",
              "      <td>1.832647</td>\n",
              "      <td>2.728395</td>\n",
              "      <td>3.315500</td>\n",
              "      <td>...</td>\n",
              "      <td>86.772293</td>\n",
              "      <td>89.004105</td>\n",
              "      <td>89.491081</td>\n",
              "      <td>89.148140</td>\n",
              "      <td>89.635101</td>\n",
              "      <td>89.588470</td>\n",
              "      <td>91.351166</td>\n",
              "      <td>90.755829</td>\n",
              "      <td>91.447182</td>\n",
              "      <td>93.655685</td>\n",
              "      <td>94.672150</td>\n",
              "      <td>101.401917</td>\n",
              "      <td>67.460899</td>\n",
              "      <td>61.973934</td>\n",
              "      <td>60.801094</td>\n",
              "      <td>59.813446</td>\n",
              "      <td>60.042522</td>\n",
              "      <td>58.626884</td>\n",
              "      <td>56.504799</td>\n",
              "      <td>45.894375</td>\n",
              "      <td>45.960220</td>\n",
              "      <td>49.683128</td>\n",
              "      <td>53.224968</td>\n",
              "      <td>55.556931</td>\n",
              "      <td>57.588478</td>\n",
              "      <td>61.334702</td>\n",
              "      <td>63.683128</td>\n",
              "      <td>66.661179</td>\n",
              "      <td>71.485588</td>\n",
              "      <td>75.651581</td>\n",
              "      <td>79.683121</td>\n",
              "      <td>85.231819</td>\n",
              "      <td>90.390945</td>\n",
              "      <td>94.941017</td>\n",
              "      <td>96.150894</td>\n",
              "      <td>99.596710</td>\n",
              "      <td>102.839508</td>\n",
              "      <td>105.685867</td>\n",
              "      <td>111.419746</td>\n",
              "      <td>120.784622</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0           1           2    ...         781         782         783\n",
              "0    174.002792  148.457993  138.614594  ...  127.010803  117.221016  112.785301\n",
              "1    155.358932  160.961517  159.506638  ...  159.090775  162.827057  136.528595\n",
              "2    195.583267  204.749161  215.725769  ...  140.389343  139.654968  137.690063\n",
              "3    118.147942  109.213028  100.142029  ...  133.372803  131.011841  127.686394\n",
              "4      0.000000    0.000000    0.000000  ...    0.000000    0.000000    0.000000\n",
              "..          ...         ...         ...  ...         ...         ...         ...\n",
              "145   99.899605  109.966408  112.869957  ...   83.869202   89.333076   91.406265\n",
              "146  100.198097   93.689453   96.166962  ...   62.796715   62.978378   63.394463\n",
              "147   76.250145   77.375725   81.507446  ...   10.250942    9.873240   10.531443\n",
              "148  123.780151  108.040916   99.039444  ...  152.308990  152.731934  157.472626\n",
              "149    0.115226    0.000000    0.000000  ...  105.685867  111.419746  120.784622\n",
              "\n",
              "[150 rows x 784 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31usb3UnY7lD",
        "outputId": "62ebbed4-3580-423c-db3c-0faf04372cce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_teste.shape # por que esta saindo 100 ???????"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 785)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVHUUaL8XXs-"
      },
      "source": [
        "#df_ann"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QBV18nYTaNE"
      },
      "source": [
        "img_graos = []\n",
        "Width_new = []\n",
        "k = 0\n",
        "for i in prediction:\n",
        "  if( i == 0):\n",
        "    img_graos.append(df_teste.iloc[k,:])\n",
        "    Width_new.append(Width.iloc[k])\n",
        "\n",
        "  k = k +1\n",
        "\n",
        "img_graos = pd.DataFrame(img_graos, columns=names )\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMCLCNQobH-d",
        "outputId": "55e36437-31b3-489d-ea31-ca100006b78c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "img_graos.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36, 785)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "touLevDmbBx5",
        "outputId": "f992b1c2-71ea-4af7-a785-a8042e044189",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "prediction"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n",
              "       1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
              "       1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4RSVgX4UhbC",
        "outputId": "8bc904a7-92ac-4db6-9732-e701b5db687f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "img_graos.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36, 785)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LkA4vHp-f6_"
      },
      "source": [
        "Width=np.array(Width_new)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjRbWgmX_LFH",
        "outputId": "f5c62c1e-0df5-495e-c9a6-079a0fc29a91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_paper_fev_2021\n",
        "%cd marquesgabi_paper_fev_2021\n",
        "\n",
        "from Get_PSDArea_Revival import PSDArea\n",
        "from histogram_fev_2021 import PSD\n",
        "#from GetBetterSegm import GetBetter"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'marquesgabi_paper_fev_2021' already exists and is not an empty directory.\n",
            "/content/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines/marquesgabi_paper_fev_2021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAG_I6FwCvFr",
        "outputId": "e13ec391-688a-454c-d04e-43d9f1fc3118",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "#https://github.com/marquesgabi/Doutorado/blob/master/Amostra7.csv\n",
        "#!git clone https://github.com/ucfilho/marquesgabi_out_2020\n",
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "#%cd marquesgabi_out_2020\n",
        "%cd Doutorado\n",
        "PSD_imageJ = 'Amostra7.csv' \n",
        "#PSD_new = pd.read_csv(PSD_imageJ,sep=';')\n",
        "#encoding='utf8'\n",
        "\n",
        "#PSD_imageJ = 'Areas_ImageJ.csv'\n",
        "PSD_new = pd.read_csv(PSD_imageJ)\n",
        "print(PSD_new.head(3))\n",
        "''''''"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Doutorado' already exists and is not an empty directory.\n",
            "/content/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines/marquesgabi_paper_fev_2021/Doutorado\n",
            "     ;Area\n",
            "0  1;1.387\n",
            "1  2;1.626\n",
            "2  3;1.336\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_1WIM8w7poO"
      },
      "source": [
        "Area_All, Diameter_All=PSDArea(img_graos) "
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB3gOFPeDtoH",
        "outputId": "4d83f95a-f3fe-4e85-ecd6-30fc3f2e8056",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Width.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36,)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nO6cSz2dIqb",
        "outputId": "2a822936-7eda-4df8-ea7f-eaf5a2c37de4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "img_graos.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36, 785)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PekBHQOT_6CP",
        "outputId": "24255c9b-b207-40c0-c1d8-5a95180c0a8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "img_graos.head()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Width</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "      <th>769</th>\n",
              "      <th>770</th>\n",
              "      <th>771</th>\n",
              "      <th>772</th>\n",
              "      <th>773</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>114.0</td>\n",
              "      <td>195.583267</td>\n",
              "      <td>204.749161</td>\n",
              "      <td>215.725769</td>\n",
              "      <td>219.451218</td>\n",
              "      <td>222.041229</td>\n",
              "      <td>223.955048</td>\n",
              "      <td>223.087128</td>\n",
              "      <td>219.036011</td>\n",
              "      <td>209.330261</td>\n",
              "      <td>184.635880</td>\n",
              "      <td>149.031387</td>\n",
              "      <td>122.441673</td>\n",
              "      <td>114.123734</td>\n",
              "      <td>112.783012</td>\n",
              "      <td>113.279167</td>\n",
              "      <td>110.272087</td>\n",
              "      <td>107.463837</td>\n",
              "      <td>106.948593</td>\n",
              "      <td>106.934135</td>\n",
              "      <td>104.865799</td>\n",
              "      <td>101.261612</td>\n",
              "      <td>99.784248</td>\n",
              "      <td>94.296707</td>\n",
              "      <td>89.276085</td>\n",
              "      <td>86.950760</td>\n",
              "      <td>86.318558</td>\n",
              "      <td>80.214836</td>\n",
              "      <td>77.631271</td>\n",
              "      <td>193.364716</td>\n",
              "      <td>199.561096</td>\n",
              "      <td>209.016617</td>\n",
              "      <td>216.788864</td>\n",
              "      <td>220.009216</td>\n",
              "      <td>221.803635</td>\n",
              "      <td>219.995682</td>\n",
              "      <td>182.395828</td>\n",
              "      <td>139.814087</td>\n",
              "      <td>117.186829</td>\n",
              "      <td>109.084328</td>\n",
              "      <td>...</td>\n",
              "      <td>141.267471</td>\n",
              "      <td>139.497070</td>\n",
              "      <td>138.149277</td>\n",
              "      <td>137.602661</td>\n",
              "      <td>139.632507</td>\n",
              "      <td>144.701141</td>\n",
              "      <td>145.970154</td>\n",
              "      <td>144.968597</td>\n",
              "      <td>142.821472</td>\n",
              "      <td>140.727310</td>\n",
              "      <td>137.777466</td>\n",
              "      <td>138.343796</td>\n",
              "      <td>126.987076</td>\n",
              "      <td>126.904594</td>\n",
              "      <td>122.310257</td>\n",
              "      <td>120.520775</td>\n",
              "      <td>131.304703</td>\n",
              "      <td>143.293640</td>\n",
              "      <td>148.684525</td>\n",
              "      <td>149.482300</td>\n",
              "      <td>146.701767</td>\n",
              "      <td>144.324402</td>\n",
              "      <td>143.048019</td>\n",
              "      <td>142.209595</td>\n",
              "      <td>141.724533</td>\n",
              "      <td>141.129883</td>\n",
              "      <td>141.375809</td>\n",
              "      <td>140.132965</td>\n",
              "      <td>138.859955</td>\n",
              "      <td>137.322250</td>\n",
              "      <td>135.422897</td>\n",
              "      <td>134.793793</td>\n",
              "      <td>137.239151</td>\n",
              "      <td>142.326263</td>\n",
              "      <td>143.750381</td>\n",
              "      <td>142.849808</td>\n",
              "      <td>141.418579</td>\n",
              "      <td>140.389343</td>\n",
              "      <td>139.654968</td>\n",
              "      <td>137.690063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>182.0</td>\n",
              "      <td>118.147942</td>\n",
              "      <td>109.213028</td>\n",
              "      <td>100.142029</td>\n",
              "      <td>125.964508</td>\n",
              "      <td>133.899429</td>\n",
              "      <td>134.207123</td>\n",
              "      <td>134.201202</td>\n",
              "      <td>129.372787</td>\n",
              "      <td>128.390533</td>\n",
              "      <td>126.615395</td>\n",
              "      <td>126.005928</td>\n",
              "      <td>118.881660</td>\n",
              "      <td>114.485222</td>\n",
              "      <td>113.396454</td>\n",
              "      <td>113.408287</td>\n",
              "      <td>112.177521</td>\n",
              "      <td>112.029594</td>\n",
              "      <td>115.106522</td>\n",
              "      <td>124.366867</td>\n",
              "      <td>128.733749</td>\n",
              "      <td>123.727821</td>\n",
              "      <td>109.609482</td>\n",
              "      <td>105.964508</td>\n",
              "      <td>104.710068</td>\n",
              "      <td>102.644981</td>\n",
              "      <td>100.171600</td>\n",
              "      <td>99.639069</td>\n",
              "      <td>101.840240</td>\n",
              "      <td>112.147942</td>\n",
              "      <td>112.065102</td>\n",
              "      <td>107.893501</td>\n",
              "      <td>123.538467</td>\n",
              "      <td>132.869843</td>\n",
              "      <td>135.473389</td>\n",
              "      <td>135.029602</td>\n",
              "      <td>129.183441</td>\n",
              "      <td>128.615387</td>\n",
              "      <td>125.869827</td>\n",
              "      <td>126.301788</td>\n",
              "      <td>...</td>\n",
              "      <td>119.538475</td>\n",
              "      <td>120.461555</td>\n",
              "      <td>124.745575</td>\n",
              "      <td>133.810669</td>\n",
              "      <td>146.094681</td>\n",
              "      <td>153.656815</td>\n",
              "      <td>171.455627</td>\n",
              "      <td>173.621323</td>\n",
              "      <td>136.094696</td>\n",
              "      <td>128.520721</td>\n",
              "      <td>130.029587</td>\n",
              "      <td>123.816589</td>\n",
              "      <td>118.041428</td>\n",
              "      <td>118.242615</td>\n",
              "      <td>117.745575</td>\n",
              "      <td>113.177521</td>\n",
              "      <td>111.307693</td>\n",
              "      <td>118.159775</td>\n",
              "      <td>130.686401</td>\n",
              "      <td>132.000015</td>\n",
              "      <td>126.408295</td>\n",
              "      <td>121.733742</td>\n",
              "      <td>121.798828</td>\n",
              "      <td>120.757408</td>\n",
              "      <td>116.284027</td>\n",
              "      <td>110.627228</td>\n",
              "      <td>109.023682</td>\n",
              "      <td>108.609467</td>\n",
              "      <td>112.153854</td>\n",
              "      <td>113.905334</td>\n",
              "      <td>119.349121</td>\n",
              "      <td>122.189369</td>\n",
              "      <td>125.053268</td>\n",
              "      <td>138.556229</td>\n",
              "      <td>159.514801</td>\n",
              "      <td>161.893494</td>\n",
              "      <td>139.171600</td>\n",
              "      <td>133.372803</td>\n",
              "      <td>131.011841</td>\n",
              "      <td>127.686394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>128.0</td>\n",
              "      <td>143.456055</td>\n",
              "      <td>134.411133</td>\n",
              "      <td>132.058594</td>\n",
              "      <td>131.609375</td>\n",
              "      <td>130.284180</td>\n",
              "      <td>129.412109</td>\n",
              "      <td>130.028320</td>\n",
              "      <td>131.826172</td>\n",
              "      <td>134.992188</td>\n",
              "      <td>136.059570</td>\n",
              "      <td>137.705078</td>\n",
              "      <td>140.930664</td>\n",
              "      <td>142.062500</td>\n",
              "      <td>142.027344</td>\n",
              "      <td>144.413086</td>\n",
              "      <td>149.830078</td>\n",
              "      <td>151.470703</td>\n",
              "      <td>150.662109</td>\n",
              "      <td>146.475586</td>\n",
              "      <td>134.752930</td>\n",
              "      <td>130.853516</td>\n",
              "      <td>131.475586</td>\n",
              "      <td>130.369141</td>\n",
              "      <td>128.162109</td>\n",
              "      <td>124.580078</td>\n",
              "      <td>119.907227</td>\n",
              "      <td>117.910156</td>\n",
              "      <td>117.995117</td>\n",
              "      <td>144.622070</td>\n",
              "      <td>139.894531</td>\n",
              "      <td>133.794922</td>\n",
              "      <td>132.096680</td>\n",
              "      <td>131.998047</td>\n",
              "      <td>133.353516</td>\n",
              "      <td>134.517578</td>\n",
              "      <td>135.047852</td>\n",
              "      <td>135.388672</td>\n",
              "      <td>137.069336</td>\n",
              "      <td>139.469727</td>\n",
              "      <td>...</td>\n",
              "      <td>162.263672</td>\n",
              "      <td>161.887695</td>\n",
              "      <td>159.660156</td>\n",
              "      <td>156.973633</td>\n",
              "      <td>158.476562</td>\n",
              "      <td>158.921875</td>\n",
              "      <td>164.202148</td>\n",
              "      <td>162.112305</td>\n",
              "      <td>158.486328</td>\n",
              "      <td>157.828125</td>\n",
              "      <td>157.708008</td>\n",
              "      <td>160.337891</td>\n",
              "      <td>104.603516</td>\n",
              "      <td>105.735352</td>\n",
              "      <td>112.358398</td>\n",
              "      <td>114.228516</td>\n",
              "      <td>106.102539</td>\n",
              "      <td>113.876953</td>\n",
              "      <td>136.125000</td>\n",
              "      <td>200.351562</td>\n",
              "      <td>248.477539</td>\n",
              "      <td>251.241211</td>\n",
              "      <td>250.918945</td>\n",
              "      <td>237.383789</td>\n",
              "      <td>214.951172</td>\n",
              "      <td>197.577148</td>\n",
              "      <td>172.078125</td>\n",
              "      <td>168.559570</td>\n",
              "      <td>162.264648</td>\n",
              "      <td>162.015625</td>\n",
              "      <td>158.225586</td>\n",
              "      <td>152.249023</td>\n",
              "      <td>152.625977</td>\n",
              "      <td>155.299805</td>\n",
              "      <td>160.967773</td>\n",
              "      <td>159.802734</td>\n",
              "      <td>158.863281</td>\n",
              "      <td>157.237305</td>\n",
              "      <td>156.943359</td>\n",
              "      <td>160.303711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>111.0</td>\n",
              "      <td>29.497118</td>\n",
              "      <td>21.165489</td>\n",
              "      <td>18.512701</td>\n",
              "      <td>14.546466</td>\n",
              "      <td>13.900171</td>\n",
              "      <td>16.832077</td>\n",
              "      <td>24.778996</td>\n",
              "      <td>34.931091</td>\n",
              "      <td>59.385036</td>\n",
              "      <td>78.607010</td>\n",
              "      <td>83.536728</td>\n",
              "      <td>85.406380</td>\n",
              "      <td>85.965744</td>\n",
              "      <td>86.410355</td>\n",
              "      <td>85.871597</td>\n",
              "      <td>87.371964</td>\n",
              "      <td>89.917702</td>\n",
              "      <td>92.103722</td>\n",
              "      <td>93.503769</td>\n",
              "      <td>95.307045</td>\n",
              "      <td>97.952759</td>\n",
              "      <td>100.843109</td>\n",
              "      <td>99.883041</td>\n",
              "      <td>95.870865</td>\n",
              "      <td>95.209167</td>\n",
              "      <td>96.976387</td>\n",
              "      <td>101.638420</td>\n",
              "      <td>106.036118</td>\n",
              "      <td>36.281467</td>\n",
              "      <td>21.463356</td>\n",
              "      <td>19.440872</td>\n",
              "      <td>13.209560</td>\n",
              "      <td>10.696048</td>\n",
              "      <td>10.969727</td>\n",
              "      <td>12.141385</td>\n",
              "      <td>14.039932</td>\n",
              "      <td>21.890026</td>\n",
              "      <td>49.169464</td>\n",
              "      <td>79.011765</td>\n",
              "      <td>...</td>\n",
              "      <td>4.510024</td>\n",
              "      <td>4.047399</td>\n",
              "      <td>5.290074</td>\n",
              "      <td>9.049996</td>\n",
              "      <td>11.865676</td>\n",
              "      <td>12.030111</td>\n",
              "      <td>10.821280</td>\n",
              "      <td>11.131483</td>\n",
              "      <td>3.336174</td>\n",
              "      <td>1.330492</td>\n",
              "      <td>1.056814</td>\n",
              "      <td>0.747748</td>\n",
              "      <td>72.524147</td>\n",
              "      <td>87.446304</td>\n",
              "      <td>90.477310</td>\n",
              "      <td>90.163216</td>\n",
              "      <td>88.592163</td>\n",
              "      <td>90.163139</td>\n",
              "      <td>93.398186</td>\n",
              "      <td>96.754242</td>\n",
              "      <td>100.862022</td>\n",
              "      <td>101.744743</td>\n",
              "      <td>101.356056</td>\n",
              "      <td>100.940018</td>\n",
              "      <td>97.601982</td>\n",
              "      <td>76.724129</td>\n",
              "      <td>11.478045</td>\n",
              "      <td>4.491762</td>\n",
              "      <td>2.917783</td>\n",
              "      <td>1.409139</td>\n",
              "      <td>1.039445</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.945946</td>\n",
              "      <td>0.349566</td>\n",
              "      <td>0.618213</td>\n",
              "      <td>0.945459</td>\n",
              "      <td>0.863647</td>\n",
              "      <td>0.497768</td>\n",
              "      <td>0.747748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>157.0</td>\n",
              "      <td>170.004547</td>\n",
              "      <td>173.035660</td>\n",
              "      <td>174.338684</td>\n",
              "      <td>167.419220</td>\n",
              "      <td>141.186630</td>\n",
              "      <td>125.846130</td>\n",
              "      <td>127.503067</td>\n",
              "      <td>129.547455</td>\n",
              "      <td>134.785324</td>\n",
              "      <td>140.872787</td>\n",
              "      <td>143.314514</td>\n",
              "      <td>145.952911</td>\n",
              "      <td>147.572540</td>\n",
              "      <td>149.780045</td>\n",
              "      <td>151.737930</td>\n",
              "      <td>150.613190</td>\n",
              "      <td>147.241196</td>\n",
              "      <td>144.923462</td>\n",
              "      <td>140.305817</td>\n",
              "      <td>124.207390</td>\n",
              "      <td>99.370163</td>\n",
              "      <td>66.986122</td>\n",
              "      <td>76.890945</td>\n",
              "      <td>96.448013</td>\n",
              "      <td>103.337631</td>\n",
              "      <td>103.863235</td>\n",
              "      <td>111.869011</td>\n",
              "      <td>145.286026</td>\n",
              "      <td>170.540482</td>\n",
              "      <td>180.306473</td>\n",
              "      <td>183.303833</td>\n",
              "      <td>170.765640</td>\n",
              "      <td>142.889801</td>\n",
              "      <td>126.000854</td>\n",
              "      <td>120.243042</td>\n",
              "      <td>116.377098</td>\n",
              "      <td>124.410614</td>\n",
              "      <td>136.208160</td>\n",
              "      <td>144.077454</td>\n",
              "      <td>...</td>\n",
              "      <td>193.639511</td>\n",
              "      <td>212.292999</td>\n",
              "      <td>239.537277</td>\n",
              "      <td>245.639511</td>\n",
              "      <td>226.491989</td>\n",
              "      <td>204.979080</td>\n",
              "      <td>227.072021</td>\n",
              "      <td>242.210236</td>\n",
              "      <td>173.157455</td>\n",
              "      <td>151.007751</td>\n",
              "      <td>157.832169</td>\n",
              "      <td>175.568787</td>\n",
              "      <td>146.480194</td>\n",
              "      <td>146.446686</td>\n",
              "      <td>153.576248</td>\n",
              "      <td>160.793594</td>\n",
              "      <td>165.416260</td>\n",
              "      <td>166.664490</td>\n",
              "      <td>170.992279</td>\n",
              "      <td>173.139236</td>\n",
              "      <td>168.156998</td>\n",
              "      <td>162.684174</td>\n",
              "      <td>158.167267</td>\n",
              "      <td>160.899963</td>\n",
              "      <td>167.910843</td>\n",
              "      <td>180.028885</td>\n",
              "      <td>192.142151</td>\n",
              "      <td>203.943634</td>\n",
              "      <td>224.696762</td>\n",
              "      <td>237.753738</td>\n",
              "      <td>239.220825</td>\n",
              "      <td>206.140305</td>\n",
              "      <td>153.449036</td>\n",
              "      <td>163.029449</td>\n",
              "      <td>174.995178</td>\n",
              "      <td>159.368332</td>\n",
              "      <td>144.522217</td>\n",
              "      <td>154.268982</td>\n",
              "      <td>152.083618</td>\n",
              "      <td>148.380829</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Width           0           1  ...         781         782         783\n",
              "2   114.0  195.583267  204.749161  ...  140.389343  139.654968  137.690063\n",
              "3   182.0  118.147942  109.213028  ...  133.372803  131.011841  127.686394\n",
              "15  128.0  143.456055  134.411133  ...  157.237305  156.943359  160.303711\n",
              "19  111.0   29.497118   21.165489  ...    0.863647    0.497768    0.747748\n",
              "26  157.0  170.004547  173.035660  ...  154.268982  152.083618  148.380829\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaZPe_AxNBK9",
        "outputId": "24662fcc-0043-469e-d723-a785f25dc27e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "PSD_new.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vmhG2LgCabC",
        "outputId": "1e7d9eec-b6e8-458e-ef7f-87845200c428",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "Diam1 =[]\n",
        "'''\n",
        "# \n",
        "Area = df_ImgJ['Area'].values\n",
        "# Area = np.concatenate( (Area, [lost_value] ) )\n",
        "\n",
        "Diam1 = [ (4*A/np.pi)**0.5 for A in Area]\n",
        "'''\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n# \\nArea = df_ImgJ['Area'].values\\n# Area = np.concatenate( (Area, [lost_value] ) )\\n\\nDiam1 = [ (4*A/np.pi)**0.5 for A in Area]\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79MY9ZHxBW37",
        "outputId": "441ea5c9-fb9d-4a77-ab0f-4cb972f5a65d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(Diameter_All)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KooHVpH5k2mZ",
        "outputId": "d455ded8-03c9-4102-f2c2-59b1cc57ce71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "A=PSD_new[';Area'].values\n",
        "k = 0\n",
        "Area2 = []\n",
        "for i in A:\n",
        "  if(A[k][2] == ';'):\n",
        "    Area2.append(float(A[k][3:]))\n",
        "  else:\n",
        "      Area2.append(float(A[k][2:]))  \n",
        "  k = k +1\n",
        "print(Area2)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.387, 1.626, 1.336, 0.64, 2.211, 1.12, 0.974, 1.237, 1.29, 3.755, 2.778, 1.256, 1.386, 1.302, 1.071, 1.497, 1.518, 1.244, 1.532, 1.325, 1.519, 1.895, 1.22, 1.241, 1.301, 1.429, 0.667, 2.157, 1.052, 2.082, 1.517, 1.281, 0.784, 1.067, 2.764, 1.215, 0.943, 2.182, 1.486, 1.569, 2.667, 0.709, 1.006, 1.6, 1.408, 3.16, 2.465, 2.284, 1.273, 1.256, 3.021, 1.701, 1.955, 5.248, 1.627, 1.367, 1.592, 2.718, 1.658, 1.128, 2.192, 1.508, 2.547, 1.945, 1.606, 3.482, 1.756, 1.457, 1.864, 1.821, 1.314, 1.715, 1.015, 1.345, 1.265, 1.844, 1.396, 1.785, 1.694, 1.413, 1.368, 2.21, 1.034, 1.367, 1.943, 1.008, 1.279, 1.579, 1.444, 1.879, 1.466, 2.154, 1.794, 3.149, 1.883, 1.692, 1.163, 1.297, 2.949, 1.09, 1.444, 1.524]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvda6sN-9voL",
        "outputId": "e83bfa07-36a7-43eb-bb93-8477ee2d15db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(Area2)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "102"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPWCPPf7bzsf"
      },
      "source": [
        "#lost_value = float(PSD_new.columns[1])\n",
        "#Area2 = np.array(PSD_new.iloc[:,1])\n",
        "#Area2 = np.concatenate( (Area2, [lost_value] ) )\n",
        "\n",
        "for A in Area2:\n",
        "  Diam1.append((4*A/np.pi)**0.5) \n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfk_fNXGDK5_"
      },
      "source": [
        "wt1 = np.ones(len(Diam1)) / len(Diam1)*100\n",
        "wt2 = np.ones(len(Diameter_All)) / len(Diameter_All)*100\n",
        "X = pd.DataFrame([Diam1,Diameter_All])\n",
        "wts = pd.DataFrame([wt1,wt2])\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWf2nmnEp6yX",
        "outputId": "86a33ae8-7e5e-472c-d7c5-1fbbf620718d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "X"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>100</th>\n",
              "      <th>101</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.328903</td>\n",
              "      <td>1.438849</td>\n",
              "      <td>1.304242</td>\n",
              "      <td>0.902703</td>\n",
              "      <td>1.677836</td>\n",
              "      <td>1.194164</td>\n",
              "      <td>1.113614</td>\n",
              "      <td>1.254989</td>\n",
              "      <td>1.281592</td>\n",
              "      <td>2.186553</td>\n",
              "      <td>1.880707</td>\n",
              "      <td>1.264590</td>\n",
              "      <td>1.328424</td>\n",
              "      <td>1.287539</td>\n",
              "      <td>1.167750</td>\n",
              "      <td>1.380594</td>\n",
              "      <td>1.390244</td>\n",
              "      <td>1.258535</td>\n",
              "      <td>1.396640</td>\n",
              "      <td>1.298862</td>\n",
              "      <td>1.390702</td>\n",
              "      <td>1.553315</td>\n",
              "      <td>1.246336</td>\n",
              "      <td>1.257016</td>\n",
              "      <td>1.287045</td>\n",
              "      <td>1.348873</td>\n",
              "      <td>0.921548</td>\n",
              "      <td>1.657220</td>\n",
              "      <td>1.157345</td>\n",
              "      <td>1.628154</td>\n",
              "      <td>1.389786</td>\n",
              "      <td>1.277114</td>\n",
              "      <td>0.999110</td>\n",
              "      <td>1.165567</td>\n",
              "      <td>1.875962</td>\n",
              "      <td>1.243779</td>\n",
              "      <td>1.095749</td>\n",
              "      <td>1.666796</td>\n",
              "      <td>1.375512</td>\n",
              "      <td>1.413405</td>\n",
              "      <td>...</td>\n",
              "      <td>1.800817</td>\n",
              "      <td>1.573674</td>\n",
              "      <td>1.429973</td>\n",
              "      <td>2.105569</td>\n",
              "      <td>1.495262</td>\n",
              "      <td>1.362024</td>\n",
              "      <td>1.540558</td>\n",
              "      <td>1.522685</td>\n",
              "      <td>1.293459</td>\n",
              "      <td>1.477703</td>\n",
              "      <td>1.136811</td>\n",
              "      <td>1.308628</td>\n",
              "      <td>1.269113</td>\n",
              "      <td>1.532271</td>\n",
              "      <td>1.333208</td>\n",
              "      <td>1.507558</td>\n",
              "      <td>1.468628</td>\n",
              "      <td>1.341301</td>\n",
              "      <td>1.31977</td>\n",
              "      <td>1.677456</td>\n",
              "      <td>1.147401</td>\n",
              "      <td>1.319287</td>\n",
              "      <td>1.572865</td>\n",
              "      <td>1.132884</td>\n",
              "      <td>1.276117</td>\n",
              "      <td>1.417902</td>\n",
              "      <td>1.355934</td>\n",
              "      <td>1.546744</td>\n",
              "      <td>1.366224</td>\n",
              "      <td>1.656067</td>\n",
              "      <td>1.511354</td>\n",
              "      <td>2.002356</td>\n",
              "      <td>1.54839</td>\n",
              "      <td>1.467761</td>\n",
              "      <td>1.216872</td>\n",
              "      <td>1.285065</td>\n",
              "      <td>1.937726</td>\n",
              "      <td>1.178062</td>\n",
              "      <td>1.355934</td>\n",
              "      <td>1.392989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.826605</td>\n",
              "      <td>1.302448</td>\n",
              "      <td>0.712229</td>\n",
              "      <td>0.666224</td>\n",
              "      <td>1.095420</td>\n",
              "      <td>0.706760</td>\n",
              "      <td>0.803360</td>\n",
              "      <td>1.183854</td>\n",
              "      <td>1.324879</td>\n",
              "      <td>1.360216</td>\n",
              "      <td>0.902438</td>\n",
              "      <td>0.841541</td>\n",
              "      <td>1.210028</td>\n",
              "      <td>1.010299</td>\n",
              "      <td>1.067512</td>\n",
              "      <td>1.007889</td>\n",
              "      <td>0.865927</td>\n",
              "      <td>0.683235</td>\n",
              "      <td>1.177514</td>\n",
              "      <td>0.920193</td>\n",
              "      <td>0.982770</td>\n",
              "      <td>1.519928</td>\n",
              "      <td>0.808710</td>\n",
              "      <td>0.654220</td>\n",
              "      <td>0.917908</td>\n",
              "      <td>1.127408</td>\n",
              "      <td>1.168924</td>\n",
              "      <td>1.316344</td>\n",
              "      <td>0.807047</td>\n",
              "      <td>0.698947</td>\n",
              "      <td>1.234227</td>\n",
              "      <td>1.034439</td>\n",
              "      <td>1.109582</td>\n",
              "      <td>1.047482</td>\n",
              "      <td>0.620826</td>\n",
              "      <td>1.168924</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 102 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2    ...       99        100       101\n",
              "0  1.328903  1.438849  1.304242  ...  1.178062  1.355934  1.392989\n",
              "1  0.826605  1.302448  0.712229  ...       NaN       NaN       NaN\n",
              "\n",
              "[2 rows x 102 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzFRjY4BLtbh",
        "outputId": "1dbea6a5-80df-46ce-e6cd-eeb9adc115e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Diameter_All"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8266047195180816,\n",
              " 1.3024480485581642,\n",
              " 0.7122290426186543,\n",
              " 0.6662235651195668,\n",
              " 1.0954203479585845,\n",
              " 0.7067596756696943,\n",
              " 0.8033601145185016,\n",
              " 1.183853935327951,\n",
              " 1.3248787644500064,\n",
              " 1.3602157675064022,\n",
              " 0.902437812914977,\n",
              " 0.8415411059969924,\n",
              " 1.2100281218753939,\n",
              " 1.010298512002567,\n",
              " 1.0675115492844804,\n",
              " 1.0078886002501233,\n",
              " 0.8659268680937375,\n",
              " 0.6832350945673288,\n",
              " 1.1775141876583566,\n",
              " 0.9201933420381102,\n",
              " 0.9827702141677241,\n",
              " 1.5199281396717972,\n",
              " 0.8087098742301323,\n",
              " 0.6542195369192143,\n",
              " 0.9179082540507852,\n",
              " 1.1274076946348592,\n",
              " 1.1689238923939973,\n",
              " 1.3163444586217485,\n",
              " 0.8070471090669118,\n",
              " 0.69894687526331,\n",
              " 1.2342269031422655,\n",
              " 1.0344391616620074,\n",
              " 1.1095816743720852,\n",
              " 1.0474819460764522,\n",
              " 0.6208261923625497,\n",
              " 1.1689238923939973]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OieAXw_by3nz",
        "outputId": "e300d4d2-5c18-4d36-e574-2daa267b2c1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "A = plt.hist(X,weights=wts,bins=7)\n",
        "plt.legend(['True','CNN'])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f82d52aca10>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WryLryB9ovi3",
        "outputId": "a56471c9-afe7-43a3-c31d-185605acbe35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('ImgJ:','media=',np.mean(np.array(Diam1)),'desvio=',np.std(np.array(Diam1)),'pontos=',len(Diam1))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ImgJ: media= 1.4365604096576146 desvio= 0.2749068872026991 pontos= 102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_Nyv-Nopbkc",
        "outputId": "48013122-988d-4d59-e0f1-a0078070539e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Software:','media=',np.mean(np.array(Diameter_All)),'desvio=',np.std(np.array(Diameter_All)),'pontos=',len(Diameter_All))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Software: media= 0.9968404165265975 desvio= 0.2301430499896455 pontos= 36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eE6PjA0SZ8ZQ"
      },
      "source": [
        "# Software: media= 1.3185563233999378 desvio= 0.2728642468732428 pontos= 66 theshold =0.8 e repete=80\n",
        "# Software: media= 1.2650227960747715 desvio= 0.22942393421076387 pontos= 20 theshold =0.5 e repete=40"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpdrvEySy8Ij",
        "outputId": "75b70632-e1e6-47ad-da2a-218da5a0ee95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.mean(np.array(Diameter_All))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9968404165265975"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMK89w-fzCVe",
        "outputId": "ac801b92-bd00-474c-b09f-c736fd449434",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# Freq1 = [19.12043703, 29.22484843, 19.35872174, 20.82190224, 11.47409056] # avarage 4 samples\n",
        "Freq1 = [20.69301557, 28.55598044, 18.50768331, 22.7106327, 8.905907357] # avarage 10 samples\n",
        "#Freq2 = [16.93792791, 31.38008965, 24.93810752, 18.56158392, 6.233810752, 0.4]\n",
        "Freq2 = [16.93792791, 31.38008965, 24.93810752, 18.56158392, 6.633810752]\n",
        "Freq3 = [22.22489, 30.15078, 25.10463, 19.30926, 2.810434]\n",
        "barWidth = 0.25\n",
        "\n",
        "br1 = range(len(Freq1))\n",
        "# Set position of bar on X axis\n",
        "br2 = [x + barWidth for x in br1]\n",
        "br3 = [x + barWidth for x in br2]\n",
        "# labels = [0.8, 1.0, 1.2, 1.4, 1.6, 1.8]\n",
        "labels = [0.8, 1.0, 1.2, 1.4, 1.6]\n",
        "\n",
        "xx=[]\n",
        "for a in labels:\n",
        "  xx.append(str(a))\n",
        "plt.bar(br1, Freq1 , color=\"green\", align=\"center\", width=0.3, tick_label= xx) \n",
        "plt.bar(br2, Freq2 , color=\"red\", align=\"center\", width=0.3, tick_label= xx)\n",
        "plt.bar(br3, Freq3 , color=\"blue\", align=\"center\", width=0.3, tick_label= xx)\n",
        "plt.legend(['CNN 1','CNN 2','True'])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f82d51a3e10>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}