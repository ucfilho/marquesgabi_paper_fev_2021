{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PSD_histogram_BEST_sample_03.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ucfilho/marquesgabi_paper_fev_2021/blob/main/defesa/PSD_histogram_BEST_sample_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sog7Z9pyhUD_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import zipfile\n",
        "#import random\n",
        "from random import randint\n",
        "from PIL import Image\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "#import scikit-image\n",
        "import skimage\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
        "from sklearn.metrics import r2_score\n",
        "from google.colab import files"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsqQZIu-mEfi"
      },
      "source": [
        "Repetir = 40"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwc7AZrXRyqk"
      },
      "source": [
        "# New version change routine inside MarquesGabi_Routines\n",
        "# Try to improve segmentation \n",
        "# New routine is called Segment_Filter_revisited_One... Two,Three, etc\n",
        "# this exemple threshold 0.4\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZEvJvfoibE4"
      },
      "source": [
        "#!pip install mahotas"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UZ30b1EVQhq"
      },
      "source": [
        "def BlackWhite(Transfere,Size):\n",
        "\n",
        "  img_name=[]\n",
        "  xw=[]\n",
        "  ww=[]\n",
        "\n",
        "  with zipfile.ZipFile(Transfere, \"r\") as f:\n",
        "    for name in f.namelist():\n",
        "      img_name.append(name)\n",
        "      #xw.append(cv2.imread(name))\n",
        "      xw.append(cv2.resize(cv2.imread(name),(Size,Size)))\n",
        "\n",
        "  nrow=len(img_name)\n",
        "  ncol=Size*Size\n",
        "  pw=np.zeros((nrow,ncol))\n",
        "  #pw=[]\n",
        "  for i in range(nrow):\n",
        "    ww.append(cv2.cvtColor(np.array(xw[i]), cv2.COLOR_BGR2GRAY))\n",
        "    pw[i,:]=ww[i].ravel()\n",
        "  return ww,img_name"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v7SRrc8mH2N",
        "outputId": "63696915-af8e-4ddc-9f24-e9f258f26464"
      },
      "source": [
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "%cd Doutorado\n",
        "\n",
        "Transfere='Fotos_Grandes_3cdAmostra.zip' \n",
        "file_name = zipfile.ZipFile(Transfere, 'r')\n",
        "file_name.extractall()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Doutorado' already exists and is not an empty directory.\n",
            "/content/Doutorado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqIYzUcnrdMp",
        "outputId": "0ecd639e-743b-4999-d463-ffcdb3fcb9f7"
      },
      "source": [
        "labels =[]\n",
        "with zipfile.ZipFile(Transfere, \"r\") as f:\n",
        "  for f in f.namelist():\n",
        "    labels.append(f)\n",
        "print(labels)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Fotos_Grandes-3cdAmostra/Q6-8-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-8-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-8-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-4.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kA4IWSmasoD"
      },
      "source": [
        "Size=1200 # tamanho da foto\n",
        "ww,img_name=BlackWhite(Transfere,Size) #Pegamos a primeira foto Grande\n",
        "# this is the big image we want to segment \n",
        "# ww[0], change it if you want to segment another picture"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHgqAnaFyCjp",
        "outputId": "de80c0c1-559c-4bb4-d311-d1e1b6a95b0f"
      },
      "source": [
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MarquesGabi_Routines' already exists and is not an empty directory.\n",
            "/content/Doutorado/MarquesGabi_Routines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDEGUiuubwuZ"
      },
      "source": [
        "FILE='SugarSample03.zip'\n",
        "img_name=[]\n",
        "x_original = [] \n",
        "\n",
        "data_file ='xls'\n",
        "\n",
        "\n",
        "file_name = zipfile.ZipFile(FILE, 'r')\n",
        "file_name.extractall()\n",
        "\n",
        "k = 0\n",
        "with zipfile.ZipFile(FILE, \"r\") as f:\n",
        "    for name in f.namelist():\n",
        "      if(name[-3:] == data_file):\n",
        "        #df =pd.read_csv(name)\n",
        "        if( k > 0):\n",
        "          df_old = df_ImgJ.copy()\n",
        "        df_ImgJ = pd.read_excel(name)\n",
        "        df_ImgJ = df_ImgJ.drop(labels=[0], axis=0)\n",
        "        if(k > 0):\n",
        "          df_ImgJ = pd.concat( [df_ImgJ, df_old], ignore_index = True)\n",
        "        k = k + 1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbQ0tal0etXx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01990547-8626-4609-be48-88c58606d1fb"
      },
      "source": [
        "f.namelist()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Results_03_02.xls', 'Results_03_03.xls', 'Results_03_01.xls']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSYrykxxGJ5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16a5b04a-5d3f-41eb-e3e4-1b2f947205d4"
      },
      "source": [
        "df_ImgJ.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(174, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KDJn09lGTBD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "919af8e5-4e17-4036-ba8b-33df8f88550b"
      },
      "source": [
        "df_ImgJ.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Area</th>\n",
              "      <th>Mean</th>\n",
              "      <th>Min</th>\n",
              "      <th>Max</th>\n",
              "      <th>Major</th>\n",
              "      <th>Minor</th>\n",
              "      <th>Angle</th>\n",
              "      <th>Feret</th>\n",
              "      <th>FeretX</th>\n",
              "      <th>FeretY</th>\n",
              "      <th>FeretAngle</th>\n",
              "      <th>MinFeret</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>1.288</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>1.383</td>\n",
              "      <td>1.185</td>\n",
              "      <td>5.847</td>\n",
              "      <td>1.636</td>\n",
              "      <td>767</td>\n",
              "      <td>213</td>\n",
              "      <td>18.157</td>\n",
              "      <td>1.161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>0.407</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>0.814</td>\n",
              "      <td>0.637</td>\n",
              "      <td>62.186</td>\n",
              "      <td>0.877</td>\n",
              "      <td>283</td>\n",
              "      <td>234</td>\n",
              "      <td>59.036</td>\n",
              "      <td>0.667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>0.592</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>0.925</td>\n",
              "      <td>0.815</td>\n",
              "      <td>117.923</td>\n",
              "      <td>1.078</td>\n",
              "      <td>633</td>\n",
              "      <td>154</td>\n",
              "      <td>122.335</td>\n",
              "      <td>0.802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>1.391</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>1.435</td>\n",
              "      <td>1.235</td>\n",
              "      <td>29.966</td>\n",
              "      <td>1.564</td>\n",
              "      <td>1321</td>\n",
              "      <td>333</td>\n",
              "      <td>53.253</td>\n",
              "      <td>1.165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>0.549</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>0.923</td>\n",
              "      <td>0.758</td>\n",
              "      <td>136.396</td>\n",
              "      <td>1.024</td>\n",
              "      <td>370</td>\n",
              "      <td>254</td>\n",
              "      <td>118.237</td>\n",
              "      <td>0.738</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Area  Mean  Min  Max  ...  Feret  FeretX  FeretY  FeretAngle  MinFeret\n",
              "0  2  1.288   255  255  255  ...  1.636     767     213      18.157     1.161\n",
              "1  3  0.407   255  255  255  ...  0.877     283     234      59.036     0.667\n",
              "2  4  0.592   255  255  255  ...  1.078     633     154     122.335     0.802\n",
              "3  5  1.391   255  255  255  ...  1.564    1321     333      53.253     1.165\n",
              "4  6  0.549   255  255  255  ...  1.024     370     254     118.237     0.738\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMBJ6C-YdF3q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "a92250ba-ecd4-4a2c-ee25-541e3bc4326d"
      },
      "source": [
        "df_ImgJ.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Area</th>\n",
              "      <th>Mean</th>\n",
              "      <th>Min</th>\n",
              "      <th>Max</th>\n",
              "      <th>Major</th>\n",
              "      <th>Minor</th>\n",
              "      <th>Angle</th>\n",
              "      <th>Feret</th>\n",
              "      <th>FeretX</th>\n",
              "      <th>FeretY</th>\n",
              "      <th>FeretAngle</th>\n",
              "      <th>MinFeret</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>1.288</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>1.383</td>\n",
              "      <td>1.185</td>\n",
              "      <td>5.847</td>\n",
              "      <td>1.636</td>\n",
              "      <td>767</td>\n",
              "      <td>213</td>\n",
              "      <td>18.157</td>\n",
              "      <td>1.161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>0.407</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>0.814</td>\n",
              "      <td>0.637</td>\n",
              "      <td>62.186</td>\n",
              "      <td>0.877</td>\n",
              "      <td>283</td>\n",
              "      <td>234</td>\n",
              "      <td>59.036</td>\n",
              "      <td>0.667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>0.592</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>0.925</td>\n",
              "      <td>0.815</td>\n",
              "      <td>117.923</td>\n",
              "      <td>1.078</td>\n",
              "      <td>633</td>\n",
              "      <td>154</td>\n",
              "      <td>122.335</td>\n",
              "      <td>0.802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>1.391</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>1.435</td>\n",
              "      <td>1.235</td>\n",
              "      <td>29.966</td>\n",
              "      <td>1.564</td>\n",
              "      <td>1321</td>\n",
              "      <td>333</td>\n",
              "      <td>53.253</td>\n",
              "      <td>1.165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>0.549</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>0.923</td>\n",
              "      <td>0.758</td>\n",
              "      <td>136.396</td>\n",
              "      <td>1.024</td>\n",
              "      <td>370</td>\n",
              "      <td>254</td>\n",
              "      <td>118.237</td>\n",
              "      <td>0.738</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Area  Mean  Min  Max  ...  Feret  FeretX  FeretY  FeretAngle  MinFeret\n",
              "0  2  1.288   255  255  255  ...  1.636     767     213      18.157     1.161\n",
              "1  3  0.407   255  255  255  ...  0.877     283     234      59.036     0.667\n",
              "2  4  0.592   255  255  255  ...  1.078     633     154     122.335     0.802\n",
              "3  5  1.391   255  255  255  ...  1.564    1321     333      53.253     1.165\n",
              "4  6  0.549   255  255  255  ...  1.024     370     254     118.237     0.738\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc4rFvzkyWCi"
      },
      "source": [
        "from Segment_Filter_Revival import Segmenta  # got image provided segmented"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR2emP4rNjQy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a1bbf6f-9eb8-40be-bcbb-3ce8f847abfc"
      },
      "source": [
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MarquesGabi_Routines' already exists and is not an empty directory.\n",
            "/content/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6cMHOrlNliO"
      },
      "source": [
        "# leitura dos dados\n",
        "df=pd.read_excel(\"FotosTreinoRede.xlsx\")\n",
        "y = df['y']\n",
        "df.drop(['Unnamed: 0','y'], axis='columns', inplace=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQO8d2QbNqj0"
      },
      "source": [
        "X =np.array(df.copy())/255.0 \n",
        "\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIFPGE_-vx3T"
      },
      "source": [
        "Img_Size = 28"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23iKv6bDPWQl"
      },
      "source": [
        "# helper\n",
        "def ynindicator(Y):\n",
        "  N = len(Y)\n",
        "  K = len(set(Y))\n",
        "  I = np.zeros((N, K))\n",
        "  I[np.arange(N), Y] = 1\n",
        "  return I\n",
        "\n",
        "def yback(Y_test):\n",
        "  nrow, ncol = Y_test.shape\n",
        "  y_class = np.zeros(nrow,dtype=int)\n",
        "  y_resp = Y_test\n",
        "  for k in range(nrow):\n",
        "    for kk in range(K):\n",
        "      if(y_resp[k,kk] == 1):\n",
        "        y_class[k] = kk\n",
        "  Y_test = y_class.copy()\n",
        "  return Y_test\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train)\n",
        "K = len(set(Y_train))\n",
        "\n",
        "X_train = X_train.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "Y_train = Y_train.astype(np.int32)\n",
        "Y_train = ynindicator(Y_train)\n",
        "\n",
        "X_test = np.array(X_test )\n",
        "Y_test = np.array(Y_test)\n",
        "X_test = X_test.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "Y_test = Y_test.astype(np.int32)\n",
        "Y_test = ynindicator(Y_test)\n",
        "\n",
        "# the model will be a sequence of layers\n",
        "\n",
        "Description = '3 layers of Convolution: 64, 128, 256 '\n",
        "N1 = 20\n",
        "N2 = 20\n",
        "\n",
        "# make the CNN\n",
        "model = Sequential()\n",
        "model.add(Conv2D(input_shape=(Img_Size, Img_Size, 1), filters=64, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=N1))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=N2))\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(units=K))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "# list of losses: https://keras.io/losses/\n",
        "# list of optimizers: https://keras.io/optimizers/\n",
        "# list of metrics: https://keras.io/metrics/\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpbPQ1FSRG6A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95fc61b6-3f84-42c4-dba7-7c07957a0881"
      },
      "source": [
        "# training the model\n",
        "r = model.fit(X_train, Y_train, validation_data=(X_test,Y_test), \n",
        "              epochs=200, batch_size=32)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "11/11 [==============================] - 3s 158ms/step - loss: 0.5021 - accuracy: 0.7755 - val_loss: 0.6936 - val_accuracy: 0.4898\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 0.3111 - accuracy: 0.8571 - val_loss: 0.6932 - val_accuracy: 0.4898\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 0.2732 - accuracy: 0.8863 - val_loss: 0.6936 - val_accuracy: 0.4898\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 0.2051 - accuracy: 0.9242 - val_loss: 0.6928 - val_accuracy: 0.5102\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 0.1012 - accuracy: 0.9592 - val_loss: 0.6926 - val_accuracy: 0.5102\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 0.1208 - accuracy: 0.9504 - val_loss: 0.6924 - val_accuracy: 0.5102\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 0.0506 - accuracy: 0.9854 - val_loss: 0.6933 - val_accuracy: 0.4898\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 0.0608 - accuracy: 0.9854 - val_loss: 0.6927 - val_accuracy: 0.5102\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 0.0361 - accuracy: 0.9854 - val_loss: 0.6927 - val_accuracy: 0.5102\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 0.0253 - accuracy: 0.9913 - val_loss: 0.6932 - val_accuracy: 0.5102\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.6932 - val_accuracy: 0.5102\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.6933 - val_accuracy: 0.5102\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 0.0140 - accuracy: 0.9971 - val_loss: 0.6954 - val_accuracy: 0.5102\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.6951 - val_accuracy: 0.5102\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 0.0071 - accuracy: 0.9942 - val_loss: 0.6960 - val_accuracy: 0.5102\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.6941 - val_accuracy: 0.5102\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 0.0116 - accuracy: 0.9971 - val_loss: 0.6952 - val_accuracy: 0.5102\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.6972 - val_accuracy: 0.5102\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 2s 137ms/step - loss: 0.0258 - accuracy: 0.9913 - val_loss: 0.6992 - val_accuracy: 0.5102\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.7363 - val_accuracy: 0.5102\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.7164 - val_accuracy: 0.5102\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.6979 - val_accuracy: 0.5102\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 2s 137ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.6896 - val_accuracy: 0.5102\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6965 - val_accuracy: 0.5102\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.7123 - val_accuracy: 0.5102\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 6.7697e-04 - accuracy: 1.0000 - val_loss: 0.7149 - val_accuracy: 0.5102\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7085 - val_accuracy: 0.5102\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7194 - val_accuracy: 0.5102\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 7.4547e-04 - accuracy: 1.0000 - val_loss: 0.7298 - val_accuracy: 0.5102\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7440 - val_accuracy: 0.5102\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7811 - val_accuracy: 0.5102\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 7.4321e-04 - accuracy: 1.0000 - val_loss: 0.7655 - val_accuracy: 0.5102\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 9.5591e-04 - accuracy: 1.0000 - val_loss: 0.7473 - val_accuracy: 0.5102\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 7.7191e-04 - accuracy: 1.0000 - val_loss: 0.7104 - val_accuracy: 0.5102\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7587 - val_accuracy: 0.5102\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 1s 138ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7585 - val_accuracy: 0.5102\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 3.8660e-04 - accuracy: 1.0000 - val_loss: 0.7087 - val_accuracy: 0.5102\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 5.5344e-04 - accuracy: 1.0000 - val_loss: 0.6684 - val_accuracy: 0.5102\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 9.0421e-04 - accuracy: 1.0000 - val_loss: 0.6335 - val_accuracy: 0.5170\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6139 - val_accuracy: 0.5442\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5773 - val_accuracy: 0.8639\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 2s 145ms/step - loss: 5.6594e-04 - accuracy: 1.0000 - val_loss: 0.5703 - val_accuracy: 0.6395\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 3.0976e-04 - accuracy: 1.0000 - val_loss: 0.5714 - val_accuracy: 0.5646\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 4.9299e-04 - accuracy: 1.0000 - val_loss: 0.5640 - val_accuracy: 0.5714\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 3.6394e-04 - accuracy: 1.0000 - val_loss: 0.5212 - val_accuracy: 0.7007\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5552 - val_accuracy: 0.5510\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 2s 137ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.4565 - val_accuracy: 0.5102\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 2s 137ms/step - loss: 3.4163e-04 - accuracy: 1.0000 - val_loss: 2.4785 - val_accuracy: 0.5102\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.8501 - val_accuracy: 0.5102\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 2s 137ms/step - loss: 7.4555e-04 - accuracy: 1.0000 - val_loss: 3.9265 - val_accuracy: 0.5102\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 5.4217e-04 - accuracy: 1.0000 - val_loss: 3.9991 - val_accuracy: 0.5102\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 3.1052e-04 - accuracy: 1.0000 - val_loss: 3.4880 - val_accuracy: 0.5102\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 2.0306e-04 - accuracy: 1.0000 - val_loss: 3.1972 - val_accuracy: 0.5102\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 1.7122e-04 - accuracy: 1.0000 - val_loss: 3.0608 - val_accuracy: 0.5102\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 3.4866e-04 - accuracy: 1.0000 - val_loss: 3.0257 - val_accuracy: 0.5102\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 1.7738e-04 - accuracy: 1.0000 - val_loss: 3.0213 - val_accuracy: 0.5102\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 5.1905e-04 - accuracy: 1.0000 - val_loss: 2.5073 - val_accuracy: 0.5102\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 6.5086e-05 - accuracy: 1.0000 - val_loss: 2.0631 - val_accuracy: 0.5102\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 8.5083e-05 - accuracy: 1.0000 - val_loss: 1.8535 - val_accuracy: 0.5102\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 2.4913e-04 - accuracy: 1.0000 - val_loss: 1.5871 - val_accuracy: 0.5170\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 1s 138ms/step - loss: 1.5266e-04 - accuracy: 1.0000 - val_loss: 1.4099 - val_accuracy: 0.5374\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 3.5655e-04 - accuracy: 1.0000 - val_loss: 1.2531 - val_accuracy: 0.5510\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 3.5345e-04 - accuracy: 1.0000 - val_loss: 1.0713 - val_accuracy: 0.5714\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 2.2435e-04 - accuracy: 1.0000 - val_loss: 0.9729 - val_accuracy: 0.6190\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 1.3368e-04 - accuracy: 1.0000 - val_loss: 1.0601 - val_accuracy: 0.5986\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 2.3967e-04 - accuracy: 1.0000 - val_loss: 1.4333 - val_accuracy: 0.5646\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 2.3666e-04 - accuracy: 1.0000 - val_loss: 1.8963 - val_accuracy: 0.5306\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 7.8343e-05 - accuracy: 1.0000 - val_loss: 2.1767 - val_accuracy: 0.5238\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 7.0419e-05 - accuracy: 1.0000 - val_loss: 1.8532 - val_accuracy: 0.5442\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 1.3902e-04 - accuracy: 1.0000 - val_loss: 1.3015 - val_accuracy: 0.6122\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 4.5628e-05 - accuracy: 1.0000 - val_loss: 0.8348 - val_accuracy: 0.7075\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 2s 137ms/step - loss: 1.1584e-04 - accuracy: 1.0000 - val_loss: 0.6209 - val_accuracy: 0.7619\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 9.3825e-05 - accuracy: 1.0000 - val_loss: 0.4803 - val_accuracy: 0.8163\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 4.8768e-04 - accuracy: 1.0000 - val_loss: 0.6593 - val_accuracy: 0.7483\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 5.9438e-05 - accuracy: 1.0000 - val_loss: 0.6137 - val_accuracy: 0.7619\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 8.1937e-05 - accuracy: 1.0000 - val_loss: 0.5005 - val_accuracy: 0.7959\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 5.3849e-05 - accuracy: 1.0000 - val_loss: 0.3591 - val_accuracy: 0.8571\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 1.0378e-04 - accuracy: 1.0000 - val_loss: 0.2627 - val_accuracy: 0.8912\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 4.9164e-04 - accuracy: 1.0000 - val_loss: 0.1662 - val_accuracy: 0.9388\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 7.2666e-05 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.8980\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 28.8635 - val_accuracy: 0.5102\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 0.0061 - accuracy: 0.9971 - val_loss: 24.3680 - val_accuracy: 0.5102\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 0.0125 - accuracy: 0.9971 - val_loss: 93.5294 - val_accuracy: 0.5102\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 2s 145ms/step - loss: 0.0386 - accuracy: 0.9796 - val_loss: 77.9335 - val_accuracy: 0.5102\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 2s 150ms/step - loss: 0.1798 - accuracy: 0.9417 - val_loss: 122.5355 - val_accuracy: 0.5102\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 0.2733 - accuracy: 0.9300 - val_loss: 57.7317 - val_accuracy: 0.5102\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 0.0654 - accuracy: 0.9796 - val_loss: 30.0206 - val_accuracy: 0.5102\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 0.0526 - accuracy: 0.9738 - val_loss: 43.9432 - val_accuracy: 0.5102\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 0.0249 - accuracy: 0.9883 - val_loss: 130.3498 - val_accuracy: 0.5102\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 112.5629 - val_accuracy: 0.5102\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 103.4523 - val_accuracy: 0.5102\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 0.0082 - accuracy: 0.9971 - val_loss: 109.7341 - val_accuracy: 0.5102\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 100.3815 - val_accuracy: 0.5102\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 84.8426 - val_accuracy: 0.5102\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 67.4250 - val_accuracy: 0.5102\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 56.0073 - val_accuracy: 0.5102\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 46.0284 - val_accuracy: 0.5102\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 37.8818 - val_accuracy: 0.5102\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 32.1144 - val_accuracy: 0.5102\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 2s 137ms/step - loss: 0.0035 - accuracy: 0.9971 - val_loss: 17.5371 - val_accuracy: 0.5102\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 0.0269 - accuracy: 0.9883 - val_loss: 9.3563 - val_accuracy: 0.5102\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 4.8396 - val_accuracy: 0.5170\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 0.0100 - accuracy: 0.9942 - val_loss: 11.4534 - val_accuracy: 0.5102\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 8.4199 - val_accuracy: 0.5102\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 6.4405 - val_accuracy: 0.5102\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.9528 - val_accuracy: 0.5102\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.9835 - val_accuracy: 0.5170\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4524 - val_accuracy: 0.7347\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 6.8563e-04 - accuracy: 1.0000 - val_loss: 0.3654 - val_accuracy: 0.8503\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 0.0033 - accuracy: 0.9971 - val_loss: 0.6312 - val_accuracy: 0.6327\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 7.2747e-04 - accuracy: 1.0000 - val_loss: 3.1736 - val_accuracy: 0.5102\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 0.0126 - accuracy: 0.9971 - val_loss: 5.7472 - val_accuracy: 0.5102\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 2s 137ms/step - loss: 0.0137 - accuracy: 0.9971 - val_loss: 10.2509 - val_accuracy: 0.5102\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 7.2575e-04 - accuracy: 1.0000 - val_loss: 11.9608 - val_accuracy: 0.5102\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 0.0077 - accuracy: 0.9971 - val_loss: 11.4706 - val_accuracy: 0.5102\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 7.6761e-04 - accuracy: 1.0000 - val_loss: 8.5781 - val_accuracy: 0.5102\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 8.2039 - val_accuracy: 0.5102\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 2s 146ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 9.0437 - val_accuracy: 0.5102\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 10.2815 - val_accuracy: 0.5102\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 2s 145ms/step - loss: 5.6615e-04 - accuracy: 1.0000 - val_loss: 9.6036 - val_accuracy: 0.5102\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 4.2868e-04 - accuracy: 1.0000 - val_loss: 8.8242 - val_accuracy: 0.5102\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 2s 145ms/step - loss: 4.2337e-04 - accuracy: 1.0000 - val_loss: 8.0291 - val_accuracy: 0.5102\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 6.4594 - val_accuracy: 0.5102\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 3.1020e-04 - accuracy: 1.0000 - val_loss: 4.8827 - val_accuracy: 0.5102\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 2.5163e-04 - accuracy: 1.0000 - val_loss: 3.8851 - val_accuracy: 0.5102\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 1.9124e-04 - accuracy: 1.0000 - val_loss: 3.2202 - val_accuracy: 0.5102\n",
            "Epoch 127/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 3.9446e-05 - accuracy: 1.0000 - val_loss: 2.6897 - val_accuracy: 0.5102\n",
            "Epoch 128/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 1.2876e-04 - accuracy: 1.0000 - val_loss: 2.3020 - val_accuracy: 0.5102\n",
            "Epoch 129/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 2.8011e-04 - accuracy: 1.0000 - val_loss: 1.8116 - val_accuracy: 0.5442\n",
            "Epoch 130/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 1.4394e-04 - accuracy: 1.0000 - val_loss: 1.3831 - val_accuracy: 0.5850\n",
            "Epoch 131/200\n",
            "11/11 [==============================] - 2s 146ms/step - loss: 8.3331e-05 - accuracy: 1.0000 - val_loss: 1.0828 - val_accuracy: 0.6395\n",
            "Epoch 132/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 1.0318e-04 - accuracy: 1.0000 - val_loss: 0.8637 - val_accuracy: 0.6735\n",
            "Epoch 133/200\n",
            "11/11 [==============================] - 2s 146ms/step - loss: 1.2917e-04 - accuracy: 1.0000 - val_loss: 0.6720 - val_accuracy: 0.7279\n",
            "Epoch 134/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 2.0298e-04 - accuracy: 1.0000 - val_loss: 0.5302 - val_accuracy: 0.7823\n",
            "Epoch 135/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3959 - val_accuracy: 0.6190\n",
            "Epoch 136/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 5.8646e-04 - accuracy: 1.0000 - val_loss: 1.0326 - val_accuracy: 0.7075\n",
            "Epoch 137/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 4.1746e-04 - accuracy: 1.0000 - val_loss: 0.8173 - val_accuracy: 0.7211\n",
            "Epoch 138/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 1.1801e-04 - accuracy: 1.0000 - val_loss: 0.7635 - val_accuracy: 0.7483\n",
            "Epoch 139/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 1.1883e-04 - accuracy: 1.0000 - val_loss: 0.6762 - val_accuracy: 0.7619\n",
            "Epoch 140/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 3.3384e-04 - accuracy: 1.0000 - val_loss: 0.4452 - val_accuracy: 0.8707\n",
            "Epoch 141/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 7.6596 - val_accuracy: 0.5102\n",
            "Epoch 142/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 1.6698e-04 - accuracy: 1.0000 - val_loss: 6.9590 - val_accuracy: 0.5102\n",
            "Epoch 143/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 8.6276e-05 - accuracy: 1.0000 - val_loss: 6.0393 - val_accuracy: 0.5102\n",
            "Epoch 144/200\n",
            "11/11 [==============================] - 2s 145ms/step - loss: 1.4221e-04 - accuracy: 1.0000 - val_loss: 5.4156 - val_accuracy: 0.5102\n",
            "Epoch 145/200\n",
            "11/11 [==============================] - 2s 146ms/step - loss: 2.5518e-04 - accuracy: 1.0000 - val_loss: 4.8743 - val_accuracy: 0.5102\n",
            "Epoch 146/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 1.4051e-04 - accuracy: 1.0000 - val_loss: 4.2580 - val_accuracy: 0.5102\n",
            "Epoch 147/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 5.2227e-05 - accuracy: 1.0000 - val_loss: 3.7577 - val_accuracy: 0.5102\n",
            "Epoch 148/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 1.9698e-04 - accuracy: 1.0000 - val_loss: 3.6716 - val_accuracy: 0.5102\n",
            "Epoch 149/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 1.0465e-04 - accuracy: 1.0000 - val_loss: 3.4813 - val_accuracy: 0.5170\n",
            "Epoch 150/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 1.5901e-04 - accuracy: 1.0000 - val_loss: 3.0878 - val_accuracy: 0.5238\n",
            "Epoch 151/200\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 8.8592e-05 - accuracy: 1.0000 - val_loss: 2.7290 - val_accuracy: 0.5510\n",
            "Epoch 152/200\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 6.9088e-05 - accuracy: 1.0000 - val_loss: 2.3372 - val_accuracy: 0.5850\n",
            "Epoch 153/200\n",
            "11/11 [==============================] - 2s 148ms/step - loss: 2.8647e-04 - accuracy: 1.0000 - val_loss: 1.9754 - val_accuracy: 0.6259\n",
            "Epoch 154/200\n",
            "11/11 [==============================] - 2s 147ms/step - loss: 1.8206e-04 - accuracy: 1.0000 - val_loss: 1.6623 - val_accuracy: 0.6803\n",
            "Epoch 155/200\n",
            "11/11 [==============================] - 2s 147ms/step - loss: 8.6134e-05 - accuracy: 1.0000 - val_loss: 1.5287 - val_accuracy: 0.7007\n",
            "Epoch 156/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 7.0170e-05 - accuracy: 1.0000 - val_loss: 1.3101 - val_accuracy: 0.7347\n",
            "Epoch 157/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 1.2081e-04 - accuracy: 1.0000 - val_loss: 1.2396 - val_accuracy: 0.7483\n",
            "Epoch 158/200\n",
            "11/11 [==============================] - 2s 150ms/step - loss: 2.1885e-04 - accuracy: 1.0000 - val_loss: 0.9093 - val_accuracy: 0.7891\n",
            "Epoch 159/200\n",
            "11/11 [==============================] - 2s 146ms/step - loss: 2.3041e-04 - accuracy: 1.0000 - val_loss: 0.5223 - val_accuracy: 0.8980\n",
            "Epoch 160/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 1.3577e-04 - accuracy: 1.0000 - val_loss: 0.4541 - val_accuracy: 0.9184\n",
            "Epoch 161/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 1.5770e-04 - accuracy: 1.0000 - val_loss: 0.4287 - val_accuracy: 0.9184\n",
            "Epoch 162/200\n",
            "11/11 [==============================] - 2s 148ms/step - loss: 1.7088e-04 - accuracy: 1.0000 - val_loss: 0.4896 - val_accuracy: 0.9116\n",
            "Epoch 163/200\n",
            "11/11 [==============================] - 2s 148ms/step - loss: 7.0874e-05 - accuracy: 1.0000 - val_loss: 0.4919 - val_accuracy: 0.9048\n",
            "Epoch 164/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 1.6225e-04 - accuracy: 1.0000 - val_loss: 0.3646 - val_accuracy: 0.9252\n",
            "Epoch 165/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 3.9822e-04 - accuracy: 1.0000 - val_loss: 0.2224 - val_accuracy: 0.9388\n",
            "Epoch 166/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 7.4523e-05 - accuracy: 1.0000 - val_loss: 0.1799 - val_accuracy: 0.9592\n",
            "Epoch 167/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 5.3623e-05 - accuracy: 1.0000 - val_loss: 0.1650 - val_accuracy: 0.9660\n",
            "Epoch 168/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 9.3509e-04 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 0.9456\n",
            "Epoch 169/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 8.3610e-05 - accuracy: 1.0000 - val_loss: 0.4186 - val_accuracy: 0.8435\n",
            "Epoch 170/200\n",
            "11/11 [==============================] - 2s 148ms/step - loss: 3.8871e-05 - accuracy: 1.0000 - val_loss: 0.4493 - val_accuracy: 0.8435\n",
            "Epoch 171/200\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 2.3250e-04 - accuracy: 1.0000 - val_loss: 0.3915 - val_accuracy: 0.8639\n",
            "Epoch 172/200\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 1.3306e-04 - accuracy: 1.0000 - val_loss: 0.6425 - val_accuracy: 0.7891\n",
            "Epoch 173/200\n",
            "11/11 [==============================] - 2s 157ms/step - loss: 5.5591e-05 - accuracy: 1.0000 - val_loss: 0.5320 - val_accuracy: 0.8231\n",
            "Epoch 174/200\n",
            "11/11 [==============================] - 2s 160ms/step - loss: 4.0742e-05 - accuracy: 1.0000 - val_loss: 0.4185 - val_accuracy: 0.8776\n",
            "Epoch 175/200\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 2.8344e-04 - accuracy: 1.0000 - val_loss: 0.3805 - val_accuracy: 0.8844\n",
            "Epoch 176/200\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 3.9814e-05 - accuracy: 1.0000 - val_loss: 0.3136 - val_accuracy: 0.9048\n",
            "Epoch 177/200\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 9.3026e-05 - accuracy: 1.0000 - val_loss: 0.2640 - val_accuracy: 0.9184\n",
            "Epoch 178/200\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 4.1412e-05 - accuracy: 1.0000 - val_loss: 0.2255 - val_accuracy: 0.9320\n",
            "Epoch 179/200\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 1.3651e-04 - accuracy: 1.0000 - val_loss: 0.1709 - val_accuracy: 0.9592\n",
            "Epoch 180/200\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 1.0722e-04 - accuracy: 1.0000 - val_loss: 0.1563 - val_accuracy: 0.9728\n",
            "Epoch 181/200\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 4.1870e-05 - accuracy: 1.0000 - val_loss: 0.1517 - val_accuracy: 0.9728\n",
            "Epoch 182/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 8.0387e-05 - accuracy: 1.0000 - val_loss: 0.1580 - val_accuracy: 0.9728\n",
            "Epoch 183/200\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 4.2141e-04 - accuracy: 1.0000 - val_loss: 0.1377 - val_accuracy: 0.9796\n",
            "Epoch 184/200\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 1.1526e-04 - accuracy: 1.0000 - val_loss: 0.1350 - val_accuracy: 0.9796\n",
            "Epoch 185/200\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 8.2937e-05 - accuracy: 1.0000 - val_loss: 0.1464 - val_accuracy: 0.9728\n",
            "Epoch 186/200\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 3.9232e-05 - accuracy: 1.0000 - val_loss: 0.1542 - val_accuracy: 0.9728\n",
            "Epoch 187/200\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 5.0796e-05 - accuracy: 1.0000 - val_loss: 0.1576 - val_accuracy: 0.9660\n",
            "Epoch 188/200\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 1.3328e-05 - accuracy: 1.0000 - val_loss: 0.1640 - val_accuracy: 0.9660\n",
            "Epoch 189/200\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 2.1445e-05 - accuracy: 1.0000 - val_loss: 0.1718 - val_accuracy: 0.9728\n",
            "Epoch 190/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 3.5714e-05 - accuracy: 1.0000 - val_loss: 0.1811 - val_accuracy: 0.9728\n",
            "Epoch 191/200\n",
            "11/11 [==============================] - 2s 148ms/step - loss: 2.3973e-05 - accuracy: 1.0000 - val_loss: 0.1922 - val_accuracy: 0.9660\n",
            "Epoch 192/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 1.4198e-04 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9592\n",
            "Epoch 193/200\n",
            "11/11 [==============================] - 2s 147ms/step - loss: 9.2672e-05 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9660\n",
            "Epoch 194/200\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 1.0656e-04 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9728\n",
            "Epoch 195/200\n",
            "11/11 [==============================] - 2s 157ms/step - loss: 2.7016e-04 - accuracy: 1.0000 - val_loss: 0.2865 - val_accuracy: 0.9456\n",
            "Epoch 196/200\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 1.0013e-05 - accuracy: 1.0000 - val_loss: 0.8058 - val_accuracy: 0.8299\n",
            "Epoch 197/200\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 3.0677e-05 - accuracy: 1.0000 - val_loss: 1.1019 - val_accuracy: 0.7823\n",
            "Epoch 198/200\n",
            "11/11 [==============================] - 2s 158ms/step - loss: 1.5842e-05 - accuracy: 1.0000 - val_loss: 1.0443 - val_accuracy: 0.8095\n",
            "Epoch 199/200\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 7.7613e-05 - accuracy: 1.0000 - val_loss: 0.8841 - val_accuracy: 0.8299\n",
            "Epoch 200/200\n",
            "11/11 [==============================] - 2s 148ms/step - loss: 3.3955e-05 - accuracy: 1.0000 - val_loss: 0.7124 - val_accuracy: 0.8639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSTlOSUBWMpj"
      },
      "source": [
        "Y_test = yback(Y_test)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDVY6HbxMOlH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9bbb14d-6758-4ccb-da4d-109e3bcb9f76"
      },
      "source": [
        "# pred_test= model.predict_classes(X_test)\n",
        "pred_test = np.argmax(model.predict(X_test), axis=-1)\n",
        "\n",
        "data = {'y_true': Y_test,'y_predict': pred_test}  # este dado esta no formato de dicionario\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_true','y_predict'])\n",
        "\n",
        "\n",
        "confusion_matrix = pd.crosstab(df['y_true'], df['y_predict'], rownames=['Actual'], colnames=['Predict'])\n",
        "print(confusion_matrix)\n",
        "\n",
        "y_true = df['y_true']\n",
        "y_pred = df['y_predict']\n",
        "\n",
        "  \n",
        "METRICS=sklearn.metrics.classification_report(y_true, y_pred)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predict   0   1\n",
            "Actual         \n",
            "0        53  19\n",
            "1         1  74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7pT2q7traXg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5db81c3-eeb7-41c1-8bc5-19fc373bf1d8"
      },
      "source": [
        "print(METRICS)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.74      0.84        72\n",
            "           1       0.80      0.99      0.88        75\n",
            "\n",
            "    accuracy                           0.86       147\n",
            "   macro avg       0.89      0.86      0.86       147\n",
            "weighted avg       0.89      0.86      0.86       147\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iFNNrlWV9tH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a64ee07-1fd3-4912-91ba-7a6b07117d32"
      },
      "source": [
        "pred_test"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
              "       1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
              "       0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5pq5z8DHeJ0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "883481fc-678a-48b4-90d2-5b55ce356ac3"
      },
      "source": [
        "'''\n",
        "img=ww[4] \n",
        "df=Segmenta(img)\n",
        "df.shape\n",
        "'''"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nimg=ww[4] \\ndf=Segmenta(img)\\ndf.shape\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8ofkAXlS-0F"
      },
      "source": [
        "Sample3 =[4,13,25]\n",
        "\n",
        "for i in range(Repetir):\n",
        "  k = 0\n",
        "  for i in Sample3:\n",
        "    img=ww[i]\n",
        "    if( k > 0):\n",
        "      df_old = df_ann.copy()\n",
        "    df_ann=Segmenta(img)\n",
        "    if(k > 0):\n",
        "      df_ann = pd.concat( [df_ann, df_old], ignore_index = True)\n",
        "    k = k + 1\n",
        "#df_ann = df.copy\n",
        "\n",
        "df_teste = np.array(df_ann)\n",
        "names = df_ann.columns\n",
        "df_teste = pd.DataFrame(df_teste,columns=names)\n",
        "Width = df_ann['Width']\n",
        "#del df_ann['Width']\n",
        "names = df_ann.columns\n",
        "del df_ann['Width']\n",
        "result = np.array(df_ann)\n",
        "result = result.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "prediction= np.argmax(model.predict(result), axis=-1)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "_kfx72YkUYiz",
        "outputId": "994d80ed-9cd7-4138-975c-4e9a045cf567"
      },
      "source": [
        "df_ann"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "      <th>769</th>\n",
              "      <th>770</th>\n",
              "      <th>771</th>\n",
              "      <th>772</th>\n",
              "      <th>773</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>152.933960</td>\n",
              "      <td>163.522308</td>\n",
              "      <td>167.142761</td>\n",
              "      <td>159.192749</td>\n",
              "      <td>156.329559</td>\n",
              "      <td>174.430695</td>\n",
              "      <td>181.089828</td>\n",
              "      <td>189.752518</td>\n",
              "      <td>185.621063</td>\n",
              "      <td>170.343262</td>\n",
              "      <td>168.776321</td>\n",
              "      <td>164.086868</td>\n",
              "      <td>147.659729</td>\n",
              "      <td>134.823334</td>\n",
              "      <td>132.113617</td>\n",
              "      <td>139.754318</td>\n",
              "      <td>139.209991</td>\n",
              "      <td>138.149323</td>\n",
              "      <td>135.443787</td>\n",
              "      <td>136.741226</td>\n",
              "      <td>158.983368</td>\n",
              "      <td>172.812027</td>\n",
              "      <td>169.783478</td>\n",
              "      <td>172.260559</td>\n",
              "      <td>164.994049</td>\n",
              "      <td>157.690079</td>\n",
              "      <td>162.808456</td>\n",
              "      <td>168.930389</td>\n",
              "      <td>138.160034</td>\n",
              "      <td>152.095764</td>\n",
              "      <td>170.384308</td>\n",
              "      <td>163.556213</td>\n",
              "      <td>151.528854</td>\n",
              "      <td>181.248672</td>\n",
              "      <td>178.641876</td>\n",
              "      <td>173.673401</td>\n",
              "      <td>170.006546</td>\n",
              "      <td>167.598450</td>\n",
              "      <td>177.071381</td>\n",
              "      <td>185.629395</td>\n",
              "      <td>...</td>\n",
              "      <td>134.337891</td>\n",
              "      <td>141.956573</td>\n",
              "      <td>162.869720</td>\n",
              "      <td>168.054749</td>\n",
              "      <td>192.675201</td>\n",
              "      <td>223.130859</td>\n",
              "      <td>225.065445</td>\n",
              "      <td>210.953598</td>\n",
              "      <td>214.696014</td>\n",
              "      <td>209.014282</td>\n",
              "      <td>213.030350</td>\n",
              "      <td>215.210007</td>\n",
              "      <td>172.423553</td>\n",
              "      <td>174.099945</td>\n",
              "      <td>173.011307</td>\n",
              "      <td>147.728149</td>\n",
              "      <td>120.856628</td>\n",
              "      <td>141.523499</td>\n",
              "      <td>151.238556</td>\n",
              "      <td>157.650818</td>\n",
              "      <td>166.216553</td>\n",
              "      <td>171.944672</td>\n",
              "      <td>164.761444</td>\n",
              "      <td>156.182037</td>\n",
              "      <td>150.913757</td>\n",
              "      <td>139.446762</td>\n",
              "      <td>126.678162</td>\n",
              "      <td>122.917305</td>\n",
              "      <td>131.530045</td>\n",
              "      <td>138.656158</td>\n",
              "      <td>155.912552</td>\n",
              "      <td>166.542526</td>\n",
              "      <td>172.721588</td>\n",
              "      <td>182.259964</td>\n",
              "      <td>173.525864</td>\n",
              "      <td>221.519333</td>\n",
              "      <td>212.930389</td>\n",
              "      <td>210.687698</td>\n",
              "      <td>214.039276</td>\n",
              "      <td>216.164764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>181.394958</td>\n",
              "      <td>174.922165</td>\n",
              "      <td>158.891022</td>\n",
              "      <td>160.087936</td>\n",
              "      <td>165.700958</td>\n",
              "      <td>175.858368</td>\n",
              "      <td>182.961075</td>\n",
              "      <td>181.787369</td>\n",
              "      <td>175.497116</td>\n",
              "      <td>181.665421</td>\n",
              "      <td>218.825211</td>\n",
              "      <td>210.956787</td>\n",
              "      <td>198.013275</td>\n",
              "      <td>183.713913</td>\n",
              "      <td>185.753723</td>\n",
              "      <td>196.827515</td>\n",
              "      <td>188.916595</td>\n",
              "      <td>168.256012</td>\n",
              "      <td>164.265900</td>\n",
              "      <td>152.173721</td>\n",
              "      <td>140.357651</td>\n",
              "      <td>134.482758</td>\n",
              "      <td>147.408127</td>\n",
              "      <td>164.590195</td>\n",
              "      <td>171.651657</td>\n",
              "      <td>175.814148</td>\n",
              "      <td>172.903183</td>\n",
              "      <td>174.329453</td>\n",
              "      <td>177.975677</td>\n",
              "      <td>171.029510</td>\n",
              "      <td>158.027618</td>\n",
              "      <td>155.785065</td>\n",
              "      <td>165.384033</td>\n",
              "      <td>169.885040</td>\n",
              "      <td>178.610138</td>\n",
              "      <td>181.376648</td>\n",
              "      <td>184.793076</td>\n",
              "      <td>201.556778</td>\n",
              "      <td>223.725937</td>\n",
              "      <td>230.368729</td>\n",
              "      <td>...</td>\n",
              "      <td>223.020584</td>\n",
              "      <td>229.149582</td>\n",
              "      <td>235.545685</td>\n",
              "      <td>232.121704</td>\n",
              "      <td>225.091324</td>\n",
              "      <td>211.364365</td>\n",
              "      <td>197.430176</td>\n",
              "      <td>169.503830</td>\n",
              "      <td>152.163223</td>\n",
              "      <td>146.025131</td>\n",
              "      <td>141.054733</td>\n",
              "      <td>145.826675</td>\n",
              "      <td>195.481186</td>\n",
              "      <td>204.554031</td>\n",
              "      <td>198.573212</td>\n",
              "      <td>194.890686</td>\n",
              "      <td>181.822769</td>\n",
              "      <td>182.759125</td>\n",
              "      <td>185.596634</td>\n",
              "      <td>190.823364</td>\n",
              "      <td>200.338776</td>\n",
              "      <td>204.805054</td>\n",
              "      <td>202.626038</td>\n",
              "      <td>201.094269</td>\n",
              "      <td>189.089233</td>\n",
              "      <td>226.690979</td>\n",
              "      <td>245.864609</td>\n",
              "      <td>238.578827</td>\n",
              "      <td>238.598602</td>\n",
              "      <td>238.271194</td>\n",
              "      <td>233.731689</td>\n",
              "      <td>227.868622</td>\n",
              "      <td>219.976089</td>\n",
              "      <td>211.641983</td>\n",
              "      <td>199.651154</td>\n",
              "      <td>166.966980</td>\n",
              "      <td>153.799805</td>\n",
              "      <td>153.014145</td>\n",
              "      <td>152.437500</td>\n",
              "      <td>156.600006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>152.977386</td>\n",
              "      <td>156.133759</td>\n",
              "      <td>164.130569</td>\n",
              "      <td>174.673523</td>\n",
              "      <td>180.985641</td>\n",
              "      <td>176.593964</td>\n",
              "      <td>165.445602</td>\n",
              "      <td>165.985153</td>\n",
              "      <td>180.607269</td>\n",
              "      <td>205.651611</td>\n",
              "      <td>199.955383</td>\n",
              "      <td>166.295944</td>\n",
              "      <td>158.027084</td>\n",
              "      <td>157.538345</td>\n",
              "      <td>154.940994</td>\n",
              "      <td>160.054459</td>\n",
              "      <td>176.154282</td>\n",
              "      <td>180.998718</td>\n",
              "      <td>181.901840</td>\n",
              "      <td>171.300385</td>\n",
              "      <td>168.735687</td>\n",
              "      <td>173.399597</td>\n",
              "      <td>176.450577</td>\n",
              "      <td>173.501785</td>\n",
              "      <td>168.863937</td>\n",
              "      <td>180.070084</td>\n",
              "      <td>181.346497</td>\n",
              "      <td>184.672256</td>\n",
              "      <td>150.222748</td>\n",
              "      <td>152.432922</td>\n",
              "      <td>160.923538</td>\n",
              "      <td>174.558350</td>\n",
              "      <td>179.037933</td>\n",
              "      <td>177.720703</td>\n",
              "      <td>174.083023</td>\n",
              "      <td>147.336227</td>\n",
              "      <td>127.823402</td>\n",
              "      <td>142.381271</td>\n",
              "      <td>158.925171</td>\n",
              "      <td>174.593430</td>\n",
              "      <td>...</td>\n",
              "      <td>0.538711</td>\n",
              "      <td>1.679815</td>\n",
              "      <td>0.979939</td>\n",
              "      <td>0.114720</td>\n",
              "      <td>1.244232</td>\n",
              "      <td>1.501901</td>\n",
              "      <td>0.360796</td>\n",
              "      <td>0.667545</td>\n",
              "      <td>1.732433</td>\n",
              "      <td>0.810079</td>\n",
              "      <td>0.231962</td>\n",
              "      <td>1.308781</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.009936</td>\n",
              "      <td>1.225639</td>\n",
              "      <td>0.858896</td>\n",
              "      <td>0.925552</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.373066</td>\n",
              "      <td>0.489631</td>\n",
              "      <td>0.538711</td>\n",
              "      <td>1.679815</td>\n",
              "      <td>0.979939</td>\n",
              "      <td>0.114720</td>\n",
              "      <td>1.244232</td>\n",
              "      <td>1.501901</td>\n",
              "      <td>0.360796</td>\n",
              "      <td>0.667545</td>\n",
              "      <td>1.732432</td>\n",
              "      <td>0.810079</td>\n",
              "      <td>0.231962</td>\n",
              "      <td>1.319319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>145.965820</td>\n",
              "      <td>135.034531</td>\n",
              "      <td>123.946251</td>\n",
              "      <td>131.633682</td>\n",
              "      <td>142.175156</td>\n",
              "      <td>143.735855</td>\n",
              "      <td>141.542542</td>\n",
              "      <td>130.475250</td>\n",
              "      <td>135.435760</td>\n",
              "      <td>138.808472</td>\n",
              "      <td>150.824493</td>\n",
              "      <td>166.602341</td>\n",
              "      <td>171.155914</td>\n",
              "      <td>160.926666</td>\n",
              "      <td>154.848694</td>\n",
              "      <td>161.585632</td>\n",
              "      <td>172.310791</td>\n",
              "      <td>178.627640</td>\n",
              "      <td>179.704529</td>\n",
              "      <td>176.887146</td>\n",
              "      <td>177.548599</td>\n",
              "      <td>175.818451</td>\n",
              "      <td>168.578156</td>\n",
              "      <td>161.677460</td>\n",
              "      <td>153.322174</td>\n",
              "      <td>148.624420</td>\n",
              "      <td>148.888580</td>\n",
              "      <td>150.082596</td>\n",
              "      <td>150.735489</td>\n",
              "      <td>147.197571</td>\n",
              "      <td>140.997864</td>\n",
              "      <td>134.183350</td>\n",
              "      <td>135.098602</td>\n",
              "      <td>142.168747</td>\n",
              "      <td>141.806702</td>\n",
              "      <td>129.063370</td>\n",
              "      <td>132.437515</td>\n",
              "      <td>132.066574</td>\n",
              "      <td>146.397293</td>\n",
              "      <td>155.584900</td>\n",
              "      <td>...</td>\n",
              "      <td>131.223206</td>\n",
              "      <td>133.765762</td>\n",
              "      <td>143.735489</td>\n",
              "      <td>155.503387</td>\n",
              "      <td>160.910645</td>\n",
              "      <td>162.573883</td>\n",
              "      <td>174.362778</td>\n",
              "      <td>185.475616</td>\n",
              "      <td>182.577438</td>\n",
              "      <td>170.633682</td>\n",
              "      <td>143.164841</td>\n",
              "      <td>138.407257</td>\n",
              "      <td>166.860443</td>\n",
              "      <td>164.747253</td>\n",
              "      <td>154.415100</td>\n",
              "      <td>143.489502</td>\n",
              "      <td>135.850479</td>\n",
              "      <td>152.618011</td>\n",
              "      <td>145.196869</td>\n",
              "      <td>144.255600</td>\n",
              "      <td>150.421509</td>\n",
              "      <td>159.498764</td>\n",
              "      <td>159.105026</td>\n",
              "      <td>138.321121</td>\n",
              "      <td>125.108932</td>\n",
              "      <td>138.421143</td>\n",
              "      <td>134.003555</td>\n",
              "      <td>131.990738</td>\n",
              "      <td>123.067291</td>\n",
              "      <td>130.294769</td>\n",
              "      <td>147.076187</td>\n",
              "      <td>163.214310</td>\n",
              "      <td>171.854050</td>\n",
              "      <td>177.653961</td>\n",
              "      <td>182.936646</td>\n",
              "      <td>188.098633</td>\n",
              "      <td>183.331451</td>\n",
              "      <td>161.050903</td>\n",
              "      <td>144.867233</td>\n",
              "      <td>148.313293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>98.808861</td>\n",
              "      <td>95.287003</td>\n",
              "      <td>87.248428</td>\n",
              "      <td>101.758629</td>\n",
              "      <td>102.572479</td>\n",
              "      <td>94.502129</td>\n",
              "      <td>89.267021</td>\n",
              "      <td>95.707596</td>\n",
              "      <td>133.453949</td>\n",
              "      <td>133.390305</td>\n",
              "      <td>132.811035</td>\n",
              "      <td>131.902161</td>\n",
              "      <td>133.606720</td>\n",
              "      <td>131.988754</td>\n",
              "      <td>128.851639</td>\n",
              "      <td>113.446350</td>\n",
              "      <td>106.939117</td>\n",
              "      <td>116.719696</td>\n",
              "      <td>134.713348</td>\n",
              "      <td>159.144638</td>\n",
              "      <td>162.981659</td>\n",
              "      <td>145.925888</td>\n",
              "      <td>143.767654</td>\n",
              "      <td>133.666245</td>\n",
              "      <td>130.619492</td>\n",
              "      <td>137.029373</td>\n",
              "      <td>144.822418</td>\n",
              "      <td>133.798218</td>\n",
              "      <td>94.141495</td>\n",
              "      <td>99.075821</td>\n",
              "      <td>87.534904</td>\n",
              "      <td>94.342873</td>\n",
              "      <td>106.618042</td>\n",
              "      <td>101.435883</td>\n",
              "      <td>92.571373</td>\n",
              "      <td>94.867218</td>\n",
              "      <td>123.624115</td>\n",
              "      <td>135.503693</td>\n",
              "      <td>143.194031</td>\n",
              "      <td>142.395676</td>\n",
              "      <td>...</td>\n",
              "      <td>0.526991</td>\n",
              "      <td>0.725090</td>\n",
              "      <td>2.395321</td>\n",
              "      <td>7.701204</td>\n",
              "      <td>11.408154</td>\n",
              "      <td>8.613029</td>\n",
              "      <td>4.000670</td>\n",
              "      <td>4.728388</td>\n",
              "      <td>2.334304</td>\n",
              "      <td>4.151924</td>\n",
              "      <td>2.227885</td>\n",
              "      <td>9.304905</td>\n",
              "      <td>0.762658</td>\n",
              "      <td>1.584375</td>\n",
              "      <td>0.297276</td>\n",
              "      <td>1.075137</td>\n",
              "      <td>1.427015</td>\n",
              "      <td>0.189054</td>\n",
              "      <td>1.411425</td>\n",
              "      <td>3.306192</td>\n",
              "      <td>3.167513</td>\n",
              "      <td>1.883584</td>\n",
              "      <td>1.748151</td>\n",
              "      <td>1.774022</td>\n",
              "      <td>2.123039</td>\n",
              "      <td>1.284625</td>\n",
              "      <td>1.015512</td>\n",
              "      <td>1.187585</td>\n",
              "      <td>0.508233</td>\n",
              "      <td>0.694272</td>\n",
              "      <td>1.666675</td>\n",
              "      <td>2.350537</td>\n",
              "      <td>4.089335</td>\n",
              "      <td>1.970136</td>\n",
              "      <td>2.755598</td>\n",
              "      <td>1.859362</td>\n",
              "      <td>3.579376</td>\n",
              "      <td>1.712283</td>\n",
              "      <td>1.800201</td>\n",
              "      <td>2.141359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>169.943115</td>\n",
              "      <td>157.183594</td>\n",
              "      <td>159.874542</td>\n",
              "      <td>160.449631</td>\n",
              "      <td>166.965698</td>\n",
              "      <td>171.994354</td>\n",
              "      <td>167.610657</td>\n",
              "      <td>136.071609</td>\n",
              "      <td>132.012146</td>\n",
              "      <td>132.851120</td>\n",
              "      <td>137.861099</td>\n",
              "      <td>149.663620</td>\n",
              "      <td>176.710068</td>\n",
              "      <td>176.791229</td>\n",
              "      <td>174.529938</td>\n",
              "      <td>173.047729</td>\n",
              "      <td>151.205719</td>\n",
              "      <td>141.643219</td>\n",
              "      <td>143.164490</td>\n",
              "      <td>154.889740</td>\n",
              "      <td>176.354156</td>\n",
              "      <td>184.211365</td>\n",
              "      <td>180.664917</td>\n",
              "      <td>183.430542</td>\n",
              "      <td>174.641037</td>\n",
              "      <td>174.501297</td>\n",
              "      <td>170.193573</td>\n",
              "      <td>175.416214</td>\n",
              "      <td>188.812042</td>\n",
              "      <td>170.512131</td>\n",
              "      <td>163.374115</td>\n",
              "      <td>158.618912</td>\n",
              "      <td>164.913177</td>\n",
              "      <td>176.105453</td>\n",
              "      <td>164.015182</td>\n",
              "      <td>151.070297</td>\n",
              "      <td>153.582001</td>\n",
              "      <td>152.416656</td>\n",
              "      <td>149.650146</td>\n",
              "      <td>146.307724</td>\n",
              "      <td>...</td>\n",
              "      <td>148.664917</td>\n",
              "      <td>149.329422</td>\n",
              "      <td>155.821594</td>\n",
              "      <td>161.864578</td>\n",
              "      <td>168.349808</td>\n",
              "      <td>177.265610</td>\n",
              "      <td>175.901901</td>\n",
              "      <td>168.090714</td>\n",
              "      <td>156.553391</td>\n",
              "      <td>194.299484</td>\n",
              "      <td>219.778625</td>\n",
              "      <td>231.754333</td>\n",
              "      <td>197.996948</td>\n",
              "      <td>207.522980</td>\n",
              "      <td>217.165787</td>\n",
              "      <td>235.950073</td>\n",
              "      <td>234.409698</td>\n",
              "      <td>215.926651</td>\n",
              "      <td>184.036011</td>\n",
              "      <td>185.592453</td>\n",
              "      <td>165.029938</td>\n",
              "      <td>148.164490</td>\n",
              "      <td>131.345474</td>\n",
              "      <td>132.266052</td>\n",
              "      <td>143.340698</td>\n",
              "      <td>144.017792</td>\n",
              "      <td>147.074631</td>\n",
              "      <td>148.413620</td>\n",
              "      <td>151.147552</td>\n",
              "      <td>152.407974</td>\n",
              "      <td>154.868484</td>\n",
              "      <td>156.419693</td>\n",
              "      <td>164.432281</td>\n",
              "      <td>176.355026</td>\n",
              "      <td>175.211792</td>\n",
              "      <td>173.891937</td>\n",
              "      <td>143.435745</td>\n",
              "      <td>162.928391</td>\n",
              "      <td>177.658417</td>\n",
              "      <td>166.837662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>204.219894</td>\n",
              "      <td>215.777771</td>\n",
              "      <td>224.865738</td>\n",
              "      <td>162.277008</td>\n",
              "      <td>140.875778</td>\n",
              "      <td>148.395844</td>\n",
              "      <td>153.822525</td>\n",
              "      <td>147.119598</td>\n",
              "      <td>151.813278</td>\n",
              "      <td>152.683624</td>\n",
              "      <td>121.581795</td>\n",
              "      <td>87.823311</td>\n",
              "      <td>117.817131</td>\n",
              "      <td>125.203705</td>\n",
              "      <td>125.939049</td>\n",
              "      <td>123.756950</td>\n",
              "      <td>127.593361</td>\n",
              "      <td>127.228401</td>\n",
              "      <td>122.795517</td>\n",
              "      <td>123.674393</td>\n",
              "      <td>126.399689</td>\n",
              "      <td>131.290909</td>\n",
              "      <td>138.893524</td>\n",
              "      <td>141.312515</td>\n",
              "      <td>151.220688</td>\n",
              "      <td>159.851852</td>\n",
              "      <td>166.672073</td>\n",
              "      <td>164.091049</td>\n",
              "      <td>211.319458</td>\n",
              "      <td>228.211426</td>\n",
              "      <td>220.483032</td>\n",
              "      <td>154.391205</td>\n",
              "      <td>136.324860</td>\n",
              "      <td>137.474548</td>\n",
              "      <td>142.553238</td>\n",
              "      <td>153.103394</td>\n",
              "      <td>156.826401</td>\n",
              "      <td>131.739197</td>\n",
              "      <td>81.648918</td>\n",
              "      <td>71.830246</td>\n",
              "      <td>...</td>\n",
              "      <td>181.931320</td>\n",
              "      <td>186.344910</td>\n",
              "      <td>187.807877</td>\n",
              "      <td>187.331802</td>\n",
              "      <td>185.368820</td>\n",
              "      <td>179.060196</td>\n",
              "      <td>178.070999</td>\n",
              "      <td>174.979172</td>\n",
              "      <td>176.984573</td>\n",
              "      <td>183.668991</td>\n",
              "      <td>182.420517</td>\n",
              "      <td>174.477615</td>\n",
              "      <td>95.944458</td>\n",
              "      <td>62.033955</td>\n",
              "      <td>99.703705</td>\n",
              "      <td>136.969910</td>\n",
              "      <td>185.418213</td>\n",
              "      <td>224.828705</td>\n",
              "      <td>227.250015</td>\n",
              "      <td>219.769287</td>\n",
              "      <td>175.731506</td>\n",
              "      <td>156.568680</td>\n",
              "      <td>179.983810</td>\n",
              "      <td>191.494614</td>\n",
              "      <td>200.993073</td>\n",
              "      <td>194.716034</td>\n",
              "      <td>189.976852</td>\n",
              "      <td>185.496918</td>\n",
              "      <td>186.638885</td>\n",
              "      <td>188.300156</td>\n",
              "      <td>184.957565</td>\n",
              "      <td>187.557861</td>\n",
              "      <td>185.131958</td>\n",
              "      <td>174.843353</td>\n",
              "      <td>174.402023</td>\n",
              "      <td>170.756180</td>\n",
              "      <td>178.175934</td>\n",
              "      <td>194.705246</td>\n",
              "      <td>199.230713</td>\n",
              "      <td>185.170532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>220.614594</td>\n",
              "      <td>217.602646</td>\n",
              "      <td>216.969238</td>\n",
              "      <td>217.440704</td>\n",
              "      <td>207.582413</td>\n",
              "      <td>197.246750</td>\n",
              "      <td>184.072708</td>\n",
              "      <td>178.041794</td>\n",
              "      <td>171.203735</td>\n",
              "      <td>165.765152</td>\n",
              "      <td>165.849777</td>\n",
              "      <td>156.083725</td>\n",
              "      <td>152.036636</td>\n",
              "      <td>157.890503</td>\n",
              "      <td>168.108810</td>\n",
              "      <td>177.099731</td>\n",
              "      <td>183.061859</td>\n",
              "      <td>186.457794</td>\n",
              "      <td>173.596268</td>\n",
              "      <td>153.377945</td>\n",
              "      <td>157.479111</td>\n",
              "      <td>164.483917</td>\n",
              "      <td>182.274124</td>\n",
              "      <td>199.835739</td>\n",
              "      <td>203.526199</td>\n",
              "      <td>200.304886</td>\n",
              "      <td>197.413849</td>\n",
              "      <td>196.201080</td>\n",
              "      <td>236.193954</td>\n",
              "      <td>240.410507</td>\n",
              "      <td>243.269684</td>\n",
              "      <td>242.444092</td>\n",
              "      <td>237.454056</td>\n",
              "      <td>235.189529</td>\n",
              "      <td>235.437347</td>\n",
              "      <td>239.046936</td>\n",
              "      <td>241.393600</td>\n",
              "      <td>225.185944</td>\n",
              "      <td>195.154678</td>\n",
              "      <td>172.377426</td>\n",
              "      <td>...</td>\n",
              "      <td>173.838043</td>\n",
              "      <td>217.231110</td>\n",
              "      <td>219.480164</td>\n",
              "      <td>222.579193</td>\n",
              "      <td>227.274506</td>\n",
              "      <td>220.777771</td>\n",
              "      <td>213.253876</td>\n",
              "      <td>199.385437</td>\n",
              "      <td>169.181351</td>\n",
              "      <td>159.918762</td>\n",
              "      <td>157.078415</td>\n",
              "      <td>154.241425</td>\n",
              "      <td>151.204971</td>\n",
              "      <td>141.936005</td>\n",
              "      <td>137.838577</td>\n",
              "      <td>132.806396</td>\n",
              "      <td>131.905060</td>\n",
              "      <td>128.159988</td>\n",
              "      <td>129.373505</td>\n",
              "      <td>131.360352</td>\n",
              "      <td>140.072891</td>\n",
              "      <td>154.248886</td>\n",
              "      <td>179.108627</td>\n",
              "      <td>189.537781</td>\n",
              "      <td>192.560715</td>\n",
              "      <td>198.941879</td>\n",
              "      <td>189.563370</td>\n",
              "      <td>139.383118</td>\n",
              "      <td>126.176888</td>\n",
              "      <td>147.273773</td>\n",
              "      <td>169.827194</td>\n",
              "      <td>207.407303</td>\n",
              "      <td>214.396622</td>\n",
              "      <td>216.333679</td>\n",
              "      <td>206.541351</td>\n",
              "      <td>174.512543</td>\n",
              "      <td>162.579025</td>\n",
              "      <td>159.511642</td>\n",
              "      <td>151.404800</td>\n",
              "      <td>149.958038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>106.416328</td>\n",
              "      <td>99.758148</td>\n",
              "      <td>92.525230</td>\n",
              "      <td>93.700974</td>\n",
              "      <td>100.473183</td>\n",
              "      <td>105.412064</td>\n",
              "      <td>105.579758</td>\n",
              "      <td>86.269142</td>\n",
              "      <td>103.259430</td>\n",
              "      <td>146.115829</td>\n",
              "      <td>156.404388</td>\n",
              "      <td>156.594971</td>\n",
              "      <td>152.000000</td>\n",
              "      <td>145.675522</td>\n",
              "      <td>139.008896</td>\n",
              "      <td>135.254578</td>\n",
              "      <td>131.223114</td>\n",
              "      <td>130.412872</td>\n",
              "      <td>132.699707</td>\n",
              "      <td>129.460770</td>\n",
              "      <td>107.635132</td>\n",
              "      <td>85.809814</td>\n",
              "      <td>84.833252</td>\n",
              "      <td>64.306381</td>\n",
              "      <td>61.326462</td>\n",
              "      <td>71.046310</td>\n",
              "      <td>106.157936</td>\n",
              "      <td>135.098526</td>\n",
              "      <td>92.823090</td>\n",
              "      <td>98.038513</td>\n",
              "      <td>106.755386</td>\n",
              "      <td>113.333542</td>\n",
              "      <td>109.184845</td>\n",
              "      <td>99.175819</td>\n",
              "      <td>96.487122</td>\n",
              "      <td>95.652885</td>\n",
              "      <td>116.124512</td>\n",
              "      <td>144.781143</td>\n",
              "      <td>155.385223</td>\n",
              "      <td>156.402969</td>\n",
              "      <td>...</td>\n",
              "      <td>0.570569</td>\n",
              "      <td>0.512089</td>\n",
              "      <td>1.360042</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.981875</td>\n",
              "      <td>2.676584</td>\n",
              "      <td>1.477993</td>\n",
              "      <td>1.842447</td>\n",
              "      <td>16.759516</td>\n",
              "      <td>107.985847</td>\n",
              "      <td>131.668076</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.974146</td>\n",
              "      <td>0.056530</td>\n",
              "      <td>0.171027</td>\n",
              "      <td>1.344721</td>\n",
              "      <td>0.749838</td>\n",
              "      <td>0.330905</td>\n",
              "      <td>1.512192</td>\n",
              "      <td>1.186621</td>\n",
              "      <td>0.080948</td>\n",
              "      <td>1.237338</td>\n",
              "      <td>1.471256</td>\n",
              "      <td>0.289970</td>\n",
              "      <td>0.797476</td>\n",
              "      <td>1.692316</td>\n",
              "      <td>0.564823</td>\n",
              "      <td>0.506344</td>\n",
              "      <td>1.354297</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000889</td>\n",
              "      <td>1.685100</td>\n",
              "      <td>1.704661</td>\n",
              "      <td>1.471940</td>\n",
              "      <td>3.207517</td>\n",
              "      <td>21.498989</td>\n",
              "      <td>104.684525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>153.946945</td>\n",
              "      <td>160.250092</td>\n",
              "      <td>174.971802</td>\n",
              "      <td>184.186737</td>\n",
              "      <td>122.858604</td>\n",
              "      <td>110.095505</td>\n",
              "      <td>107.630135</td>\n",
              "      <td>159.937912</td>\n",
              "      <td>174.929703</td>\n",
              "      <td>180.514648</td>\n",
              "      <td>163.070297</td>\n",
              "      <td>165.816040</td>\n",
              "      <td>172.625870</td>\n",
              "      <td>171.272415</td>\n",
              "      <td>184.151825</td>\n",
              "      <td>186.668884</td>\n",
              "      <td>140.550598</td>\n",
              "      <td>151.430450</td>\n",
              "      <td>160.103378</td>\n",
              "      <td>168.329071</td>\n",
              "      <td>165.034119</td>\n",
              "      <td>172.274948</td>\n",
              "      <td>181.229172</td>\n",
              "      <td>176.818237</td>\n",
              "      <td>170.674423</td>\n",
              "      <td>163.388260</td>\n",
              "      <td>127.043251</td>\n",
              "      <td>77.720787</td>\n",
              "      <td>151.189392</td>\n",
              "      <td>152.373810</td>\n",
              "      <td>149.619949</td>\n",
              "      <td>149.491852</td>\n",
              "      <td>150.052032</td>\n",
              "      <td>122.986710</td>\n",
              "      <td>113.278877</td>\n",
              "      <td>149.910416</td>\n",
              "      <td>172.908203</td>\n",
              "      <td>181.307800</td>\n",
              "      <td>179.848663</td>\n",
              "      <td>179.757553</td>\n",
              "      <td>...</td>\n",
              "      <td>173.977936</td>\n",
              "      <td>162.316925</td>\n",
              "      <td>152.439133</td>\n",
              "      <td>168.684021</td>\n",
              "      <td>195.939880</td>\n",
              "      <td>201.395325</td>\n",
              "      <td>196.374634</td>\n",
              "      <td>176.326996</td>\n",
              "      <td>164.092285</td>\n",
              "      <td>151.626541</td>\n",
              "      <td>141.489670</td>\n",
              "      <td>135.707703</td>\n",
              "      <td>251.301788</td>\n",
              "      <td>247.273117</td>\n",
              "      <td>187.910416</td>\n",
              "      <td>159.396591</td>\n",
              "      <td>177.489899</td>\n",
              "      <td>194.562393</td>\n",
              "      <td>184.301315</td>\n",
              "      <td>180.341080</td>\n",
              "      <td>183.933868</td>\n",
              "      <td>187.781494</td>\n",
              "      <td>187.028351</td>\n",
              "      <td>183.031326</td>\n",
              "      <td>177.967514</td>\n",
              "      <td>174.808304</td>\n",
              "      <td>179.362244</td>\n",
              "      <td>185.937592</td>\n",
              "      <td>176.164307</td>\n",
              "      <td>174.721817</td>\n",
              "      <td>172.425720</td>\n",
              "      <td>167.402481</td>\n",
              "      <td>190.044189</td>\n",
              "      <td>201.247314</td>\n",
              "      <td>190.810501</td>\n",
              "      <td>178.393341</td>\n",
              "      <td>175.672104</td>\n",
              "      <td>164.130890</td>\n",
              "      <td>142.344559</td>\n",
              "      <td>129.911667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0           1           2    ...         781         782         783\n",
              "0    152.933960  163.522308  167.142761  ...  210.687698  214.039276  216.164764\n",
              "1    181.394958  174.922165  158.891022  ...  153.014145  152.437500  156.600006\n",
              "2    152.977386  156.133759  164.130569  ...    0.810079    0.231962    1.319319\n",
              "3    145.965820  135.034531  123.946251  ...  161.050903  144.867233  148.313293\n",
              "4     98.808861   95.287003   87.248428  ...    1.712283    1.800201    2.141359\n",
              "..          ...         ...         ...  ...         ...         ...         ...\n",
              "145  169.943115  157.183594  159.874542  ...  162.928391  177.658417  166.837662\n",
              "146  204.219894  215.777771  224.865738  ...  194.705246  199.230713  185.170532\n",
              "147  220.614594  217.602646  216.969238  ...  159.511642  151.404800  149.958038\n",
              "148  106.416328   99.758148   92.525230  ...    3.207517   21.498989  104.684525\n",
              "149  153.946945  160.250092  174.971802  ...  164.130890  142.344559  129.911667\n",
              "\n",
              "[150 rows x 784 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31usb3UnY7lD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47c87880-6f9e-4857-ba6c-0622b202b8d7"
      },
      "source": [
        "df_teste.shape # por que esta saindo 100 ???????"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 785)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVHUUaL8XXs-"
      },
      "source": [
        "#df_ann"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QBV18nYTaNE"
      },
      "source": [
        "img_graos = []\n",
        "Width_new = []\n",
        "k = 0\n",
        "for i in prediction:\n",
        "  if( i == 0):\n",
        "    img_graos.append(df_teste.iloc[k,:])\n",
        "    Width_new.append(Width.iloc[k])\n",
        "\n",
        "  k = k +1\n",
        "\n",
        "img_graos = pd.DataFrame(img_graos, columns=names )\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMCLCNQobH-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d455ad87-3939-42cf-f023-b3efbf4e9586"
      },
      "source": [
        "img_graos.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(98, 785)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "touLevDmbBx5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fd0af9a-198e-462c-ea1e-3514fd789a81"
      },
      "source": [
        "prediction"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
              "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "       0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4RSVgX4UhbC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6cf4900-51c4-4e32-bd7c-a1c8bfcfeacc"
      },
      "source": [
        "img_graos.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(98, 785)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LkA4vHp-f6_"
      },
      "source": [
        "Width=np.array(Width_new)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjRbWgmX_LFH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a048ff2-56c1-4288-aef9-5c744dcb7b9c"
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_paper_fev_2021\n",
        "%cd marquesgabi_paper_fev_2021\n",
        "\n",
        "from Get_PSDArea_Revival import PSDArea\n",
        "from histogram_fev_2021 import PSD\n",
        "#from GetBetterSegm import GetBetter"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'marquesgabi_paper_fev_2021' already exists and is not an empty directory.\n",
            "/content/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines/marquesgabi_paper_fev_2021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAG_I6FwCvFr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "795ee6cc-15b5-4492-846c-79dd6230ad8b"
      },
      "source": [
        "\n",
        "!git clone https://github.com/ucfilho/marquesgabi_out_2020\n",
        "#!git clone https://github.com/marquesgabi/Doutorado\n",
        "%cd marquesgabi_out_2020\n",
        "#%cd Doutorado\n",
        "#PSD_imageJ = 'Amostra7.csv' \n",
        "#PSD_new = pd.read_csv(PSD_imageJ,sep=';')\n",
        "#encoding='utf8'\n",
        "\n",
        "PSD_imageJ = 'Areas_ImageJ.csv'\n",
        "PSD_new = pd.read_csv(PSD_imageJ)\n",
        "print(PSD_new.head(3))\n",
        "''''''"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'marquesgabi_out_2020' already exists and is not an empty directory.\n",
            "/content/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines/marquesgabi_paper_fev_2021/marquesgabi_out_2020\n",
            "   Juntas   Area\n",
            "0       1  2.001\n",
            "1       2  0.820\n",
            "2       3  1.270\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_1WIM8w7poO"
      },
      "source": [
        "Area_All, Diameter_All=PSDArea(img_graos) "
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB3gOFPeDtoH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c005ad8-e8fe-4093-f264-4d8849ec0527"
      },
      "source": [
        "Width.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(98,)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkB2l0K0YEjz",
        "outputId": "0aa9ad74-abae-4b34-c0a3-cdc61ecf87d6"
      },
      "source": [
        "Width"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([165, 163, 106, 182, 101, 180, 141, 150, 147, 102, 169, 162, 104,\n",
              "       182, 200, 130, 174, 171, 147, 117, 130, 107, 111, 121, 126, 177,\n",
              "       146, 128, 155, 129, 152, 130, 134, 170, 119, 107, 154, 160, 185,\n",
              "       134, 103, 145, 156, 193, 151, 172, 188, 194, 199, 189, 132, 172,\n",
              "       155, 192, 156, 128, 132, 158, 182, 120, 192, 156, 110, 115, 146,\n",
              "       132, 125, 163, 106, 198, 155, 169, 200, 188, 115, 164, 120, 153,\n",
              "       154, 183, 152, 106, 185, 178, 147, 132, 169, 102, 113, 124, 140,\n",
              "       167, 123, 167, 110, 191, 192, 150])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nO6cSz2dIqb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5b559d1-545b-4379-f0fa-91885c80e9b5"
      },
      "source": [
        "img_graos.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(98, 785)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PekBHQOT_6CP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "7b5d6f29-2a52-4c50-e8dc-1c79757f95b1"
      },
      "source": [
        "img_graos.head()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Width</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "      <th>769</th>\n",
              "      <th>770</th>\n",
              "      <th>771</th>\n",
              "      <th>772</th>\n",
              "      <th>773</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>165.0</td>\n",
              "      <td>181.394958</td>\n",
              "      <td>174.922165</td>\n",
              "      <td>158.891022</td>\n",
              "      <td>160.087936</td>\n",
              "      <td>165.700958</td>\n",
              "      <td>175.858368</td>\n",
              "      <td>182.961075</td>\n",
              "      <td>181.787369</td>\n",
              "      <td>175.497116</td>\n",
              "      <td>181.665421</td>\n",
              "      <td>218.825211</td>\n",
              "      <td>210.956787</td>\n",
              "      <td>198.013275</td>\n",
              "      <td>183.713913</td>\n",
              "      <td>185.753723</td>\n",
              "      <td>196.827515</td>\n",
              "      <td>188.916595</td>\n",
              "      <td>168.256012</td>\n",
              "      <td>164.265900</td>\n",
              "      <td>152.173721</td>\n",
              "      <td>140.357651</td>\n",
              "      <td>134.482758</td>\n",
              "      <td>147.408127</td>\n",
              "      <td>164.590195</td>\n",
              "      <td>171.651657</td>\n",
              "      <td>175.814148</td>\n",
              "      <td>172.903183</td>\n",
              "      <td>174.329453</td>\n",
              "      <td>177.975677</td>\n",
              "      <td>171.029510</td>\n",
              "      <td>158.027618</td>\n",
              "      <td>155.785065</td>\n",
              "      <td>165.384033</td>\n",
              "      <td>169.885040</td>\n",
              "      <td>178.610138</td>\n",
              "      <td>181.376648</td>\n",
              "      <td>184.793076</td>\n",
              "      <td>201.556778</td>\n",
              "      <td>223.725937</td>\n",
              "      <td>...</td>\n",
              "      <td>223.020584</td>\n",
              "      <td>229.149582</td>\n",
              "      <td>235.545685</td>\n",
              "      <td>232.121704</td>\n",
              "      <td>225.091324</td>\n",
              "      <td>211.364365</td>\n",
              "      <td>197.430176</td>\n",
              "      <td>169.503830</td>\n",
              "      <td>152.163223</td>\n",
              "      <td>146.025131</td>\n",
              "      <td>141.054733</td>\n",
              "      <td>145.826675</td>\n",
              "      <td>195.481186</td>\n",
              "      <td>204.554031</td>\n",
              "      <td>198.573212</td>\n",
              "      <td>194.890686</td>\n",
              "      <td>181.822769</td>\n",
              "      <td>182.759125</td>\n",
              "      <td>185.596634</td>\n",
              "      <td>190.823364</td>\n",
              "      <td>200.338776</td>\n",
              "      <td>204.805054</td>\n",
              "      <td>202.626038</td>\n",
              "      <td>201.094269</td>\n",
              "      <td>189.089233</td>\n",
              "      <td>226.690979</td>\n",
              "      <td>245.864609</td>\n",
              "      <td>238.578827</td>\n",
              "      <td>238.598602</td>\n",
              "      <td>238.271194</td>\n",
              "      <td>233.731689</td>\n",
              "      <td>227.868622</td>\n",
              "      <td>219.976089</td>\n",
              "      <td>211.641983</td>\n",
              "      <td>199.651154</td>\n",
              "      <td>166.966980</td>\n",
              "      <td>153.799805</td>\n",
              "      <td>153.014145</td>\n",
              "      <td>152.437500</td>\n",
              "      <td>156.600006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>163.0</td>\n",
              "      <td>152.977386</td>\n",
              "      <td>156.133759</td>\n",
              "      <td>164.130569</td>\n",
              "      <td>174.673523</td>\n",
              "      <td>180.985641</td>\n",
              "      <td>176.593964</td>\n",
              "      <td>165.445602</td>\n",
              "      <td>165.985153</td>\n",
              "      <td>180.607269</td>\n",
              "      <td>205.651611</td>\n",
              "      <td>199.955383</td>\n",
              "      <td>166.295944</td>\n",
              "      <td>158.027084</td>\n",
              "      <td>157.538345</td>\n",
              "      <td>154.940994</td>\n",
              "      <td>160.054459</td>\n",
              "      <td>176.154282</td>\n",
              "      <td>180.998718</td>\n",
              "      <td>181.901840</td>\n",
              "      <td>171.300385</td>\n",
              "      <td>168.735687</td>\n",
              "      <td>173.399597</td>\n",
              "      <td>176.450577</td>\n",
              "      <td>173.501785</td>\n",
              "      <td>168.863937</td>\n",
              "      <td>180.070084</td>\n",
              "      <td>181.346497</td>\n",
              "      <td>184.672256</td>\n",
              "      <td>150.222748</td>\n",
              "      <td>152.432922</td>\n",
              "      <td>160.923538</td>\n",
              "      <td>174.558350</td>\n",
              "      <td>179.037933</td>\n",
              "      <td>177.720703</td>\n",
              "      <td>174.083023</td>\n",
              "      <td>147.336227</td>\n",
              "      <td>127.823402</td>\n",
              "      <td>142.381271</td>\n",
              "      <td>158.925171</td>\n",
              "      <td>...</td>\n",
              "      <td>0.538711</td>\n",
              "      <td>1.679815</td>\n",
              "      <td>0.979939</td>\n",
              "      <td>0.114720</td>\n",
              "      <td>1.244232</td>\n",
              "      <td>1.501901</td>\n",
              "      <td>0.360796</td>\n",
              "      <td>0.667545</td>\n",
              "      <td>1.732433</td>\n",
              "      <td>0.810079</td>\n",
              "      <td>0.231962</td>\n",
              "      <td>1.308781</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.009936</td>\n",
              "      <td>1.225639</td>\n",
              "      <td>0.858896</td>\n",
              "      <td>0.925552</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.373066</td>\n",
              "      <td>0.489631</td>\n",
              "      <td>0.538711</td>\n",
              "      <td>1.679815</td>\n",
              "      <td>0.979939</td>\n",
              "      <td>0.114720</td>\n",
              "      <td>1.244232</td>\n",
              "      <td>1.501901</td>\n",
              "      <td>0.360796</td>\n",
              "      <td>0.667545</td>\n",
              "      <td>1.732432</td>\n",
              "      <td>0.810079</td>\n",
              "      <td>0.231962</td>\n",
              "      <td>1.319319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>106.0</td>\n",
              "      <td>145.965820</td>\n",
              "      <td>135.034531</td>\n",
              "      <td>123.946251</td>\n",
              "      <td>131.633682</td>\n",
              "      <td>142.175156</td>\n",
              "      <td>143.735855</td>\n",
              "      <td>141.542542</td>\n",
              "      <td>130.475250</td>\n",
              "      <td>135.435760</td>\n",
              "      <td>138.808472</td>\n",
              "      <td>150.824493</td>\n",
              "      <td>166.602341</td>\n",
              "      <td>171.155914</td>\n",
              "      <td>160.926666</td>\n",
              "      <td>154.848694</td>\n",
              "      <td>161.585632</td>\n",
              "      <td>172.310791</td>\n",
              "      <td>178.627640</td>\n",
              "      <td>179.704529</td>\n",
              "      <td>176.887146</td>\n",
              "      <td>177.548599</td>\n",
              "      <td>175.818451</td>\n",
              "      <td>168.578156</td>\n",
              "      <td>161.677460</td>\n",
              "      <td>153.322174</td>\n",
              "      <td>148.624420</td>\n",
              "      <td>148.888580</td>\n",
              "      <td>150.082596</td>\n",
              "      <td>150.735489</td>\n",
              "      <td>147.197571</td>\n",
              "      <td>140.997864</td>\n",
              "      <td>134.183350</td>\n",
              "      <td>135.098602</td>\n",
              "      <td>142.168747</td>\n",
              "      <td>141.806702</td>\n",
              "      <td>129.063370</td>\n",
              "      <td>132.437515</td>\n",
              "      <td>132.066574</td>\n",
              "      <td>146.397293</td>\n",
              "      <td>...</td>\n",
              "      <td>131.223206</td>\n",
              "      <td>133.765762</td>\n",
              "      <td>143.735489</td>\n",
              "      <td>155.503387</td>\n",
              "      <td>160.910645</td>\n",
              "      <td>162.573883</td>\n",
              "      <td>174.362778</td>\n",
              "      <td>185.475616</td>\n",
              "      <td>182.577438</td>\n",
              "      <td>170.633682</td>\n",
              "      <td>143.164841</td>\n",
              "      <td>138.407257</td>\n",
              "      <td>166.860443</td>\n",
              "      <td>164.747253</td>\n",
              "      <td>154.415100</td>\n",
              "      <td>143.489502</td>\n",
              "      <td>135.850479</td>\n",
              "      <td>152.618011</td>\n",
              "      <td>145.196869</td>\n",
              "      <td>144.255600</td>\n",
              "      <td>150.421509</td>\n",
              "      <td>159.498764</td>\n",
              "      <td>159.105026</td>\n",
              "      <td>138.321121</td>\n",
              "      <td>125.108932</td>\n",
              "      <td>138.421143</td>\n",
              "      <td>134.003555</td>\n",
              "      <td>131.990738</td>\n",
              "      <td>123.067291</td>\n",
              "      <td>130.294769</td>\n",
              "      <td>147.076187</td>\n",
              "      <td>163.214310</td>\n",
              "      <td>171.854050</td>\n",
              "      <td>177.653961</td>\n",
              "      <td>182.936646</td>\n",
              "      <td>188.098633</td>\n",
              "      <td>183.331451</td>\n",
              "      <td>161.050903</td>\n",
              "      <td>144.867233</td>\n",
              "      <td>148.313293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>182.0</td>\n",
              "      <td>131.242615</td>\n",
              "      <td>134.639053</td>\n",
              "      <td>135.686401</td>\n",
              "      <td>146.171600</td>\n",
              "      <td>152.355042</td>\n",
              "      <td>158.840240</td>\n",
              "      <td>166.875748</td>\n",
              "      <td>165.100601</td>\n",
              "      <td>157.674561</td>\n",
              "      <td>167.591721</td>\n",
              "      <td>179.846176</td>\n",
              "      <td>181.751495</td>\n",
              "      <td>179.952682</td>\n",
              "      <td>181.372803</td>\n",
              "      <td>180.355042</td>\n",
              "      <td>172.875748</td>\n",
              "      <td>167.822495</td>\n",
              "      <td>163.858002</td>\n",
              "      <td>177.585815</td>\n",
              "      <td>203.372803</td>\n",
              "      <td>205.875748</td>\n",
              "      <td>183.733734</td>\n",
              "      <td>158.378723</td>\n",
              "      <td>151.325455</td>\n",
              "      <td>160.952682</td>\n",
              "      <td>165.378708</td>\n",
              "      <td>164.787003</td>\n",
              "      <td>134.893494</td>\n",
              "      <td>131.786987</td>\n",
              "      <td>132.248535</td>\n",
              "      <td>142.479309</td>\n",
              "      <td>151.875748</td>\n",
              "      <td>155.633133</td>\n",
              "      <td>153.479294</td>\n",
              "      <td>159.337296</td>\n",
              "      <td>148.662720</td>\n",
              "      <td>140.443802</td>\n",
              "      <td>156.940842</td>\n",
              "      <td>168.710068</td>\n",
              "      <td>...</td>\n",
              "      <td>158.698227</td>\n",
              "      <td>136.035522</td>\n",
              "      <td>126.609482</td>\n",
              "      <td>152.988174</td>\n",
              "      <td>158.248535</td>\n",
              "      <td>155.834320</td>\n",
              "      <td>151.893509</td>\n",
              "      <td>152.982254</td>\n",
              "      <td>152.970428</td>\n",
              "      <td>137.715988</td>\n",
              "      <td>122.964508</td>\n",
              "      <td>120.313614</td>\n",
              "      <td>150.550308</td>\n",
              "      <td>151.177536</td>\n",
              "      <td>151.207123</td>\n",
              "      <td>161.964493</td>\n",
              "      <td>165.792923</td>\n",
              "      <td>174.005936</td>\n",
              "      <td>180.710068</td>\n",
              "      <td>175.384644</td>\n",
              "      <td>168.568069</td>\n",
              "      <td>178.236694</td>\n",
              "      <td>188.710083</td>\n",
              "      <td>196.781082</td>\n",
              "      <td>199.266281</td>\n",
              "      <td>192.875748</td>\n",
              "      <td>175.349121</td>\n",
              "      <td>186.828415</td>\n",
              "      <td>185.325455</td>\n",
              "      <td>166.875748</td>\n",
              "      <td>156.372803</td>\n",
              "      <td>160.171600</td>\n",
              "      <td>163.053268</td>\n",
              "      <td>152.946762</td>\n",
              "      <td>143.798828</td>\n",
              "      <td>154.662735</td>\n",
              "      <td>159.313629</td>\n",
              "      <td>147.538483</td>\n",
              "      <td>121.094681</td>\n",
              "      <td>123.840256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>101.0</td>\n",
              "      <td>209.705429</td>\n",
              "      <td>214.385559</td>\n",
              "      <td>221.094513</td>\n",
              "      <td>225.629150</td>\n",
              "      <td>222.967346</td>\n",
              "      <td>225.200684</td>\n",
              "      <td>228.778351</td>\n",
              "      <td>225.974915</td>\n",
              "      <td>229.742889</td>\n",
              "      <td>231.922867</td>\n",
              "      <td>231.181854</td>\n",
              "      <td>223.824127</td>\n",
              "      <td>220.402924</td>\n",
              "      <td>222.793274</td>\n",
              "      <td>219.998047</td>\n",
              "      <td>223.198517</td>\n",
              "      <td>223.053635</td>\n",
              "      <td>218.853256</td>\n",
              "      <td>216.084900</td>\n",
              "      <td>213.793777</td>\n",
              "      <td>210.609650</td>\n",
              "      <td>207.471527</td>\n",
              "      <td>211.954025</td>\n",
              "      <td>216.820999</td>\n",
              "      <td>211.757294</td>\n",
              "      <td>215.129883</td>\n",
              "      <td>215.711792</td>\n",
              "      <td>216.631317</td>\n",
              "      <td>207.439575</td>\n",
              "      <td>216.608673</td>\n",
              "      <td>225.723282</td>\n",
              "      <td>230.370865</td>\n",
              "      <td>230.797974</td>\n",
              "      <td>231.628296</td>\n",
              "      <td>232.566620</td>\n",
              "      <td>232.964447</td>\n",
              "      <td>231.259018</td>\n",
              "      <td>230.566345</td>\n",
              "      <td>230.444275</td>\n",
              "      <td>...</td>\n",
              "      <td>175.506042</td>\n",
              "      <td>172.499481</td>\n",
              "      <td>175.585739</td>\n",
              "      <td>180.934219</td>\n",
              "      <td>187.322433</td>\n",
              "      <td>191.725906</td>\n",
              "      <td>193.107941</td>\n",
              "      <td>195.803741</td>\n",
              "      <td>197.185974</td>\n",
              "      <td>197.164795</td>\n",
              "      <td>196.991760</td>\n",
              "      <td>197.500153</td>\n",
              "      <td>173.690704</td>\n",
              "      <td>173.627594</td>\n",
              "      <td>172.054901</td>\n",
              "      <td>169.945892</td>\n",
              "      <td>166.959518</td>\n",
              "      <td>157.637878</td>\n",
              "      <td>135.565735</td>\n",
              "      <td>123.435745</td>\n",
              "      <td>139.343018</td>\n",
              "      <td>162.116272</td>\n",
              "      <td>180.231155</td>\n",
              "      <td>189.134003</td>\n",
              "      <td>189.016479</td>\n",
              "      <td>188.208130</td>\n",
              "      <td>185.430054</td>\n",
              "      <td>178.370743</td>\n",
              "      <td>173.069412</td>\n",
              "      <td>172.381836</td>\n",
              "      <td>178.243134</td>\n",
              "      <td>183.928833</td>\n",
              "      <td>187.471252</td>\n",
              "      <td>189.950989</td>\n",
              "      <td>192.208008</td>\n",
              "      <td>196.006866</td>\n",
              "      <td>199.418503</td>\n",
              "      <td>202.228790</td>\n",
              "      <td>204.295761</td>\n",
              "      <td>209.282928</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Width           0           1  ...         781         782         783\n",
              "1  165.0  181.394958  174.922165  ...  153.014145  152.437500  156.600006\n",
              "2  163.0  152.977386  156.133759  ...    0.810079    0.231962    1.319319\n",
              "3  106.0  145.965820  135.034531  ...  161.050903  144.867233  148.313293\n",
              "5  182.0  131.242615  134.639053  ...  147.538483  121.094681  123.840256\n",
              "6  101.0  209.705429  214.385559  ...  202.228790  204.295761  209.282928\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaZPe_AxNBK9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "a47f04db-97dd-40c7-b77c-1c1022a83355"
      },
      "source": [
        "PSD_new.head()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Juntas</th>\n",
              "      <th>Area</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2.001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1.270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1.162</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Juntas   Area\n",
              "0       1  2.001\n",
              "1       2  0.820\n",
              "2       3  1.270\n",
              "3       4  0.958\n",
              "4       5  1.162"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vmhG2LgCabC"
      },
      "source": [
        "# \n",
        "Area = df_ImgJ['Area'].values\n",
        "# Area = np.concatenate( (Area, [lost_value] ) )\n",
        "\n",
        "Diam1 = [ (4*A/np.pi)**0.5 for A in Area]\n",
        "\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79MY9ZHxBW37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70c173ba-4e91-435c-8e4d-619c3ac8210d"
      },
      "source": [
        "len(Diameter_All)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KooHVpH5k2mZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12373d15-920a-443b-f149-6e084010f46c"
      },
      "source": [
        "#\n",
        "\n",
        "PSD_new['Area'].shape"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(95,)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFcOxMmjJjpL"
      },
      "source": [
        "#PSD_new.shape"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPWCPPf7bzsf"
      },
      "source": [
        "#lost_value = float(PSD_new.columns[1])\n",
        "#Area2 = np.array(PSD_new.iloc[:,1])\n",
        "#Area2 = np.concatenate( (Area2, [lost_value] ) )\n",
        "Area2 = PSD_new['Area'].values\n",
        "for A in Area2:\n",
        "  Diam1.append((4*A/np.pi)**0.5) \n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfk_fNXGDK5_"
      },
      "source": [
        "wt1 = np.ones(len(Diam1)) / len(Diam1)*100\n",
        "wt2 = np.ones(len(Diameter_All)) / len(Diameter_All)*100\n",
        "X = pd.DataFrame([Diam1,Diameter_All])\n",
        "wts = pd.DataFrame([wt1,wt2])\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWf2nmnEp6yX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "60dbb6b2-3fee-4e6b-ef35-5ab686089d37"
      },
      "source": [
        "X"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>229</th>\n",
              "      <th>230</th>\n",
              "      <th>231</th>\n",
              "      <th>232</th>\n",
              "      <th>233</th>\n",
              "      <th>234</th>\n",
              "      <th>235</th>\n",
              "      <th>236</th>\n",
              "      <th>237</th>\n",
              "      <th>238</th>\n",
              "      <th>239</th>\n",
              "      <th>240</th>\n",
              "      <th>241</th>\n",
              "      <th>242</th>\n",
              "      <th>243</th>\n",
              "      <th>244</th>\n",
              "      <th>245</th>\n",
              "      <th>246</th>\n",
              "      <th>247</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "      <th>256</th>\n",
              "      <th>257</th>\n",
              "      <th>258</th>\n",
              "      <th>259</th>\n",
              "      <th>260</th>\n",
              "      <th>261</th>\n",
              "      <th>262</th>\n",
              "      <th>263</th>\n",
              "      <th>264</th>\n",
              "      <th>265</th>\n",
              "      <th>266</th>\n",
              "      <th>267</th>\n",
              "      <th>268</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.280599</td>\n",
              "      <td>0.719867</td>\n",
              "      <td>0.868192</td>\n",
              "      <td>1.330818</td>\n",
              "      <td>0.836067</td>\n",
              "      <td>0.923618</td>\n",
              "      <td>0.955465</td>\n",
              "      <td>0.904113</td>\n",
              "      <td>0.697408</td>\n",
              "      <td>0.911127</td>\n",
              "      <td>1.045198</td>\n",
              "      <td>0.970012</td>\n",
              "      <td>0.579772</td>\n",
              "      <td>0.628255</td>\n",
              "      <td>0.600272</td>\n",
              "      <td>0.659885</td>\n",
              "      <td>0.934581</td>\n",
              "      <td>0.731273</td>\n",
              "      <td>0.777682</td>\n",
              "      <td>1.113042</td>\n",
              "      <td>0.753568</td>\n",
              "      <td>0.874039</td>\n",
              "      <td>0.918781</td>\n",
              "      <td>0.970012</td>\n",
              "      <td>0.623168</td>\n",
              "      <td>1.355934</td>\n",
              "      <td>0.932536</td>\n",
              "      <td>0.906925</td>\n",
              "      <td>0.858607</td>\n",
              "      <td>0.660849</td>\n",
              "      <td>0.952796</td>\n",
              "      <td>1.028621</td>\n",
              "      <td>0.891348</td>\n",
              "      <td>0.856380</td>\n",
              "      <td>0.575363</td>\n",
              "      <td>1.260557</td>\n",
              "      <td>1.048239</td>\n",
              "      <td>0.606602</td>\n",
              "      <td>0.860088</td>\n",
              "      <td>0.769452</td>\n",
              "      <td>...</td>\n",
              "      <td>1.550444</td>\n",
              "      <td>0.782578</td>\n",
              "      <td>1.469061</td>\n",
              "      <td>1.053087</td>\n",
              "      <td>1.267607</td>\n",
              "      <td>0.7744</td>\n",
              "      <td>1.378748</td>\n",
              "      <td>1.363893</td>\n",
              "      <td>1.299352</td>\n",
              "      <td>1.287045</td>\n",
              "      <td>1.118178</td>\n",
              "      <td>0.947435</td>\n",
              "      <td>1.521848</td>\n",
              "      <td>1.352644</td>\n",
              "      <td>1.155694</td>\n",
              "      <td>1.601345</td>\n",
              "      <td>1.274619</td>\n",
              "      <td>1.422384</td>\n",
              "      <td>1.340826</td>\n",
              "      <td>1.172646</td>\n",
              "      <td>1.149065</td>\n",
              "      <td>1.45906</td>\n",
              "      <td>1.248377</td>\n",
              "      <td>1.336546</td>\n",
              "      <td>0.960117</td>\n",
              "      <td>1.486723</td>\n",
              "      <td>1.427745</td>\n",
              "      <td>1.350288</td>\n",
              "      <td>0.756098</td>\n",
              "      <td>1.259041</td>\n",
              "      <td>1.134568</td>\n",
              "      <td>1.654913</td>\n",
              "      <td>1.120453</td>\n",
              "      <td>1.117608</td>\n",
              "      <td>0.91531</td>\n",
              "      <td>1.163927</td>\n",
              "      <td>1.306681</td>\n",
              "      <td>1.152936</td>\n",
              "      <td>1.30473</td>\n",
              "      <td>1.306681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.279895</td>\n",
              "      <td>1.034866</td>\n",
              "      <td>0.857406</td>\n",
              "      <td>1.279969</td>\n",
              "      <td>0.740435</td>\n",
              "      <td>1.199364</td>\n",
              "      <td>1.033677</td>\n",
              "      <td>1.176646</td>\n",
              "      <td>1.059947</td>\n",
              "      <td>0.755850</td>\n",
              "      <td>1.190880</td>\n",
              "      <td>1.116660</td>\n",
              "      <td>0.851185</td>\n",
              "      <td>1.334250</td>\n",
              "      <td>1.332627</td>\n",
              "      <td>0.916061</td>\n",
              "      <td>1.174541</td>\n",
              "      <td>1.067142</td>\n",
              "      <td>1.045960</td>\n",
              "      <td>0.895736</td>\n",
              "      <td>0.959917</td>\n",
              "      <td>0.756940</td>\n",
              "      <td>0.870718</td>\n",
              "      <td>0.840857</td>\n",
              "      <td>0.887875</td>\n",
              "      <td>1.134555</td>\n",
              "      <td>1.089550</td>\n",
              "      <td>0.901968</td>\n",
              "      <td>1.196475</td>\n",
              "      <td>0.992516</td>\n",
              "      <td>1.036940</td>\n",
              "      <td>1.063981</td>\n",
              "      <td>1.034372</td>\n",
              "      <td>1.320812</td>\n",
              "      <td>0.766387</td>\n",
              "      <td>0.697145</td>\n",
              "      <td>1.054971</td>\n",
              "      <td>1.208551</td>\n",
              "      <td>1.259422</td>\n",
              "      <td>1.039430</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 269 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2    ...       266      267       268\n",
              "0  1.280599  0.719867  0.868192  ...  1.152936  1.30473  1.306681\n",
              "1  1.279895  1.034866  0.857406  ...       NaN      NaN       NaN\n",
              "\n",
              "[2 rows x 269 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzFRjY4BLtbh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a4fd391-553a-4812-eac6-efaee623830b"
      },
      "source": [
        "Diameter_All"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.2798949664323076,\n",
              " 1.0348655368389381,\n",
              " 0.8574062621743879,\n",
              " 1.2799688290450868,\n",
              " 0.7404352088732734,\n",
              " 1.1993641844784313,\n",
              " 1.0336768757537775,\n",
              " 1.1766463379876717,\n",
              " 1.0599469086806317,\n",
              " 0.7558504449547874,\n",
              " 1.1908798363888629,\n",
              " 1.1166602966045986,\n",
              " 0.8511845023113964,\n",
              " 1.3342495843062947,\n",
              " 1.3326268716427017,\n",
              " 0.9160614126068177,\n",
              " 1.1745413860183187,\n",
              " 1.067142104196661,\n",
              " 1.0459601914453895,\n",
              " 0.8957364695383886,\n",
              " 0.9599166288692309,\n",
              " 0.7569400534200263,\n",
              " 0.8707182901108771,\n",
              " 0.8408574141712454,\n",
              " 0.8878749076035309,\n",
              " 1.1345552274592623,\n",
              " 1.0895496348895501,\n",
              " 0.9019681601051743,\n",
              " 1.1964748070837572,\n",
              " 0.9925163031631931,\n",
              " 1.0369401381082037,\n",
              " 1.0639806278892454,\n",
              " 1.0343717687046676,\n",
              " 1.320811724670132,\n",
              " 0.7663866134327456,\n",
              " 0.6971450878551626,\n",
              " 1.0549706787622295,\n",
              " 1.2085508829350433,\n",
              " 1.2594222280796918,\n",
              " 1.0394298515268439,\n",
              " 0.6967585440622804,\n",
              " 1.1953411290207776,\n",
              " 1.084080633146399,\n",
              " 1.381167436108383,\n",
              " 1.193824838900442,\n",
              " 1.2654995411249033,\n",
              " 1.5138788205734408,\n",
              " 1.4778181943186668,\n",
              " 1.4105032024956483,\n",
              " 1.2342269031422655,\n",
              " 0.9535697716006324,\n",
              " 1.27457133855121,\n",
              " 1.1155361887010455,\n",
              " 1.5507249677003363,\n",
              " 1.079700491463545,\n",
              " 0.8713840280767597,\n",
              " 0.8737281686356362,\n",
              " 1.2295563261395341,\n",
              " 1.2824859776495448,\n",
              " 0.7782502498377168,\n",
              " 1.3422989071301665,\n",
              " 1.164176322210752,\n",
              " 0.7133960623512403,\n",
              " 0.7544059835665137,\n",
              " 1.099032404067409,\n",
              " 0.9080049480486178,\n",
              " 0.9473973555309126,\n",
              " 1.2100183857994598,\n",
              " 0.7827012512318345,\n",
              " 1.3450874183567758,\n",
              " 0.9697077667083048,\n",
              " 1.2299354063115413,\n",
              " 1.4528667618538986,\n",
              " 1.2192587247457563,\n",
              " 0.7283541476632568,\n",
              " 1.2721380272418086,\n",
              " 1.0390172501918813,\n",
              " 1.0589370204738615,\n",
              " 1.192634109961629,\n",
              " 1.1477252113184173,\n",
              " 0.9926057633736737,\n",
              " 0.7261486490181581,\n",
              " 1.2647028475839452,\n",
              " 1.259208686997801,\n",
              " 1.0439467917123926,\n",
              " 0.8678837674664837,\n",
              " 1.133453849306999,\n",
              " 0.9820074787127192,\n",
              " 0.9058297094074966,\n",
              " 0.9123368784853954,\n",
              " 1.0484203128949652,\n",
              " 1.0905602794960758,\n",
              " 0.8835664066456196,\n",
              " 1.3407308890385141,\n",
              " 0.8064145839213869,\n",
              " 1.3353077669888638,\n",
              " 1.374011128149272,\n",
              " 1.178506649565076]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OieAXw_by3nz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "d219a35e-83ea-4617-e165-cf276e69b274"
      },
      "source": [
        "A = plt.hist(X,weights=wts,bins=7)\n",
        "plt.legend(['True','CNN'])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fbaec121e10>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WryLryB9ovi3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8747a86e-b9f8-4c5e-c49b-fe4cbff33336"
      },
      "source": [
        "print('ImgJ:','media=',np.mean(np.array(Diam1)),'desvio=',np.std(np.array(Diam1)),'pontos=',len(Diam1))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ImgJ: media= 1.0865462723070898 desvio= 0.279391220003608 pontos= 269\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_Nyv-Nopbkc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df568ad5-db02-4842-c837-f7689030dd9d"
      },
      "source": [
        "print('Software:','media=',np.mean(np.array(Diameter_All)),'desvio=',np.std(np.array(Diameter_All)),'pontos=',len(Diameter_All))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Software: media= 1.0779777744275163 desvio= 0.20656294718616838 pontos= 98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eE6PjA0SZ8ZQ"
      },
      "source": [
        "# Software: media= 1.3185563233999378 desvio= 0.2728642468732428 pontos= 66 theshold =0.8 e repete=80\n",
        "# Software: media= 1.2650227960747715 desvio= 0.22942393421076387 pontos= 20 theshold =0.5 e repete=40"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpdrvEySy8Ij",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d892d9ed-612d-482d-cf1f-842a62717f70"
      },
      "source": [
        "np.mean(np.array(Diameter_All))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0779777744275163"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMK89w-fzCVe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "01d49b7f-3604-439b-aa5f-2a59cb3640b9"
      },
      "source": [
        "# Freq1 = [19.12043703, 29.22484843, 19.35872174, 20.82190224, 11.47409056] # avarage 4 samples\n",
        "Freq1 = [20.69301557, 28.55598044, 18.50768331, 22.7106327, 8.905907357] # avarage 10 samples\n",
        "#Freq2 = [16.93792791, 31.38008965, 24.93810752, 18.56158392, 6.233810752, 0.4]\n",
        "Freq2 = [16.93792791, 31.38008965, 24.93810752, 18.56158392, 6.633810752]\n",
        "Freq3 = [22.22489, 30.15078, 25.10463, 19.30926, 2.810434]\n",
        "barWidth = 0.25\n",
        "\n",
        "br1 = range(len(Freq1))\n",
        "# Set position of bar on X axis\n",
        "br2 = [x + barWidth for x in br1]\n",
        "br3 = [x + barWidth for x in br2]\n",
        "# labels = [0.8, 1.0, 1.2, 1.4, 1.6, 1.8]\n",
        "labels = [0.8, 1.0, 1.2, 1.4, 1.6]\n",
        "\n",
        "xx=[]\n",
        "for a in labels:\n",
        "  xx.append(str(a))\n",
        "plt.bar(br1, Freq1 , color=\"green\", align=\"center\", width=0.3, tick_label= xx) \n",
        "plt.bar(br2, Freq2 , color=\"red\", align=\"center\", width=0.3, tick_label= xx)\n",
        "plt.bar(br3, Freq3 , color=\"blue\", align=\"center\", width=0.3, tick_label= xx)\n",
        "plt.legend(['CNN 1','CNN 2','True'])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fbaec6de450>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}