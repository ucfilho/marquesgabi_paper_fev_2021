{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PSD_histogram_final_amostra_03_nov_25_2021.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ucfilho/marquesgabi_paper_fev_2021/blob/main/defesa/PSD_histogram_final_amostra_03_nov_25_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sog7Z9pyhUD_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import zipfile\n",
        "#import random\n",
        "from random import randint\n",
        "from PIL import Image\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "#import scikit-image\n",
        "import skimage\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
        "from sklearn.metrics import r2_score\n",
        "from google.colab import files"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZEvJvfoibE4"
      },
      "source": [
        "#!pip install mahotas"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf_a6PJ1iUnT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f1d7076f-9125-4446-b60f-856c9c9a9835"
      },
      "source": [
        "'''\n",
        "import mahotas.features.texture as mht\n",
        "import mahotas.features\n",
        "'''"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nimport mahotas.features.texture as mht\\nimport mahotas.features\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "_VcTdaNVh9EE",
        "outputId": "4e89ed07-0873-4fb0-b1d3-662e05fbc4c6"
      },
      "source": [
        "'''\n",
        "!git clone https://github.com/ucfilho/marquesgabi_fev_2020 #clonar do Github\n",
        "%cd marquesgabi_fev_2020\n",
        "import Go2BlackWhite\n",
        "import Go2Mahotas\n",
        "'''"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n!git clone https://github.com/ucfilho/marquesgabi_fev_2020 #clonar do Github\\n%cd marquesgabi_fev_2020\\nimport Go2BlackWhite\\nimport Go2Mahotas\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UZ30b1EVQhq"
      },
      "source": [
        "def BlackWhite(Transfere,Size):\n",
        "\n",
        "  img_name=[]\n",
        "  xw=[]\n",
        "  ww=[]\n",
        "\n",
        "  with zipfile.ZipFile(Transfere, \"r\") as f:\n",
        "    for name in f.namelist():\n",
        "      img_name.append(name)\n",
        "      #xw.append(cv2.imread(name))\n",
        "      xw.append(cv2.resize(cv2.imread(name),(Size,Size)))\n",
        "\n",
        "  nrow=len(img_name)\n",
        "  ncol=Size*Size\n",
        "  pw=np.zeros((nrow,ncol))\n",
        "  #pw=[]\n",
        "  for i in range(nrow):\n",
        "    ww.append(cv2.cvtColor(np.array(xw[i]), cv2.COLOR_BGR2GRAY))\n",
        "    pw[i,:]=ww[i].ravel()\n",
        "  return ww,img_name"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v7SRrc8mH2N",
        "outputId": "b1a51cb1-3618-4ffe-918d-04d680ac8909"
      },
      "source": [
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "%cd Doutorado\n",
        "\n",
        "Transfere='Fotos_Grandes_3cdAmostra.zip' \n",
        "file_name = zipfile.ZipFile(Transfere, 'r')\n",
        "file_name.extractall()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Doutorado' already exists and is not an empty directory.\n",
            "/content/Doutorado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqIYzUcnrdMp",
        "outputId": "698b2c9e-2fa0-4893-b5d8-27fd0a806aa3"
      },
      "source": [
        "labels =[]\n",
        "with zipfile.ZipFile(Transfere, \"r\") as f:\n",
        "  for f in f.namelist():\n",
        "    labels.append(f)\n",
        "print(labels)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Fotos_Grandes-3cdAmostra/Q6-8-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-8-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-8-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-4.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kA4IWSmasoD"
      },
      "source": [
        "Size=1200 # tamanho da foto\n",
        "# ww,img_name=Go2BlackWhite.BlackWhite(Transfere,Size) #Pegamos a primeira foto Grande\n",
        "ww,img_name=BlackWhite(Transfere,Size) #Pegamos a primeira foto Grande\n",
        "img=ww[4] \n",
        "# this is the big image we want to segment \n",
        "# ww[0], change it if you want to segment another picture"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHgqAnaFyCjp",
        "outputId": "a452069c-606e-4b87-8b11-85a102222092"
      },
      "source": [
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MarquesGabi_Routines' already exists and is not an empty directory.\n",
            "/content/Doutorado/MarquesGabi_Routines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDEGUiuubwuZ"
      },
      "source": [
        "FILE='SugarSample03.zip'\n",
        "img_name=[]\n",
        "x_original = [] \n",
        "\n",
        "data_file ='xls'\n",
        "\n",
        "\n",
        "file_name = zipfile.ZipFile(FILE, 'r')\n",
        "file_name.extractall()\n",
        "\n",
        "k = 0\n",
        "with zipfile.ZipFile(FILE, \"r\") as f:\n",
        "    for name in f.namelist():\n",
        "      if(name[-3:] == data_file):\n",
        "        #df =pd.read_csv(name)\n",
        "        if( k > 0):\n",
        "          df_old = df_ImgJ.copy()\n",
        "        df_ImgJ = pd.read_excel(name)\n",
        "        df_ImgJ = df_ImgJ.drop(labels=[0], axis=0)\n",
        "        if(k > 0):\n",
        "          df_ImgJ = pd.concat( [df_ImgJ, df_old], ignore_index = True)\n",
        "        k = k + 1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbQ0tal0etXx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd3b092e-a179-4cec-f739-dcbf083352e4"
      },
      "source": [
        "f.namelist()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Results_03_02.xls', 'Results_03_03.xls', 'Results_03_01.xls']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMBJ6C-YdF3q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "b0f82c18-8ba8-4b73-c286-f24bbd586bb4"
      },
      "source": [
        "df_ImgJ.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Area</th>\n",
              "      <th>Mean</th>\n",
              "      <th>Min</th>\n",
              "      <th>Max</th>\n",
              "      <th>Major</th>\n",
              "      <th>Minor</th>\n",
              "      <th>Angle</th>\n",
              "      <th>Feret</th>\n",
              "      <th>FeretX</th>\n",
              "      <th>FeretY</th>\n",
              "      <th>FeretAngle</th>\n",
              "      <th>MinFeret</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>1.288</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>1.383</td>\n",
              "      <td>1.185</td>\n",
              "      <td>5.847</td>\n",
              "      <td>1.636</td>\n",
              "      <td>767</td>\n",
              "      <td>213</td>\n",
              "      <td>18.157</td>\n",
              "      <td>1.161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>0.407</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>0.814</td>\n",
              "      <td>0.637</td>\n",
              "      <td>62.186</td>\n",
              "      <td>0.877</td>\n",
              "      <td>283</td>\n",
              "      <td>234</td>\n",
              "      <td>59.036</td>\n",
              "      <td>0.667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>0.592</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>0.925</td>\n",
              "      <td>0.815</td>\n",
              "      <td>117.923</td>\n",
              "      <td>1.078</td>\n",
              "      <td>633</td>\n",
              "      <td>154</td>\n",
              "      <td>122.335</td>\n",
              "      <td>0.802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>1.391</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>1.435</td>\n",
              "      <td>1.235</td>\n",
              "      <td>29.966</td>\n",
              "      <td>1.564</td>\n",
              "      <td>1321</td>\n",
              "      <td>333</td>\n",
              "      <td>53.253</td>\n",
              "      <td>1.165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>0.549</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>0.923</td>\n",
              "      <td>0.758</td>\n",
              "      <td>136.396</td>\n",
              "      <td>1.024</td>\n",
              "      <td>370</td>\n",
              "      <td>254</td>\n",
              "      <td>118.237</td>\n",
              "      <td>0.738</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Area  Mean  Min  Max  ...  Feret  FeretX  FeretY  FeretAngle  MinFeret\n",
              "0  2  1.288   255  255  255  ...  1.636     767     213      18.157     1.161\n",
              "1  3  0.407   255  255  255  ...  0.877     283     234      59.036     0.667\n",
              "2  4  0.592   255  255  255  ...  1.078     633     154     122.335     0.802\n",
              "3  5  1.391   255  255  255  ...  1.564    1321     333      53.253     1.165\n",
              "4  6  0.549   255  255  255  ...  1.024     370     254     118.237     0.738\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc4rFvzkyWCi"
      },
      "source": [
        "from Segment_Filter import Segmenta  # got image provided segmented"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnTtH3KDP863"
      },
      "source": [
        "df=Segmenta(img)\n",
        "Img_Size = 28"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN5MN5a_v4np",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0ba9575-ebb2-45cd-8b91-a5538ba9a797"
      },
      "source": [
        "print(df)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Width           0           1  ...         781         782         783\n",
            "0     200  103.494392  105.113602  ...    1.519200    0.252800    1.304800\n",
            "1     132  116.942154  233.709839  ...  144.087250  146.259888  134.298447\n",
            "2     194  185.190125  133.348068  ...  140.648621  139.418625  128.894867\n",
            "3     173  101.537971  108.782310  ...  110.173080  120.968300  122.511757\n",
            "4     197    3.738695    4.029400  ...  161.828476  160.564728  165.091766\n",
            "5     115  175.014191  170.677261  ...  128.499954  129.518036  130.477264\n",
            "6     175  185.502396  170.964783  ...  102.687988  122.759987  171.809586\n",
            "7     113  155.500290  161.158051  ...  175.369812  179.962097  181.214478\n",
            "8     117  208.677917  206.866379  ...  251.119354  252.737213  251.655930\n",
            "9     156   76.993431   79.936226  ...    1.519395    0.416831    0.570677\n",
            "10    157  225.878616  248.420868  ...  155.369476  156.147675  157.115509\n",
            "11    164   57.961926   79.106483  ...  129.792984  129.532425  131.008331\n",
            "12    173  169.728790  159.256592  ...    1.025694    0.168499    1.349895\n",
            "13    162  104.283035  102.391251  ...  124.506477  123.023933  111.224190\n",
            "14    183  123.252563  120.683716  ...  175.849747  159.313080  160.508163\n",
            "15    162   97.367630   88.851852  ...    0.793629    0.239750    1.375553\n",
            "16    157  156.441437  163.686615  ...  124.404678  128.030991  130.637360\n",
            "17    119  172.709351  167.401382  ...   99.145332  102.688583  102.557091\n",
            "18    176  145.610031  150.017563  ...  221.305283  229.778915  231.134796\n",
            "19    198  119.642258  123.366394  ...   24.344555    9.424956    3.916539\n",
            "20    123  196.679443  190.753479  ...  183.346252  182.830017  184.238815\n",
            "21    127  195.740814  229.297913  ...  228.079849  209.626450  146.752121\n",
            "22    188  170.915344  174.192383  ...  148.851517  155.219543  159.466721\n",
            "23    157  154.267975  219.715820  ...  119.272293  121.141182  117.087463\n",
            "24    188  195.979614  196.339050  ...  197.630142  197.406967  195.958328\n",
            "25    179  135.993835  131.981644  ...  159.306152  140.844452  125.993721\n",
            "26    153  188.899963  185.456757  ...  218.554672  238.386948  245.063873\n",
            "27    193  128.703796  131.860458  ...  173.111252  198.225311  202.848114\n",
            "28    168   65.638893   71.833336  ...  144.611115  138.250000  128.027786\n",
            "29    185   88.423027   95.205200  ...  202.333572  200.967087  231.346558\n",
            "30    123   99.664223  137.164520  ...    0.000000    0.541675    1.000000\n",
            "31    183  115.827774  114.599365  ...    1.281854    0.153871    1.341963\n",
            "32    152  212.858719  191.517273  ...  164.135040  168.484756  174.033936\n",
            "33    166  117.654083  100.008560  ...  187.452454  165.914200  176.905350\n",
            "34    110  179.781494  180.561646  ...  194.443954  170.215866  177.795349\n",
            "35    129  148.786957  154.620285  ...  133.862625  196.433685  231.594666\n",
            "36    135   38.977993   43.368885  ...    0.346722    0.494870    1.457833\n",
            "37    196   87.510201  130.061218  ...    1.081633    0.224490    0.224490\n",
            "38    101  218.920990  235.059616  ...  198.893158  213.161163  238.162445\n",
            "39    116  131.485123  126.777641  ...    0.024970    0.747919    1.541023\n",
            "40    129  143.212006  143.379913  ...    1.023496    0.075116    0.679767\n",
            "41    160  170.411865  156.646881  ...  150.713745  142.206863  125.403122\n",
            "42    108  114.128937  120.554176  ...  241.292175  241.395050  233.465012\n",
            "43    150    0.101511    1.168178  ...    1.004800    0.047289    0.980622\n",
            "44    145    2.747111   13.390820  ...  154.818451  155.526535  149.952194\n",
            "45    131  146.186050  151.914383  ...    1.000000    1.000000    1.000000\n",
            "46    168  164.250000  158.194443  ...  175.361115  178.305557  193.972229\n",
            "47    151  205.553925  197.885406  ...  254.275513  254.193573  251.916077\n",
            "48    153  179.333466  181.658066  ...  169.856354  178.597092  179.729034\n",
            "49    168  110.805557  110.361115  ...    0.888889    0.194444    1.361111\n",
            "\n",
            "[50 rows x 785 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR2emP4rNjQy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "786d1050-7949-4948-966e-19cec122c7a3"
      },
      "source": [
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MarquesGabi_Routines' already exists and is not an empty directory.\n",
            "/content/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6cMHOrlNliO"
      },
      "source": [
        "# leitura dos dados\n",
        "df=pd.read_excel(\"FotosTreinoRede.xlsx\")\n",
        "y = df['y']\n",
        "df.drop(['Unnamed: 0','y'], axis='columns', inplace=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQO8d2QbNqj0"
      },
      "source": [
        "X =np.array(df.copy())/255.0 \n",
        "\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIFPGE_-vx3T"
      },
      "source": [
        ""
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23iKv6bDPWQl"
      },
      "source": [
        "# helper\n",
        "def ynindicator(Y):\n",
        "  N = len(Y)\n",
        "  K = len(set(Y))\n",
        "  I = np.zeros((N, K))\n",
        "  I[np.arange(N), Y] = 1\n",
        "  return I\n",
        "\n",
        "def yback(Y_test):\n",
        "  nrow, ncol = Y_test.shape\n",
        "  y_class = np.zeros(nrow,dtype=int)\n",
        "  y_resp = Y_test\n",
        "  for k in range(nrow):\n",
        "    for kk in range(K):\n",
        "      if(y_resp[k,kk] == 1):\n",
        "        y_class[k] = kk\n",
        "  Y_test = y_class.copy()\n",
        "  return Y_test\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train)\n",
        "K = len(set(Y_train))\n",
        "\n",
        "X_train = X_train.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "Y_train = Y_train.astype(np.int32)\n",
        "Y_train = ynindicator(Y_train)\n",
        "\n",
        "X_test = np.array(X_test )\n",
        "Y_test = np.array(Y_test)\n",
        "X_test = X_test.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "Y_test = Y_test.astype(np.int32)\n",
        "Y_test = ynindicator(Y_test)\n",
        "\n",
        "# the model will be a sequence of layers\n",
        "\n",
        "Description = '3 layers of Convolution: 64, 128, 256 '\n",
        "N1 = 20\n",
        "N2 = 20\n",
        "\n",
        "# make the CNN\n",
        "model = Sequential()\n",
        "model.add(Conv2D(input_shape=(Img_Size, Img_Size, 1), filters=64, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=N1))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=N2))\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(units=K))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "# list of losses: https://keras.io/losses/\n",
        "# list of optimizers: https://keras.io/optimizers/\n",
        "# list of metrics: https://keras.io/metrics/\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpbPQ1FSRG6A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0570878-4005-46b1-faa0-bf2961d60c30"
      },
      "source": [
        "\n",
        "# training the model\n",
        "r = model.fit(X_train, Y_train, validation_data=(X_test,Y_test), \n",
        "              epochs=200, batch_size=32)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "11/11 [==============================] - 2s 147ms/step - loss: 0.6496 - accuracy: 0.6997 - val_loss: 0.6935 - val_accuracy: 0.4898\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 0.3803 - accuracy: 0.8426 - val_loss: 0.6936 - val_accuracy: 0.4898\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.2639 - accuracy: 0.9096 - val_loss: 0.6935 - val_accuracy: 0.4898\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 0.2061 - accuracy: 0.9184 - val_loss: 0.6936 - val_accuracy: 0.4898\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.1299 - accuracy: 0.9708 - val_loss: 0.6930 - val_accuracy: 0.4898\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0989 - accuracy: 0.9650 - val_loss: 0.6943 - val_accuracy: 0.4898\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0667 - accuracy: 0.9679 - val_loss: 0.6943 - val_accuracy: 0.4898\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.0687 - accuracy: 0.9679 - val_loss: 0.6923 - val_accuracy: 0.5102\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0462 - accuracy: 0.9854 - val_loss: 0.6925 - val_accuracy: 0.5102\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.0241 - accuracy: 0.9942 - val_loss: 0.6920 - val_accuracy: 0.5102\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0281 - accuracy: 0.9913 - val_loss: 0.6924 - val_accuracy: 0.5102\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0160 - accuracy: 0.9971 - val_loss: 0.6934 - val_accuracy: 0.5102\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0205 - accuracy: 0.9942 - val_loss: 0.6907 - val_accuracy: 0.5102\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0141 - accuracy: 0.9971 - val_loss: 0.6904 - val_accuracy: 0.6327\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0148 - accuracy: 0.9942 - val_loss: 0.6909 - val_accuracy: 0.5102\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0157 - accuracy: 0.9913 - val_loss: 0.6957 - val_accuracy: 0.5102\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0206 - accuracy: 0.9942 - val_loss: 0.6917 - val_accuracy: 0.5102\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6905 - val_accuracy: 0.5102\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0154 - accuracy: 0.9942 - val_loss: 0.6962 - val_accuracy: 0.5102\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 0.0152 - accuracy: 0.9971 - val_loss: 0.7175 - val_accuracy: 0.5102\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0100 - accuracy: 0.9971 - val_loss: 0.6920 - val_accuracy: 0.5102\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.6864 - val_accuracy: 0.5102\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.6874 - val_accuracy: 0.5102\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6845 - val_accuracy: 0.5102\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0138 - accuracy: 0.9942 - val_loss: 0.7225 - val_accuracy: 0.5102\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0339 - accuracy: 0.9854 - val_loss: 0.7681 - val_accuracy: 0.5102\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0162 - accuracy: 0.9971 - val_loss: 0.8465 - val_accuracy: 0.5102\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.0259 - accuracy: 0.9942 - val_loss: 0.8159 - val_accuracy: 0.5102\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0081 - accuracy: 0.9971 - val_loss: 0.9182 - val_accuracy: 0.5102\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0100 - accuracy: 0.9971 - val_loss: 0.8224 - val_accuracy: 0.5102\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 0.0162 - accuracy: 0.9942 - val_loss: 0.8007 - val_accuracy: 0.5102\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0057 - accuracy: 0.9971 - val_loss: 1.6756 - val_accuracy: 0.5102\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0331 - accuracy: 0.9942 - val_loss: 1.1081 - val_accuracy: 0.5102\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.0210 - accuracy: 0.9883 - val_loss: 3.4776 - val_accuracy: 0.5102\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.0210 - accuracy: 0.9883 - val_loss: 7.4759 - val_accuracy: 0.5102\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0504 - accuracy: 0.9883 - val_loss: 12.6404 - val_accuracy: 0.5102\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0219 - accuracy: 0.9942 - val_loss: 9.7676 - val_accuracy: 0.5102\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 12.8388 - val_accuracy: 0.5102\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0112 - accuracy: 0.9942 - val_loss: 11.9928 - val_accuracy: 0.5102\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0119 - accuracy: 0.9971 - val_loss: 10.1204 - val_accuracy: 0.5102\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 11.8043 - val_accuracy: 0.5102\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0046 - accuracy: 0.9971 - val_loss: 9.0657 - val_accuracy: 0.5102\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 6.3536 - val_accuracy: 0.5102\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0044 - accuracy: 0.9971 - val_loss: 6.0868 - val_accuracy: 0.5102\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 4.6210 - val_accuracy: 0.5102\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0048 - accuracy: 0.9971 - val_loss: 5.1916 - val_accuracy: 0.5102\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 6.4925e-04 - accuracy: 1.0000 - val_loss: 9.4050 - val_accuracy: 0.5102\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 9.6066e-04 - accuracy: 1.0000 - val_loss: 10.5749 - val_accuracy: 0.5102\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 6.4264e-04 - accuracy: 1.0000 - val_loss: 11.1202 - val_accuracy: 0.5102\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 10.3631 - val_accuracy: 0.5102\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 6.6110e-04 - accuracy: 1.0000 - val_loss: 9.4719 - val_accuracy: 0.5102\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 8.1352e-04 - accuracy: 1.0000 - val_loss: 9.2639 - val_accuracy: 0.5102\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 3.3620e-04 - accuracy: 1.0000 - val_loss: 9.1779 - val_accuracy: 0.5102\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 9.1912e-04 - accuracy: 1.0000 - val_loss: 8.8804 - val_accuracy: 0.5102\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 7.3349e-04 - accuracy: 1.0000 - val_loss: 7.9912 - val_accuracy: 0.5102\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 3.6680e-04 - accuracy: 1.0000 - val_loss: 7.5539 - val_accuracy: 0.5102\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 3.0488e-04 - accuracy: 1.0000 - val_loss: 7.2732 - val_accuracy: 0.5102\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 3.2384e-04 - accuracy: 1.0000 - val_loss: 6.8378 - val_accuracy: 0.5102\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 6.7587e-04 - accuracy: 1.0000 - val_loss: 6.4259 - val_accuracy: 0.5102\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 2.8444e-04 - accuracy: 1.0000 - val_loss: 5.8872 - val_accuracy: 0.5102\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 2.7096e-04 - accuracy: 1.0000 - val_loss: 5.5560 - val_accuracy: 0.5102\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 1.9307e-04 - accuracy: 1.0000 - val_loss: 5.2035 - val_accuracy: 0.5102\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 2.6523e-04 - accuracy: 1.0000 - val_loss: 4.6876 - val_accuracy: 0.5102\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 1.9540e-04 - accuracy: 1.0000 - val_loss: 4.2295 - val_accuracy: 0.5102\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 3.4841e-04 - accuracy: 1.0000 - val_loss: 4.0847 - val_accuracy: 0.5102\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 1.9627e-04 - accuracy: 1.0000 - val_loss: 3.7418 - val_accuracy: 0.5102\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.4503 - val_accuracy: 0.5170\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 2.6891e-04 - accuracy: 1.0000 - val_loss: 3.0709 - val_accuracy: 0.5170\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 2.0462e-04 - accuracy: 1.0000 - val_loss: 2.6670 - val_accuracy: 0.5442\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 3.1653e-04 - accuracy: 1.0000 - val_loss: 2.5973 - val_accuracy: 0.5442\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 3.1849e-04 - accuracy: 1.0000 - val_loss: 2.7730 - val_accuracy: 0.5374\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 1.5169e-04 - accuracy: 1.0000 - val_loss: 2.7044 - val_accuracy: 0.5442\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 1.0156e-04 - accuracy: 1.0000 - val_loss: 2.6339 - val_accuracy: 0.5442\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 2.1012e-04 - accuracy: 1.0000 - val_loss: 2.3006 - val_accuracy: 0.5714\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 1.9812e-04 - accuracy: 1.0000 - val_loss: 2.3247 - val_accuracy: 0.5850\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 1.8138e-04 - accuracy: 1.0000 - val_loss: 2.9000 - val_accuracy: 0.5646\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 1.9658e-04 - accuracy: 1.0000 - val_loss: 3.9230 - val_accuracy: 0.5374\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 1.4435e-04 - accuracy: 1.0000 - val_loss: 3.9563 - val_accuracy: 0.5374\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 1.5215e-04 - accuracy: 1.0000 - val_loss: 3.6832 - val_accuracy: 0.5374\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 3.2131e-04 - accuracy: 1.0000 - val_loss: 3.9201 - val_accuracy: 0.5374\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 1.4966e-04 - accuracy: 1.0000 - val_loss: 5.9633 - val_accuracy: 0.5170\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 1.0491e-04 - accuracy: 1.0000 - val_loss: 5.2684 - val_accuracy: 0.5306\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 2.0191e-04 - accuracy: 1.0000 - val_loss: 4.9788 - val_accuracy: 0.5306\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 3.6873e-04 - accuracy: 1.0000 - val_loss: 4.1942 - val_accuracy: 0.5374\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 9.9548e-05 - accuracy: 1.0000 - val_loss: 3.4141 - val_accuracy: 0.5578\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 6.6744e-05 - accuracy: 1.0000 - val_loss: 2.8612 - val_accuracy: 0.5986\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 6.7896e-05 - accuracy: 1.0000 - val_loss: 2.2657 - val_accuracy: 0.6735\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 6.9957e-05 - accuracy: 1.0000 - val_loss: 2.0194 - val_accuracy: 0.6871\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 1.3946e-04 - accuracy: 1.0000 - val_loss: 1.5137 - val_accuracy: 0.7075\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 5.0844e-05 - accuracy: 1.0000 - val_loss: 1.0690 - val_accuracy: 0.7755\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 3.2342e-04 - accuracy: 1.0000 - val_loss: 0.3689 - val_accuracy: 0.9048\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 2.4534e-04 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9320\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 3.1504e-04 - accuracy: 1.0000 - val_loss: 0.4700 - val_accuracy: 0.9048\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 6.4945e-05 - accuracy: 1.0000 - val_loss: 0.5193 - val_accuracy: 0.8912\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 9.7237e-05 - accuracy: 1.0000 - val_loss: 0.4501 - val_accuracy: 0.9116\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 6.1074e-05 - accuracy: 1.0000 - val_loss: 0.3693 - val_accuracy: 0.9116\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 3.3485e-05 - accuracy: 1.0000 - val_loss: 0.2973 - val_accuracy: 0.9048\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 6.1318e-05 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9184\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 4.0408e-04 - accuracy: 1.0000 - val_loss: 0.3588 - val_accuracy: 0.9116\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 2.1211e-04 - accuracy: 1.0000 - val_loss: 5.5566 - val_accuracy: 0.5102\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 1.9595e-04 - accuracy: 1.0000 - val_loss: 6.2539 - val_accuracy: 0.5102\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 2.9429e-04 - accuracy: 1.0000 - val_loss: 1.9681 - val_accuracy: 0.5442\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 8.8921e-05 - accuracy: 1.0000 - val_loss: 1.1144 - val_accuracy: 0.6327\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 2.0676e-04 - accuracy: 1.0000 - val_loss: 0.9052 - val_accuracy: 0.6395\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 1.2624e-04 - accuracy: 1.0000 - val_loss: 0.7880 - val_accuracy: 0.6463\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 3.9428e-05 - accuracy: 1.0000 - val_loss: 0.6950 - val_accuracy: 0.7007\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 5.0713e-05 - accuracy: 1.0000 - val_loss: 0.6472 - val_accuracy: 0.7211\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 5.5455e-05 - accuracy: 1.0000 - val_loss: 0.5941 - val_accuracy: 0.7551\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 1.3615e-04 - accuracy: 1.0000 - val_loss: 0.3552 - val_accuracy: 0.8163\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 1.0335e-04 - accuracy: 1.0000 - val_loss: 0.2975 - val_accuracy: 0.8503\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 2.2713e-04 - accuracy: 1.0000 - val_loss: 0.1715 - val_accuracy: 0.9184\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 1.3362e-04 - accuracy: 1.0000 - val_loss: 0.1277 - val_accuracy: 0.9320\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 1.3290e-04 - accuracy: 1.0000 - val_loss: 0.2503 - val_accuracy: 0.9116\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 9.7674e-05 - accuracy: 1.0000 - val_loss: 0.3154 - val_accuracy: 0.8844\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 4.9602e-04 - accuracy: 1.0000 - val_loss: 0.1004 - val_accuracy: 0.9796\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 2.6225e-05 - accuracy: 1.0000 - val_loss: 0.1069 - val_accuracy: 0.9796\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 5.6949e-05 - accuracy: 1.0000 - val_loss: 0.1084 - val_accuracy: 0.9796\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 5.8388e-05 - accuracy: 1.0000 - val_loss: 0.1047 - val_accuracy: 0.9728\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 1.6510e-04 - accuracy: 1.0000 - val_loss: 0.5882 - val_accuracy: 0.8435\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 1.4411e-05 - accuracy: 1.0000 - val_loss: 1.3285 - val_accuracy: 0.7211\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 9.7320e-05 - accuracy: 1.0000 - val_loss: 1.5070 - val_accuracy: 0.7143\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 2.8304e-05 - accuracy: 1.0000 - val_loss: 1.3143 - val_accuracy: 0.7347\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 6.2844e-05 - accuracy: 1.0000 - val_loss: 1.0195 - val_accuracy: 0.7619\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 3.1855e-05 - accuracy: 1.0000 - val_loss: 0.6469 - val_accuracy: 0.8503\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 2.7353e-05 - accuracy: 1.0000 - val_loss: 0.4221 - val_accuracy: 0.8912\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 1.2463e-04 - accuracy: 1.0000 - val_loss: 0.2499 - val_accuracy: 0.9252\n",
            "Epoch 127/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 9.9281e-04 - accuracy: 1.0000 - val_loss: 9.9067 - val_accuracy: 0.5102\n",
            "Epoch 128/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 3.4020e-05 - accuracy: 1.0000 - val_loss: 14.4915 - val_accuracy: 0.5102\n",
            "Epoch 129/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 5.1324e-05 - accuracy: 1.0000 - val_loss: 14.6693 - val_accuracy: 0.5102\n",
            "Epoch 130/200\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 6.0291e-05 - accuracy: 1.0000 - val_loss: 13.4522 - val_accuracy: 0.5102\n",
            "Epoch 131/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 1.2980e-04 - accuracy: 1.0000 - val_loss: 12.0634 - val_accuracy: 0.5102\n",
            "Epoch 132/200\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 6.8731e-05 - accuracy: 1.0000 - val_loss: 11.1834 - val_accuracy: 0.5102\n",
            "Epoch 133/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 5.5794e-05 - accuracy: 1.0000 - val_loss: 10.0000 - val_accuracy: 0.5102\n",
            "Epoch 134/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 7.4309e-05 - accuracy: 1.0000 - val_loss: 8.9980 - val_accuracy: 0.5102\n",
            "Epoch 135/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 5.9666e-05 - accuracy: 1.0000 - val_loss: 8.1285 - val_accuracy: 0.5102\n",
            "Epoch 136/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 2.1821e-05 - accuracy: 1.0000 - val_loss: 7.0052 - val_accuracy: 0.5102\n",
            "Epoch 137/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 3.7651e-04 - accuracy: 1.0000 - val_loss: 7.4140 - val_accuracy: 0.5102\n",
            "Epoch 138/200\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 1.8091e-05 - accuracy: 1.0000 - val_loss: 7.0438 - val_accuracy: 0.5102\n",
            "Epoch 139/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 1.0762e-04 - accuracy: 1.0000 - val_loss: 5.4970 - val_accuracy: 0.5238\n",
            "Epoch 140/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 1.3719e-05 - accuracy: 1.0000 - val_loss: 3.5581 - val_accuracy: 0.5510\n",
            "Epoch 141/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 2.1847e-05 - accuracy: 1.0000 - val_loss: 2.2248 - val_accuracy: 0.6327\n",
            "Epoch 142/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 1.9235e-05 - accuracy: 1.0000 - val_loss: 1.4533 - val_accuracy: 0.7347\n",
            "Epoch 143/200\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 4.3444e-05 - accuracy: 1.0000 - val_loss: 0.9692 - val_accuracy: 0.7891\n",
            "Epoch 144/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 7.6571e-05 - accuracy: 1.0000 - val_loss: 0.5468 - val_accuracy: 0.8844\n",
            "Epoch 145/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 4.9060e-05 - accuracy: 1.0000 - val_loss: 0.3710 - val_accuracy: 0.9184\n",
            "Epoch 146/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 3.6708e-05 - accuracy: 1.0000 - val_loss: 0.4231 - val_accuracy: 0.9116\n",
            "Epoch 147/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 3.8792e-05 - accuracy: 1.0000 - val_loss: 0.4923 - val_accuracy: 0.9048\n",
            "Epoch 148/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 1.2781e-04 - accuracy: 1.0000 - val_loss: 0.3950 - val_accuracy: 0.9184\n",
            "Epoch 149/200\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 5.7422e-05 - accuracy: 1.0000 - val_loss: 0.2743 - val_accuracy: 0.9320\n",
            "Epoch 150/200\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 2.1601e-05 - accuracy: 1.0000 - val_loss: 0.2073 - val_accuracy: 0.9320\n",
            "Epoch 151/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 1.6904e-05 - accuracy: 1.0000 - val_loss: 0.1797 - val_accuracy: 0.9388\n",
            "Epoch 152/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 1.2451e-04 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 0.9456\n",
            "Epoch 153/200\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 3.7382e-05 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 0.9456\n",
            "Epoch 154/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 3.2301e-05 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 0.9592\n",
            "Epoch 155/200\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 1.4296e-05 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9524\n",
            "Epoch 156/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 1.9048e-05 - accuracy: 1.0000 - val_loss: 0.1741 - val_accuracy: 0.9660\n",
            "Epoch 157/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 1.4641e-04 - accuracy: 1.0000 - val_loss: 0.1794 - val_accuracy: 0.9796\n",
            "Epoch 158/200\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 2.8722e-05 - accuracy: 1.0000 - val_loss: 0.1905 - val_accuracy: 0.9796\n",
            "Epoch 159/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 3.4774e-04 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9252\n",
            "Epoch 160/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 7.8455e-05 - accuracy: 1.0000 - val_loss: 0.2148 - val_accuracy: 0.9048\n",
            "Epoch 161/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 2.7006e-04 - accuracy: 1.0000 - val_loss: 0.1413 - val_accuracy: 0.9592\n",
            "Epoch 162/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 3.7096e-05 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9456\n",
            "Epoch 163/200\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 1.1265e-04 - accuracy: 1.0000 - val_loss: 0.2336 - val_accuracy: 0.9456\n",
            "Epoch 164/200\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 1.1710e-04 - accuracy: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.9320\n",
            "Epoch 165/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 4.0797e-05 - accuracy: 1.0000 - val_loss: 0.2343 - val_accuracy: 0.9320\n",
            "Epoch 166/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.0120 - accuracy: 0.9971 - val_loss: 20.4194 - val_accuracy: 0.5102\n",
            "Epoch 167/200\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 0.1172 - accuracy: 0.9592 - val_loss: 109.0514 - val_accuracy: 0.5102\n",
            "Epoch 168/200\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.1287 - accuracy: 0.9650 - val_loss: 839.6240 - val_accuracy: 0.5102\n",
            "Epoch 169/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.1089 - accuracy: 0.9621 - val_loss: 663.6643 - val_accuracy: 0.5102\n",
            "Epoch 170/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.0815 - accuracy: 0.9679 - val_loss: 134.6670 - val_accuracy: 0.5102\n",
            "Epoch 171/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.0278 - accuracy: 0.9913 - val_loss: 252.3690 - val_accuracy: 0.5102\n",
            "Epoch 172/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 281.0478 - val_accuracy: 0.5102\n",
            "Epoch 173/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.0053 - accuracy: 0.9971 - val_loss: 239.4207 - val_accuracy: 0.5102\n",
            "Epoch 174/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 205.1245 - val_accuracy: 0.5102\n",
            "Epoch 175/200\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 179.0140 - val_accuracy: 0.5102\n",
            "Epoch 176/200\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 0.0035 - accuracy: 0.9971 - val_loss: 151.7896 - val_accuracy: 0.5102\n",
            "Epoch 177/200\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 0.0490 - accuracy: 0.9854 - val_loss: 92.6981 - val_accuracy: 0.5102\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.0127 - accuracy: 0.9913 - val_loss: 132.9148 - val_accuracy: 0.5102\n",
            "Epoch 179/200\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0075 - accuracy: 0.9971 - val_loss: 147.2340 - val_accuracy: 0.5102\n",
            "Epoch 180/200\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 135.8734 - val_accuracy: 0.5102\n",
            "Epoch 181/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 91.2754 - val_accuracy: 0.5102\n",
            "Epoch 182/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 79.3769 - val_accuracy: 0.5102\n",
            "Epoch 183/200\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 69.6385 - val_accuracy: 0.5102\n",
            "Epoch 184/200\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 8.7659e-04 - accuracy: 1.0000 - val_loss: 53.3464 - val_accuracy: 0.5102\n",
            "Epoch 185/200\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 49.9182 - val_accuracy: 0.5102\n",
            "Epoch 186/200\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 7.3546e-04 - accuracy: 1.0000 - val_loss: 48.2301 - val_accuracy: 0.5102\n",
            "Epoch 187/200\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 5.1352e-04 - accuracy: 1.0000 - val_loss: 44.4960 - val_accuracy: 0.5102\n",
            "Epoch 188/200\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 5.9647e-04 - accuracy: 1.0000 - val_loss: 40.6275 - val_accuracy: 0.5102\n",
            "Epoch 189/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 3.0085e-04 - accuracy: 1.0000 - val_loss: 37.3239 - val_accuracy: 0.5102\n",
            "Epoch 190/200\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 30.2354 - val_accuracy: 0.5102\n",
            "Epoch 191/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.0031 - accuracy: 0.9971 - val_loss: 22.1769 - val_accuracy: 0.5102\n",
            "Epoch 192/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 2.5367e-04 - accuracy: 1.0000 - val_loss: 38.8511 - val_accuracy: 0.5102\n",
            "Epoch 193/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0238 - accuracy: 0.9883 - val_loss: 24.1049 - val_accuracy: 0.5102\n",
            "Epoch 194/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.1029 - accuracy: 0.9825 - val_loss: 83.0570 - val_accuracy: 0.5102\n",
            "Epoch 195/200\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 0.0250 - accuracy: 0.9971 - val_loss: 87.1988 - val_accuracy: 0.5102\n",
            "Epoch 196/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.0262 - accuracy: 0.9883 - val_loss: 118.1343 - val_accuracy: 0.5102\n",
            "Epoch 197/200\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 0.0244 - accuracy: 0.9883 - val_loss: 121.9512 - val_accuracy: 0.5102\n",
            "Epoch 198/200\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 120.1352 - val_accuracy: 0.5102\n",
            "Epoch 199/200\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 105.4865 - val_accuracy: 0.5102\n",
            "Epoch 200/200\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 87.4480 - val_accuracy: 0.5102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSTlOSUBWMpj"
      },
      "source": [
        "Y_test = yback(Y_test)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDVY6HbxMOlH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25f6337e-f414-47e7-83e8-eaf6bd4ba77d"
      },
      "source": [
        "# pred_test= model.predict_classes(X_test)\n",
        "pred_test = np.argmax(model.predict(X_test), axis=-1)\n",
        "\n",
        "data = {'y_true': Y_test,'y_predict': pred_test}  # este dado esta no formato de dicionario\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_true','y_predict'])\n",
        "\n",
        "\n",
        "confusion_matrix = pd.crosstab(df['y_true'], df['y_predict'], rownames=['Actual'], colnames=['Predict'])\n",
        "print(confusion_matrix)\n",
        "\n",
        "y_true = df['y_true']\n",
        "y_pred = df['y_predict']\n",
        "\n",
        "  \n",
        "METRICS=sklearn.metrics.classification_report(y_true, y_pred)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predict   1\n",
            "Actual     \n",
            "0        72\n",
            "1        75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7pT2q7traXg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fec55bc-88c5-4de3-c2f4-c80399e31729"
      },
      "source": [
        "print(METRICS)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        72\n",
            "           1       0.51      1.00      0.68        75\n",
            "\n",
            "    accuracy                           0.51       147\n",
            "   macro avg       0.26      0.50      0.34       147\n",
            "weighted avg       0.26      0.51      0.34       147\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElpxWbBnpgLX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "688f637b-bef9-47f7-f28b-89964028e037"
      },
      "source": [
        "'''\n",
        "#X =np.array(df.copy())/255.0 \n",
        "X =np.array(df.copy())\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42)\n",
        "model = MLPClassifier(hidden_layer_sizes=(200,10), activation='tanh', solver='adam',random_state=1, max_iter=300).fit(X_train,y_train)  \n",
        "prediction = model.predict(X_test)  \n",
        "y =np.copy(y_test)\n",
        "data = {'y_true': y_test,'y_predict': prediction}  \n",
        "# este dado esta no formato de dicionario\n",
        "df = pd.DataFrame(data, columns=['y_true','y_predict'])\n",
        "confusion_matrix = pd.crosstab(df['y_true'], df['y_predict'], rownames=['Actual'], colnames=['Predict'])\n",
        "print(confusion_matrix)\n",
        "y_true = df['y_true']\n",
        "y_pred = df['y_predict']  \n",
        "METRICS=sklearn.metrics.classification_report(y_true, y_pred)\n",
        "print(METRICS)\n",
        "#X =np.array(df.copy())/255.0 X =np.array(df_all.copy())X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42)model = MLPClassifier(hidden_layer_sizes=(200,10), activation='tanh',                       solver='adam',random_state=1, max_iter=300).fit(X_train,y_train)  prediction = model.predict(X_test)  y =np.copy(y_test)data = {'y_true': y_test,'y_predict': prediction}  # este dado esta no formato de dicionariodf = pd.DataFrame(data, columns=['y_true','y_predict'])confusion_matrix = pd.crosstab(df['y_true'], df['y_predict'], rownames=['Actual'], colnames=['Predict'])print(confusion_matrix)y_true = df['y_true']y_pred = df['y_predict']\n",
        "'''"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n#X =np.array(df.copy())/255.0 \\nX =np.array(df.copy())\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42)\\nmodel = MLPClassifier(hidden_layer_sizes=(200,10), activation='tanh', solver='adam',random_state=1, max_iter=300).fit(X_train,y_train)  \\nprediction = model.predict(X_test)  \\ny =np.copy(y_test)\\ndata = {'y_true': y_test,'y_predict': prediction}  \\n# este dado esta no formato de dicionario\\ndf = pd.DataFrame(data, columns=['y_true','y_predict'])\\nconfusion_matrix = pd.crosstab(df['y_true'], df['y_predict'], rownames=['Actual'], colnames=['Predict'])\\nprint(confusion_matrix)\\ny_true = df['y_true']\\ny_pred = df['y_predict']  \\nMETRICS=sklearn.metrics.classification_report(y_true, y_pred)\\nprint(METRICS)\\n#X =np.array(df.copy())/255.0 X =np.array(df_all.copy())X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42)model = MLPClassifier(hidden_layer_sizes=(200,10), activation='tanh',                       solver='adam',random_state=1, max_iter=300).fit(X_train,y_train)  prediction = model.predict(X_test)  y =np.copy(y_test)data = {'y_true': y_test,'y_predict': prediction}  # este dado esta no formato de dicionariodf = pd.DataFrame(data, columns=['y_true','y_predict'])confusion_matrix = pd.crosstab(df['y_true'], df['y_predict'], rownames=['Actual'], colnames=['Predict'])print(confusion_matrix)y_true = df['y_true']y_pred = df['y_predict']\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iFNNrlWV9tH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f4f4514-2767-4a98-9578-1474bffb34b7"
      },
      "source": [
        "pred_test"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv5I61yhPQmk"
      },
      "source": [
        "cont = 0; num =25\n",
        "img_graos = []\n",
        "Width_new = []\n",
        "img=ww[4] \n",
        "while( cont < num):\n",
        "  df=Segmenta(img)\n",
        "  df_ann =df.copy()\n",
        "  Width = df['Width']\n",
        "  del df_ann['Width']\n",
        "  result = np.array(df_ann)\n",
        "  result = result.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "  #prediction = model.predict_classes(result)\n",
        "  prediction= np.argmax(model.predict(result), axis=-1)\n",
        "  loc_grao =[];k=0\n",
        "  for i in prediction:\n",
        "    if( i == 0):\n",
        "      img_graos.append(df.iloc[k,:])\n",
        "      Width_new.append(Width.iloc[k])\n",
        "      cont = cont + 1\n",
        "    k = k +1\n",
        "img_graos = pd.DataFrame(img_graos)\n",
        "print(img_graos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LkA4vHp-f6_"
      },
      "source": [
        "Width=np.array(Width_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjRbWgmX_LFH"
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_paper_fev_2021\n",
        "%cd marquesgabi_paper_fev_2021\n",
        "\n",
        "from Get_PSDArea_New import PSDArea\n",
        "from histogram_fev_2021 import PSD\n",
        "#from GetBetterSegm import GetBetter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAG_I6FwCvFr"
      },
      "source": [
        "'''\n",
        "!git clone https://github.com/ucfilho/marquesgabi_out_2020\n",
        "#!git clone https://github.com/marquesgabi/Doutorado\n",
        "%cd marquesgabi_out_2020\n",
        "#%cd Doutorado\n",
        "#PSD_imageJ = 'Amostra7.csv' \n",
        "#PSD_new = pd.read_csv(PSD_imageJ,sep=';')\n",
        "#encoding='utf8'\n",
        "\n",
        "PSD_imageJ = 'Areas_ImageJ.csv'\n",
        "PSD_new = pd.read_csv(PSD_imageJ)\n",
        "print(PSD_new.head(3))\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_1WIM8w7poO"
      },
      "source": [
        "Area_All, Diameter_All=PSDArea(img_graos) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PekBHQOT_6CP"
      },
      "source": [
        "img_graos.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaZPe_AxNBK9"
      },
      "source": [
        "#PSD_new.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fD3USRrhnHeC"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vmhG2LgCabC"
      },
      "source": [
        "#lost_value = float(PSD_new.columns[1])\n",
        "\n",
        "# Area = np.array(PSD_new.iloc[:,1])\n",
        "Area = df_ImgJ['Area'].values\n",
        "# Area = np.concatenate( (Area, [lost_value] ) )\n",
        "# Area = np.concatenate( (Area, [lost_value] ) )\n",
        "diam_teste = []\n",
        "for A in Area:\n",
        "  diam_teste.append((4*A/np.pi)**0.5) \n",
        "\n",
        "Diam1 = [ (4*A/np.pi)**0.5 for A in Area]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPWCPPf7bzsf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfk_fNXGDK5_"
      },
      "source": [
        "wt1 = np.ones(len(Diam1)) / len(Diam1)*100\n",
        "wt2 = np.ones(len(Diameter_All)) / len(Diameter_All)*100\n",
        "X = pd.DataFrame([Diam1,Diameter_All])\n",
        "wts = pd.DataFrame([wt1,wt2])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OieAXw_by3nz"
      },
      "source": [
        "A = plt.hist(X,weights=wts,bins=7)\n",
        "plt.legend(['True','CNN'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpdrvEySy8Ij"
      },
      "source": [
        "B = A[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUhGZHT8y9Or"
      },
      "source": [
        "Novo = []\n",
        "k = 0\n",
        "soma = 0\n",
        "for i in B:\n",
        "  if(k<4):\n",
        "    Novo.append(i)\n",
        "  else:\n",
        "    soma = soma + i\n",
        "  k = k + 1\n",
        "Novo.append(soma)\n",
        "print(Novo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMK89w-fzCVe"
      },
      "source": [
        "# Freq1 = [19.12043703, 29.22484843, 19.35872174, 20.82190224, 11.47409056] # avarage 4 samples\n",
        "Freq1 = [20.69301557, 28.55598044, 18.50768331, 22.7106327, 8.905907357] # avarage 10 samples\n",
        "#Freq2 = [16.93792791, 31.38008965, 24.93810752, 18.56158392, 6.233810752, 0.4]\n",
        "Freq2 = [16.93792791, 31.38008965, 24.93810752, 18.56158392, 6.633810752]\n",
        "Freq3 = Novo\n",
        "barWidth = 0.25\n",
        "\n",
        "br1 = range(len(Freq1))\n",
        "# Set position of bar on X axis\n",
        "br2 = [x + barWidth for x in br1]\n",
        "br3 = [x + barWidth for x in br2]\n",
        "# labels = [0.8, 1.0, 1.2, 1.4, 1.6, 1.8]\n",
        "labels = [0.8, 1.0, 1.2, 1.4, 1.6]\n",
        "\n",
        "xx=[]\n",
        "for a in labels:\n",
        "  xx.append(str(a))\n",
        "plt.bar(br1, Freq1 , color=\"green\", align=\"center\", width=0.3, tick_label= xx) \n",
        "plt.bar(br2, Freq2 , color=\"red\", align=\"center\", width=0.3, tick_label= xx)\n",
        "plt.bar(br3, Freq3 , color=\"blue\", align=\"center\", width=0.3, tick_label= xx)\n",
        "plt.legend(['CNN 1','CNN 2','True'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}