{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PSD_histogram_CNN_B_r_squared_jun_23_2021.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ucfilho/marquesgabi_paper_fev_2021/blob/main/Qualificacao/Comparative_ANNs/PSD_histogram_CNN_B_r_squared_jun_23_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sog7Z9pyhUD_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import zipfile\n",
        "#import random\n",
        "from random import randint\n",
        "from PIL import Image\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "#import scikit-image\n",
        "import skimage\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
        "from sklearn.metrics import r2_score\n",
        "from google.colab import files"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZEvJvfoibE4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "819fc344-16ba-4c9f-dc38-962e76f95c33"
      },
      "source": [
        "!pip install mahotas"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mahotas in /usr/local/lib/python3.7/dist-packages (1.4.11)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mahotas) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf_a6PJ1iUnT"
      },
      "source": [
        "import mahotas.features.texture as mht\n",
        "import mahotas.features"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VcTdaNVh9EE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b41e768d-63ba-449c-d003-1441584d8bf9"
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_fev_2020 #clonar do Github\n",
        "%cd marquesgabi_fev_2020\n",
        "import Go2BlackWhite\n",
        "import Go2Mahotas"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'marquesgabi_fev_2020' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v7SRrc8mH2N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98dcd744-070f-4f18-a09f-3337ae95670a"
      },
      "source": [
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "%cd Doutorado\n",
        "\n",
        "Transfere='Fotos_Grandes_3cdAmostra.zip'\n",
        "file_name = zipfile.ZipFile(Transfere, 'r')\n",
        "file_name.extractall()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Doutorado' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/Doutorado\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kA4IWSmasoD"
      },
      "source": [
        "Size=1200 # tamanho da foto\n",
        "ww,img_name=Go2BlackWhite.BlackWhite(Transfere,Size) #Pegamos a primeira foto Grande\n",
        "img=ww[4] \n",
        "# this is the big image we want to segment \n",
        "# ww[0], change it if you want to segment another picture"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHgqAnaFyCjp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f6fc6be-b06d-4591-a7c1-96f8e255b6f3"
      },
      "source": [
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'MarquesGabi_Routines' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc4rFvzkyWCi"
      },
      "source": [
        "from segment_filter_not_conclude import Segmenta  # got image provided segmented"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnTtH3KDP863"
      },
      "source": [
        "df=Segmenta(img)\n",
        "Img_Size = 28"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN5MN5a_v4np",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c2daadb-b135-4d8b-ffd3-345d64919293"
      },
      "source": [
        "print(df)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    Width           0           1  ...         781         782         783\n",
            "0     146  126.300804  138.789078  ...  186.979919  194.375885  207.060425\n",
            "1     184  178.176743  187.679092  ...   77.279770  109.551041  127.960297\n",
            "2     164  194.757889  194.801910  ...  176.362885  171.958359  173.856628\n",
            "3     148   66.318489  118.151947  ...    0.576333    0.360117    1.414171\n",
            "4     111   31.293888   27.945946  ...  118.664474  130.317352  143.243088\n",
            "5     140  146.119995  141.080002  ...  124.879997  126.599998  130.520004\n",
            "6     192  178.391052  185.423172  ...  146.263443  142.154495  133.990005\n",
            "7     119   82.979248   87.885818  ...    1.000000    1.000000    1.000000\n",
            "8     192  163.831161  162.668823  ...    1.396267    0.167535    1.312934\n",
            "9     185  153.730011  158.259445  ...  144.989243  147.531250  136.773315\n",
            "10    189  125.973938  126.023315  ...  226.581619  239.440338  250.748978\n",
            "11    128  153.877930  168.488281  ...  233.003906  244.421875  248.764648\n",
            "12    139  148.993011  161.636353  ...  101.033630  121.293877  131.591156\n",
            "13    180   77.572838   88.399513  ...    1.205432    0.133827    1.335309\n",
            "14    156  170.251816  171.326767  ...  143.840912  148.781067  155.223541\n",
            "15    192  194.233932  197.622818  ...  180.174469  164.641907  161.262573\n",
            "16    135  135.444168  134.989075  ...    1.493169    1.000000    1.000000\n",
            "17    108   66.894379   66.934151  ...  155.700958  154.905334  152.672150\n",
            "18    160  159.674362  147.173752  ...    1.000000    0.796875    0.560000\n",
            "19    181  171.237076  148.486374  ...  243.616135  225.664124  207.221695\n",
            "20    187  135.743591  126.966400  ...    1.337098    0.176871    1.337098\n",
            "21    196  149.285706  162.918365  ...  154.346939  164.816330  164.346939\n",
            "22    110  110.387772  119.587105  ...    0.009256    0.837355    1.573884\n",
            "23    152   87.567863  110.358032  ...  124.076180  125.123955  178.312332\n",
            "24    188    2.947940   41.233589  ...  128.176086  130.159348  144.795837\n",
            "25    188  197.545944  206.042557  ...  164.377533  160.411057  134.061554\n",
            "26    109  141.739227  134.048981  ...  169.498611  166.629059  159.585876\n",
            "27    142  152.348145  139.921249  ...   85.964096  113.775047  114.046814\n",
            "28    171  174.453781  176.407944  ...  127.895569  155.346344  163.326263\n",
            "29    108  153.868301  145.761322  ...   37.034294   26.031549   29.916321\n",
            "30    117  150.699326  177.284302  ...  157.939667  167.493530  179.271317\n",
            "31    185  160.706177  105.808174  ...  155.167175  158.152512  168.757553\n",
            "32    139  130.317429  129.267792  ...   75.102531   72.179855   69.466850\n",
            "33    136  186.688599  176.855560  ...    0.365917    0.483564    1.454152\n",
            "34    134  209.289169  204.465805  ...  142.875031  150.058380  151.985306\n",
            "35    166    0.522427    2.003338  ...  112.606026  110.990410  109.475540\n",
            "36    188  141.425079  143.047073  ...  222.078766  210.879578  208.162964\n",
            "37    176  178.173538  206.320755  ...   82.389465   84.969002   93.439560\n",
            "38    105  252.808899  253.555573  ...  150.977798  149.697784  150.302231\n",
            "39    190  187.331070  170.997787  ...  173.626251  171.514771  169.372726\n",
            "40    174   37.460037   39.224339  ...    1.052187    0.163430    1.347734\n",
            "41    119  170.145340  159.723190  ...   67.058823   56.861591   50.993080\n",
            "42    111  116.936371  121.084564  ...    0.586154    1.324893    1.811379\n",
            "43    160  142.398743  140.408112  ...  135.194382  137.981873  140.697495\n",
            "44    116  126.418541  128.204529  ...  168.462540  161.826385  157.627823\n",
            "45    115  182.918777  186.505920  ...  162.450424  153.310318  140.430908\n",
            "46    195  176.358704  176.033813  ...  131.709000  133.807114  138.923325\n",
            "47    192  118.956161  113.443565  ...   66.762146    3.398871    2.003038\n",
            "48    113   93.149193  100.426338  ...  155.409821  153.557373  150.704041\n",
            "49    148  198.003662  234.005859  ...  172.814484  174.319214  169.871460\n",
            "\n",
            "[50 rows x 785 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzpQ1Pz0fX5L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "f96522bf-3ed1-4dd3-9635-1a45bfa71a08"
      },
      "source": [
        "'''\n",
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines\n",
        "# filename = 'model_ANN.pkl'\n",
        "filename = 'model_ANN_new.pkl'\n",
        "model = joblib.load(filename)\n",
        "'''"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n!git clone https://github.com/ucfilho/MarquesGabi_Routines\\n%cd MarquesGabi_Routines\\n# filename = 'model_ANN.pkl'\\nfilename = 'model_ANN_new.pkl'\\nmodel = joblib.load(filename)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR2emP4rNjQy",
        "outputId": "4fa2e5ae-abe5-43fc-ad3a-a072b6a420e6"
      },
      "source": [
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'MarquesGabi_Routines' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6cMHOrlNliO"
      },
      "source": [
        "# leitura dos dados\n",
        "df=pd.read_excel(\"FotosTreinoRede.xlsx\")\n",
        "y = df['y']\n",
        "df.drop(['Unnamed: 0','y'], axis='columns', inplace=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQO8d2QbNqj0"
      },
      "source": [
        "X =np.array(df.copy())/255.0 \n",
        "\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23iKv6bDPWQl"
      },
      "source": [
        "# helper\n",
        "def ynindicator(Y):\n",
        "  N = len(Y)\n",
        "  K = len(set(Y))\n",
        "  I = np.zeros((N, K))\n",
        "  I[np.arange(N), Y] = 1\n",
        "  return I\n",
        "\n",
        "def yback(Y_test):\n",
        "  nrow, ncol = Y_test.shape\n",
        "  y_class = np.zeros(nrow,dtype=int)\n",
        "  y_resp = Y_test\n",
        "  for k in range(nrow):\n",
        "    for kk in range(K):\n",
        "      if(y_resp[k,kk] == 1):\n",
        "        y_class[k] = kk\n",
        "  Y_test = y_class.copy()\n",
        "  return Y_test\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train)\n",
        "K = len(set(Y_train))\n",
        "\n",
        "X_train = X_train.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "Y_train = Y_train.astype(np.int32)\n",
        "Y_train = ynindicator(Y_train)\n",
        "\n",
        "X_test = np.array(X_test )\n",
        "Y_test = np.array(Y_test)\n",
        "X_test = X_test.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "Y_test = Y_test.astype(np.int32)\n",
        "Y_test = ynindicator(Y_test)\n",
        "\n",
        "# the model will be a sequence of layers\n",
        "\n",
        "Description = '3 layers of Convolution: 32, 64, 128 '\n",
        "N1 = 200\n",
        "N2 = 10\n",
        "\n",
        "# make the CNN\n",
        "model = Sequential()\n",
        "model.add(Conv2D(input_shape=(Img_Size, Img_Size, 1), filters=32, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=N1))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=N2))\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(units=K))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "# list of losses: https://keras.io/losses/\n",
        "# list of optimizers: https://keras.io/optimizers/\n",
        "# list of metrics: https://keras.io/metrics/\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpbPQ1FSRG6A",
        "outputId": "2fb73928-6d92-43e4-8898-fe8d9bd6484c"
      },
      "source": [
        "\n",
        "# gives us back a <keras.callbacks.History object at 0x112e61a90>\n",
        "model.fit(X_train, Y_train, epochs=200, batch_size=32)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "11/11 [==============================] - 20s 49ms/step - loss: 0.6912 - accuracy: 0.6321\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 0.3085 - accuracy: 0.8616\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 0.1805 - accuracy: 0.9363\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 0.1477 - accuracy: 0.9424\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 0.0997 - accuracy: 0.9645\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 0.0885 - accuracy: 0.9678\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 0.0384 - accuracy: 0.9808\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 0.0463 - accuracy: 0.9771\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 0.0157 - accuracy: 0.9990\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 0.0121 - accuracy: 0.9986\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 0.0169 - accuracy: 0.9912\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 0.0099 - accuracy: 0.9983\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 1s 45ms/step - loss: 0.0178 - accuracy: 0.9906\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 0.0069 - accuracy: 0.9958\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 0.0051 - accuracy: 0.9967\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 8.1158e-04 - accuracy: 1.0000\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 9.6399e-04 - accuracy: 1.0000\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 1s 45ms/step - loss: 9.2314e-04 - accuracy: 1.0000\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 4.4225e-04 - accuracy: 1.0000\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 8.5099e-04 - accuracy: 1.0000\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 5.1241e-04 - accuracy: 1.0000\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 4.3024e-04 - accuracy: 1.0000\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 1s 45ms/step - loss: 2.4494e-04 - accuracy: 1.0000\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 1s 45ms/step - loss: 3.0884e-04 - accuracy: 1.0000\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 6.5702e-04 - accuracy: 1.0000\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 3.3108e-04 - accuracy: 1.0000\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 8.5531e-04 - accuracy: 1.0000\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 2.1697e-04 - accuracy: 1.0000\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 7.4797e-04 - accuracy: 1.0000\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 2.3891e-04 - accuracy: 1.0000\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 2.7957e-04 - accuracy: 1.0000\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 2.6150e-04 - accuracy: 1.0000\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 3.1010e-04 - accuracy: 1.0000\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 1.5517e-04 - accuracy: 1.0000\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 1.0300e-04 - accuracy: 1.0000\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 1.6324e-04 - accuracy: 1.0000\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 9.1819e-05 - accuracy: 1.0000\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 9.9557e-05 - accuracy: 1.0000\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 8.2097e-05 - accuracy: 1.0000\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 1.1809e-04 - accuracy: 1.0000\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 8.1486e-05 - accuracy: 1.0000\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 1.0805e-04 - accuracy: 1.0000\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 1.7473e-04 - accuracy: 1.0000\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 2.4118e-04 - accuracy: 1.0000\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 1.1294e-04 - accuracy: 1.0000\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 1.2815e-04 - accuracy: 1.0000\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 7.3104e-05 - accuracy: 1.0000\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 9.7549e-05 - accuracy: 1.0000\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 1.4228e-04 - accuracy: 1.0000\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 1.1787e-04 - accuracy: 1.0000\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 1.8053e-04 - accuracy: 1.0000\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 1.7220e-04 - accuracy: 1.0000\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 2.7549e-04 - accuracy: 1.0000\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 1.1212e-04 - accuracy: 1.0000\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 1.1629e-04 - accuracy: 1.0000\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 1.0067e-04 - accuracy: 1.0000\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 1.3481e-04 - accuracy: 1.0000\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 1.6496e-04 - accuracy: 1.0000\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 8.9418e-05 - accuracy: 1.0000\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 1s 45ms/step - loss: 5.0278e-05 - accuracy: 1.0000\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 8.4326e-05 - accuracy: 1.0000\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 6.3070e-05 - accuracy: 1.0000\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 2.1558e-04 - accuracy: 1.0000\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 4.3720e-05 - accuracy: 1.0000\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 6.8407e-05 - accuracy: 1.0000\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 9.4045e-05 - accuracy: 1.0000\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 1.2723e-04 - accuracy: 1.0000\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 1.6234e-04 - accuracy: 1.0000\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 3.8753e-05 - accuracy: 1.0000\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 3.2841e-05 - accuracy: 1.0000\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 1.3700e-04 - accuracy: 1.0000\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 5.0428e-05 - accuracy: 1.0000\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 2.7731e-05 - accuracy: 1.0000\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 7.9632e-05 - accuracy: 1.0000\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 3.8429e-05 - accuracy: 1.0000\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 4.1775e-05 - accuracy: 1.0000\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 7.8502e-05 - accuracy: 1.0000\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 6.4838e-05 - accuracy: 1.0000\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 2.6392e-04 - accuracy: 1.0000\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 8.2685e-05 - accuracy: 1.0000\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 9.8168e-05 - accuracy: 1.0000\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 9.2736e-05 - accuracy: 1.0000\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 3.3014e-05 - accuracy: 1.0000\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 2.8382e-05 - accuracy: 1.0000\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 5.4281e-05 - accuracy: 1.0000\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 2.1012e-05 - accuracy: 1.0000\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 3.2116e-05 - accuracy: 1.0000\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 5.4648e-05 - accuracy: 1.0000\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 6.4003e-05 - accuracy: 1.0000\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 3.1751e-05 - accuracy: 1.0000\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 1.1624e-04 - accuracy: 1.0000\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 1.1112e-04 - accuracy: 1.0000\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 2.7863e-05 - accuracy: 1.0000\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 5.4859e-05 - accuracy: 1.0000\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 1.2294e-04 - accuracy: 1.0000\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 1.9807e-04 - accuracy: 1.0000\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 5.4174e-05 - accuracy: 1.0000\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 1.6380e-04 - accuracy: 1.0000\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 5.0025e-04 - accuracy: 1.0000\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 1.0568e-04 - accuracy: 1.0000\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.7361e-04 - accuracy: 1.0000\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 5.0467e-05 - accuracy: 1.0000\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.6062e-04 - accuracy: 1.0000\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 3.3941e-05 - accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 1.7000e-05 - accuracy: 1.0000\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.2654e-05 - accuracy: 1.0000\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 4.6036e-05 - accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 1.6279e-05 - accuracy: 1.0000\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 2.6976e-05 - accuracy: 1.0000\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 2.4013e-05 - accuracy: 1.0000\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 8.1135e-05 - accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 2.9256e-05 - accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 1.9527e-05 - accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.2325e-04 - accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 2.5498e-04 - accuracy: 1.0000\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 5.3195e-05 - accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 5.9848e-05 - accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 3.0620e-05 - accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 1.8370e-04 - accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 0.0081 - accuracy: 0.9960\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 0.5269 - accuracy: 0.9093\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 0.1487 - accuracy: 0.9533\n",
            "Epoch 127/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 0.1143 - accuracy: 0.9456\n",
            "Epoch 128/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 0.0565 - accuracy: 0.9688\n",
            "Epoch 129/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 0.0123 - accuracy: 0.9993\n",
            "Epoch 130/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 0.0919 - accuracy: 0.9687\n",
            "Epoch 131/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 0.0407 - accuracy: 0.9792\n",
            "Epoch 132/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 0.0284 - accuracy: 0.9907\n",
            "Epoch 133/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 0.0202 - accuracy: 0.9929\n",
            "Epoch 134/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 0.0405 - accuracy: 0.9862\n",
            "Epoch 135/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 0.0057 - accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 7.1573e-04 - accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 7.1284e-04 - accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 6.1696e-04 - accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 0.0035 - accuracy: 0.9986\n",
            "Epoch 141/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 0.0069 - accuracy: 0.9973\n",
            "Epoch 142/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 5.2499e-04 - accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 2.8441e-04 - accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 7.0170e-04 - accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 0.0070 - accuracy: 0.9958\n",
            "Epoch 148/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.8355e-04 - accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 1.8547e-04 - accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 1.3404e-04 - accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 1.6819e-04 - accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 4.1643e-04 - accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 8.8106e-05 - accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 2.1387e-04 - accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 3.9590e-04 - accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 1.3811e-04 - accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 9.3691e-04 - accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 1.3811e-04 - accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.2843e-04 - accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 7.6158e-05 - accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 1.0992e-04 - accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.9439e-04 - accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 1.6093e-04 - accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 9.8513e-05 - accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 1.4228e-04 - accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 2.4806e-04 - accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 4.5948e-05 - accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "11/11 [==============================] - 1s 45ms/step - loss: 3.6563e-05 - accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 3.5943e-05 - accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 6.9349e-05 - accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 3.8412e-05 - accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 5.2090e-05 - accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 4.0412e-05 - accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 5.3822e-05 - accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 4.8580e-05 - accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 3.9938e-05 - accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 1.6105e-04 - accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 3.8603e-05 - accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 4.3570e-05 - accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 4.0629e-05 - accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 4.3626e-04 - accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 3.9863e-05 - accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 3.5585e-05 - accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 8.8060e-05 - accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 4.1990e-05 - accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 1.1083e-04 - accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 3.7527e-05 - accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 5.8949e-05 - accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 4.5316e-05 - accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 1.7372e-04 - accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 7.4757e-05 - accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 4.2518e-05 - accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 6.9286e-05 - accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 5.5129e-05 - accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 2.6361e-04 - accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 1.5869e-04 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcb44471f50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSTlOSUBWMpj"
      },
      "source": [
        "Y_test = yback(Y_test)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpf0XlSARX78",
        "outputId": "ca89f25d-2246-4247-d3cd-7405af98ab30"
      },
      "source": [
        "pred_test= model.predict_classes(X_test)\n",
        "\n",
        "data = {'y_true': Y_test,'y_predict': pred_test}  # este dado esta no formato de dicionario\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_true','y_predict'])\n",
        "\n",
        "\n",
        "confusion_matrix = pd.crosstab(df['y_true'], df['y_predict'], rownames=['Actual'], colnames=['Predict'])\n",
        "print(confusion_matrix)\n",
        "\n",
        "y_true = df['y_true']\n",
        "y_pred = df['y_predict']\n",
        "\n",
        "  \n",
        "METRICS=sklearn.metrics.classification_report(y_true, y_pred)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Predict   1\n",
            "Actual     \n",
            "0        72\n",
            "1        75\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iFNNrlWV9tH",
        "outputId": "7c2749c1-ee16-4079-dd4d-8c103d1fbf08"
      },
      "source": [
        "pred_test"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QISvYcJBgWbE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6453f98e-7208-44d0-dd9d-aa7255f2b039"
      },
      "source": [
        "cont = 0; num =25\n",
        "img_graos = []\n",
        "Width_new = []\n",
        "img=ww[0] \n",
        "while( cont < num):\n",
        "  df=Segmenta(img)\n",
        "  df_ann =df.copy()\n",
        "  Width = df['Width']\n",
        "  del df_ann['Width']\n",
        "  result = np.array(df_ann)\n",
        "  result = result.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "  prediction = model.predict_classes(result)\n",
        "  loc_grao =[];k=0\n",
        "  for i in prediction:\n",
        "    if( i == 0):\n",
        "      img_graos.append(df.iloc[k,:])\n",
        "      Width_new.append(Width.iloc[k])\n",
        "      cont = cont + 1\n",
        "    k = k +1\n",
        "img_graos = pd.DataFrame(img_graos)\n",
        "print(img_graos)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "    Width           0           1  ...         781         782         783\n",
            "44  118.0   76.873314   76.610176  ...   99.569374  103.894279  102.871017\n",
            "5   118.0    1.841712    2.146222  ...   37.178688   34.897156   34.719044\n",
            "8   177.0    0.452137    0.329886  ...   83.773109   84.853897   85.494141\n",
            "21  134.0   83.529739   82.590118  ...   83.347290   84.561821   86.808640\n",
            "9   152.0    2.920360    3.396814  ...   88.761078   79.566475   59.349716\n",
            "20  116.0    1.000000    1.112961  ...   50.793106   40.526752   30.177170\n",
            "5   152.0    0.510388    0.355263  ...   87.686279   86.876038   87.443901\n",
            "2   155.0   73.558304  105.709221  ...   36.368080   38.419483   40.962585\n",
            "29  172.0    0.000000    0.713899  ...    1.561385    0.109789    0.000000\n",
            "42  103.0   75.305862   79.386559  ...   91.972382   94.817894   95.046936\n",
            "9   106.0  104.775009   97.369530  ...   74.985397   78.296196   80.024918\n",
            "35  106.0    0.596298    0.850481  ...   56.988964   59.566750   60.704521\n",
            "37  101.0    0.000000    0.056661  ...   64.723465   64.653175   63.841682\n",
            "28  190.0    0.540831    1.352133  ...   84.121559   84.093956   87.418953\n",
            "16  153.0    1.667478    2.253578  ...    0.000000    0.000000    0.000000\n",
            "31  196.0    0.204082    0.571429  ...  100.530609  103.367348  105.122444\n",
            "21  124.0    1.313215    0.941727  ...   58.804367   59.822060   58.218517\n",
            "41  179.0    0.332075    0.000000  ...   29.559532    6.200025    1.166037\n",
            "42  174.0    0.000000    0.322368  ...    0.000000    0.000000    0.000000\n",
            "10  131.0    1.368743    1.316182  ...   30.657419   58.048309   82.805954\n",
            "3   103.0    0.073900    0.100292  ...   55.808556   53.088039   50.210857\n",
            "11  102.0   27.837374   34.038063  ...    0.000000    0.000000    0.000000\n",
            "12  110.0    0.000000    0.000000  ...    0.000000    0.000000    0.000000\n",
            "31  102.0    0.251826    1.062284  ...  103.982323  113.761642  111.114960\n",
            "0   164.0    1.575253    3.041047  ...    0.000000    0.000000    0.000000\n",
            "\n",
            "[25 rows x 785 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LkA4vHp-f6_"
      },
      "source": [
        "Width=np.array(Width_new)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjRbWgmX_LFH",
        "outputId": "a6c25b7a-31fa-4845-93c3-bf23bbfa49bf"
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_paper_fev_2021\n",
        "%cd marquesgabi_paper_fev_2021\n",
        "\n",
        "from Get_PSDArea_New import PSDArea\n",
        "from histogram_fev_2021 import PSD\n",
        "from GetBetterSegm import GetBetter"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'marquesgabi_paper_fev_2021' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines/marquesgabi_paper_fev_2021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAG_I6FwCvFr",
        "outputId": "300d4422-1bfa-4782-ea0c-43e5e2f32c32"
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_out_2020\n",
        "%cd marquesgabi_out_2020\n",
        "PSD_imageJ = 'Areas_ImageJ.csv'\n",
        "PSD_new = pd.read_csv(PSD_imageJ)\n",
        "print(PSD_new.head(3))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'marquesgabi_out_2020' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines/marquesgabi_paper_fev_2021/marquesgabi_out_2020\n",
            "   Juntas   Area\n",
            "0       1  2.001\n",
            "1       2  0.820\n",
            "2       3  1.270\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_1WIM8w7poO"
      },
      "source": [
        "Area_All, Diameter_All=PSDArea(img_graos) "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "PekBHQOT_6CP",
        "outputId": "7234b9cc-ef27-4e8b-cccd-03d0cc7d8ad1"
      },
      "source": [
        "img_graos.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Width</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "      <th>769</th>\n",
              "      <th>770</th>\n",
              "      <th>771</th>\n",
              "      <th>772</th>\n",
              "      <th>773</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>118.0</td>\n",
              "      <td>76.873314</td>\n",
              "      <td>76.610176</td>\n",
              "      <td>79.093941</td>\n",
              "      <td>81.842003</td>\n",
              "      <td>84.416550</td>\n",
              "      <td>83.567932</td>\n",
              "      <td>85.744324</td>\n",
              "      <td>86.733124</td>\n",
              "      <td>83.357941</td>\n",
              "      <td>78.301926</td>\n",
              "      <td>74.356506</td>\n",
              "      <td>68.087044</td>\n",
              "      <td>54.288418</td>\n",
              "      <td>39.357079</td>\n",
              "      <td>28.566790</td>\n",
              "      <td>20.505314</td>\n",
              "      <td>34.437225</td>\n",
              "      <td>111.192184</td>\n",
              "      <td>219.475998</td>\n",
              "      <td>110.952019</td>\n",
              "      <td>66.196503</td>\n",
              "      <td>117.289856</td>\n",
              "      <td>235.848328</td>\n",
              "      <td>245.504730</td>\n",
              "      <td>245.681396</td>\n",
              "      <td>241.362534</td>\n",
              "      <td>167.397873</td>\n",
              "      <td>48.766449</td>\n",
              "      <td>64.995117</td>\n",
              "      <td>62.954323</td>\n",
              "      <td>65.021538</td>\n",
              "      <td>68.016663</td>\n",
              "      <td>70.499855</td>\n",
              "      <td>72.199936</td>\n",
              "      <td>72.823326</td>\n",
              "      <td>73.941971</td>\n",
              "      <td>70.080147</td>\n",
              "      <td>65.674515</td>\n",
              "      <td>62.422581</td>\n",
              "      <td>...</td>\n",
              "      <td>92.909508</td>\n",
              "      <td>116.940529</td>\n",
              "      <td>132.194763</td>\n",
              "      <td>136.334381</td>\n",
              "      <td>140.767014</td>\n",
              "      <td>140.383224</td>\n",
              "      <td>116.238724</td>\n",
              "      <td>102.370872</td>\n",
              "      <td>102.693192</td>\n",
              "      <td>102.988495</td>\n",
              "      <td>104.078140</td>\n",
              "      <td>100.000572</td>\n",
              "      <td>97.223785</td>\n",
              "      <td>100.005173</td>\n",
              "      <td>103.135880</td>\n",
              "      <td>106.812408</td>\n",
              "      <td>108.708130</td>\n",
              "      <td>112.860382</td>\n",
              "      <td>118.794312</td>\n",
              "      <td>124.710999</td>\n",
              "      <td>131.869568</td>\n",
              "      <td>130.663605</td>\n",
              "      <td>76.096802</td>\n",
              "      <td>21.690033</td>\n",
              "      <td>26.016949</td>\n",
              "      <td>53.571098</td>\n",
              "      <td>89.326912</td>\n",
              "      <td>102.851761</td>\n",
              "      <td>110.742317</td>\n",
              "      <td>119.181267</td>\n",
              "      <td>127.180695</td>\n",
              "      <td>135.505310</td>\n",
              "      <td>146.049988</td>\n",
              "      <td>147.998840</td>\n",
              "      <td>118.097389</td>\n",
              "      <td>95.016090</td>\n",
              "      <td>98.100838</td>\n",
              "      <td>99.569374</td>\n",
              "      <td>103.894279</td>\n",
              "      <td>102.871017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>118.0</td>\n",
              "      <td>1.841712</td>\n",
              "      <td>2.146222</td>\n",
              "      <td>2.016662</td>\n",
              "      <td>1.713875</td>\n",
              "      <td>0.494973</td>\n",
              "      <td>0.408791</td>\n",
              "      <td>1.719908</td>\n",
              "      <td>3.213732</td>\n",
              "      <td>5.386671</td>\n",
              "      <td>5.156852</td>\n",
              "      <td>3.764723</td>\n",
              "      <td>3.769894</td>\n",
              "      <td>3.608733</td>\n",
              "      <td>3.728814</td>\n",
              "      <td>3.724792</td>\n",
              "      <td>3.719621</td>\n",
              "      <td>2.565067</td>\n",
              "      <td>2.336397</td>\n",
              "      <td>1.688882</td>\n",
              "      <td>1.701522</td>\n",
              "      <td>2.313703</td>\n",
              "      <td>3.191037</td>\n",
              "      <td>2.441827</td>\n",
              "      <td>2.291296</td>\n",
              "      <td>1.825050</td>\n",
              "      <td>0.823039</td>\n",
              "      <td>0.987934</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.729388</td>\n",
              "      <td>0.889112</td>\n",
              "      <td>0.613617</td>\n",
              "      <td>0.908360</td>\n",
              "      <td>0.890261</td>\n",
              "      <td>0.979891</td>\n",
              "      <td>1.374030</td>\n",
              "      <td>3.124102</td>\n",
              "      <td>4.883367</td>\n",
              "      <td>4.712152</td>\n",
              "      <td>5.591210</td>\n",
              "      <td>...</td>\n",
              "      <td>48.729671</td>\n",
              "      <td>48.403332</td>\n",
              "      <td>48.715599</td>\n",
              "      <td>48.685150</td>\n",
              "      <td>46.839993</td>\n",
              "      <td>39.824760</td>\n",
              "      <td>33.791149</td>\n",
              "      <td>28.887962</td>\n",
              "      <td>26.955759</td>\n",
              "      <td>25.690029</td>\n",
              "      <td>22.845446</td>\n",
              "      <td>18.193909</td>\n",
              "      <td>75.412811</td>\n",
              "      <td>74.029305</td>\n",
              "      <td>69.762703</td>\n",
              "      <td>64.611313</td>\n",
              "      <td>59.679688</td>\n",
              "      <td>54.259411</td>\n",
              "      <td>52.114906</td>\n",
              "      <td>48.747490</td>\n",
              "      <td>44.614479</td>\n",
              "      <td>39.940536</td>\n",
              "      <td>39.402756</td>\n",
              "      <td>41.305656</td>\n",
              "      <td>43.158577</td>\n",
              "      <td>44.093941</td>\n",
              "      <td>45.230392</td>\n",
              "      <td>46.751793</td>\n",
              "      <td>47.050846</td>\n",
              "      <td>47.602413</td>\n",
              "      <td>48.175522</td>\n",
              "      <td>48.735710</td>\n",
              "      <td>48.741165</td>\n",
              "      <td>47.913818</td>\n",
              "      <td>46.620224</td>\n",
              "      <td>43.686584</td>\n",
              "      <td>39.883080</td>\n",
              "      <td>37.178688</td>\n",
              "      <td>34.897156</td>\n",
              "      <td>34.719044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>177.0</td>\n",
              "      <td>0.452137</td>\n",
              "      <td>0.329886</td>\n",
              "      <td>0.952440</td>\n",
              "      <td>0.888793</td>\n",
              "      <td>0.417664</td>\n",
              "      <td>0.602285</td>\n",
              "      <td>0.960899</td>\n",
              "      <td>0.839797</td>\n",
              "      <td>0.890038</td>\n",
              "      <td>0.712120</td>\n",
              "      <td>0.543586</td>\n",
              "      <td>0.665837</td>\n",
              "      <td>0.487631</td>\n",
              "      <td>0.949950</td>\n",
              "      <td>1.210923</td>\n",
              "      <td>1.591656</td>\n",
              "      <td>2.299659</td>\n",
              "      <td>5.755689</td>\n",
              "      <td>3.901720</td>\n",
              "      <td>3.330875</td>\n",
              "      <td>2.015960</td>\n",
              "      <td>0.835201</td>\n",
              "      <td>0.506336</td>\n",
              "      <td>0.467841</td>\n",
              "      <td>0.236841</td>\n",
              "      <td>0.445977</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.224329</td>\n",
              "      <td>0.588177</td>\n",
              "      <td>0.422261</td>\n",
              "      <td>1.419356</td>\n",
              "      <td>1.612468</td>\n",
              "      <td>0.396534</td>\n",
              "      <td>0.879281</td>\n",
              "      <td>1.141434</td>\n",
              "      <td>1.512401</td>\n",
              "      <td>2.303616</td>\n",
              "      <td>3.266622</td>\n",
              "      <td>3.668358</td>\n",
              "      <td>...</td>\n",
              "      <td>36.038174</td>\n",
              "      <td>59.436554</td>\n",
              "      <td>76.688583</td>\n",
              "      <td>80.530968</td>\n",
              "      <td>81.712814</td>\n",
              "      <td>82.670517</td>\n",
              "      <td>84.470879</td>\n",
              "      <td>83.975540</td>\n",
              "      <td>82.441948</td>\n",
              "      <td>82.580162</td>\n",
              "      <td>84.126717</td>\n",
              "      <td>84.079918</td>\n",
              "      <td>85.365341</td>\n",
              "      <td>84.487312</td>\n",
              "      <td>83.187935</td>\n",
              "      <td>73.610352</td>\n",
              "      <td>56.692261</td>\n",
              "      <td>55.198627</td>\n",
              "      <td>55.492924</td>\n",
              "      <td>51.038715</td>\n",
              "      <td>51.819080</td>\n",
              "      <td>54.056301</td>\n",
              "      <td>55.907459</td>\n",
              "      <td>55.743015</td>\n",
              "      <td>57.162014</td>\n",
              "      <td>56.563782</td>\n",
              "      <td>56.715569</td>\n",
              "      <td>54.348682</td>\n",
              "      <td>55.856678</td>\n",
              "      <td>72.850388</td>\n",
              "      <td>79.312035</td>\n",
              "      <td>79.944489</td>\n",
              "      <td>77.953674</td>\n",
              "      <td>78.155014</td>\n",
              "      <td>82.137115</td>\n",
              "      <td>83.298531</td>\n",
              "      <td>82.513260</td>\n",
              "      <td>83.773109</td>\n",
              "      <td>84.853897</td>\n",
              "      <td>85.494141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>134.0</td>\n",
              "      <td>83.529739</td>\n",
              "      <td>82.590118</td>\n",
              "      <td>80.560043</td>\n",
              "      <td>72.078857</td>\n",
              "      <td>57.852974</td>\n",
              "      <td>51.929604</td>\n",
              "      <td>53.814667</td>\n",
              "      <td>54.315437</td>\n",
              "      <td>54.575188</td>\n",
              "      <td>55.627987</td>\n",
              "      <td>58.116734</td>\n",
              "      <td>60.735580</td>\n",
              "      <td>61.351753</td>\n",
              "      <td>61.582981</td>\n",
              "      <td>58.219208</td>\n",
              "      <td>51.355316</td>\n",
              "      <td>49.324795</td>\n",
              "      <td>49.226334</td>\n",
              "      <td>50.016937</td>\n",
              "      <td>51.975502</td>\n",
              "      <td>41.569168</td>\n",
              "      <td>15.073736</td>\n",
              "      <td>9.202050</td>\n",
              "      <td>11.624861</td>\n",
              "      <td>23.713524</td>\n",
              "      <td>40.963688</td>\n",
              "      <td>54.233238</td>\n",
              "      <td>63.222767</td>\n",
              "      <td>67.780128</td>\n",
              "      <td>60.076408</td>\n",
              "      <td>53.263977</td>\n",
              "      <td>47.586990</td>\n",
              "      <td>42.054356</td>\n",
              "      <td>44.723545</td>\n",
              "      <td>52.088661</td>\n",
              "      <td>57.983070</td>\n",
              "      <td>63.112057</td>\n",
              "      <td>68.455338</td>\n",
              "      <td>76.760529</td>\n",
              "      <td>...</td>\n",
              "      <td>109.518837</td>\n",
              "      <td>108.834488</td>\n",
              "      <td>105.279579</td>\n",
              "      <td>106.771667</td>\n",
              "      <td>110.707954</td>\n",
              "      <td>108.629089</td>\n",
              "      <td>99.994431</td>\n",
              "      <td>70.260864</td>\n",
              "      <td>67.080872</td>\n",
              "      <td>82.729790</td>\n",
              "      <td>86.460243</td>\n",
              "      <td>89.645355</td>\n",
              "      <td>57.359550</td>\n",
              "      <td>40.855202</td>\n",
              "      <td>66.677658</td>\n",
              "      <td>95.409225</td>\n",
              "      <td>101.914688</td>\n",
              "      <td>102.399422</td>\n",
              "      <td>104.356873</td>\n",
              "      <td>100.982399</td>\n",
              "      <td>96.891296</td>\n",
              "      <td>98.014481</td>\n",
              "      <td>98.879044</td>\n",
              "      <td>103.338829</td>\n",
              "      <td>107.288040</td>\n",
              "      <td>106.887512</td>\n",
              "      <td>105.860558</td>\n",
              "      <td>107.719757</td>\n",
              "      <td>112.062820</td>\n",
              "      <td>111.401649</td>\n",
              "      <td>111.698822</td>\n",
              "      <td>108.876366</td>\n",
              "      <td>108.394302</td>\n",
              "      <td>104.393410</td>\n",
              "      <td>95.980179</td>\n",
              "      <td>78.515709</td>\n",
              "      <td>76.779243</td>\n",
              "      <td>83.347290</td>\n",
              "      <td>84.561821</td>\n",
              "      <td>86.808640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>152.0</td>\n",
              "      <td>2.920360</td>\n",
              "      <td>3.396814</td>\n",
              "      <td>2.459834</td>\n",
              "      <td>2.776315</td>\n",
              "      <td>2.630194</td>\n",
              "      <td>4.180055</td>\n",
              "      <td>3.509003</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>1.909280</td>\n",
              "      <td>4.770775</td>\n",
              "      <td>5.585873</td>\n",
              "      <td>1.448754</td>\n",
              "      <td>0.743075</td>\n",
              "      <td>2.047091</td>\n",
              "      <td>5.215374</td>\n",
              "      <td>2.180055</td>\n",
              "      <td>3.103186</td>\n",
              "      <td>3.494460</td>\n",
              "      <td>5.332410</td>\n",
              "      <td>6.759695</td>\n",
              "      <td>7.833794</td>\n",
              "      <td>22.739613</td>\n",
              "      <td>48.816483</td>\n",
              "      <td>65.729225</td>\n",
              "      <td>75.875343</td>\n",
              "      <td>83.390579</td>\n",
              "      <td>92.802628</td>\n",
              "      <td>100.195290</td>\n",
              "      <td>1.358033</td>\n",
              "      <td>1.414127</td>\n",
              "      <td>1.339335</td>\n",
              "      <td>2.031856</td>\n",
              "      <td>1.588643</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>0.921745</td>\n",
              "      <td>0.747922</td>\n",
              "      <td>1.021468</td>\n",
              "      <td>1.794321</td>\n",
              "      <td>3.166897</td>\n",
              "      <td>...</td>\n",
              "      <td>82.793633</td>\n",
              "      <td>86.106651</td>\n",
              "      <td>87.816475</td>\n",
              "      <td>90.230614</td>\n",
              "      <td>92.027695</td>\n",
              "      <td>92.918976</td>\n",
              "      <td>93.191124</td>\n",
              "      <td>92.718834</td>\n",
              "      <td>91.008987</td>\n",
              "      <td>90.090714</td>\n",
              "      <td>84.815788</td>\n",
              "      <td>77.058167</td>\n",
              "      <td>55.022850</td>\n",
              "      <td>65.159279</td>\n",
              "      <td>74.263153</td>\n",
              "      <td>76.148888</td>\n",
              "      <td>73.518692</td>\n",
              "      <td>70.360107</td>\n",
              "      <td>66.941826</td>\n",
              "      <td>66.425903</td>\n",
              "      <td>78.185600</td>\n",
              "      <td>87.508995</td>\n",
              "      <td>84.218140</td>\n",
              "      <td>85.186981</td>\n",
              "      <td>82.284622</td>\n",
              "      <td>82.016617</td>\n",
              "      <td>81.918282</td>\n",
              "      <td>80.282547</td>\n",
              "      <td>81.421745</td>\n",
              "      <td>84.561638</td>\n",
              "      <td>88.439743</td>\n",
              "      <td>89.917595</td>\n",
              "      <td>90.135727</td>\n",
              "      <td>92.477837</td>\n",
              "      <td>93.090721</td>\n",
              "      <td>94.372574</td>\n",
              "      <td>92.340721</td>\n",
              "      <td>88.761078</td>\n",
              "      <td>79.566475</td>\n",
              "      <td>59.349716</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Width          0          1  ...        781         782         783\n",
              "44  118.0  76.873314  76.610176  ...  99.569374  103.894279  102.871017\n",
              "5   118.0   1.841712   2.146222  ...  37.178688   34.897156   34.719044\n",
              "8   177.0   0.452137   0.329886  ...  83.773109   84.853897   85.494141\n",
              "21  134.0  83.529739  82.590118  ...  83.347290   84.561821   86.808640\n",
              "9   152.0   2.920360   3.396814  ...  88.761078   79.566475   59.349716\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vmhG2LgCabC"
      },
      "source": [
        "Area = np.array(PSD_new['Area'])\n",
        "diam_teste = []\n",
        "for A in Area:\n",
        "  diam_teste.append((4*A/np.pi)**0.5) \n",
        "\n",
        "Diam1 = [ (4*A/np.pi)**0.5 for A in Area]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J705kDqsE8f",
        "outputId": "3585ca6c-b514-4a0f-c623-0184c0b577d8"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(490, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wCFDX8esLoQ"
      },
      "source": [
        ""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hn-F050Hr9Ui"
      },
      "source": [
        ""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Vfk_fNXGDK5_",
        "outputId": "8900d3a3-4cce-4c1c-cf41-5a1ee4eaaffd"
      },
      "source": [
        " wt1 = np.ones(len(Diam1)) / len(Diam1)*100\n",
        " wt2 = np.ones(len(Diameter_All)) / len(Diameter_All)*100\n",
        " X = pd.DataFrame([Diam1,Diameter_All])\n",
        " wts = pd.DataFrame([wt1,wt2])\n",
        "plt.hist(X,weights=wts)\n",
        "plt.legend(['Image J','CNN'])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fcb43a0b750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nGDbBEeiUij",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "d7e466d1-d32e-4b4d-f041-40e22a69b28e"
      },
      "source": [
        "# plt.hist(x, bins=bins, density=True, histtype='step', cumulative=-1,label='Reversed emp.')\n",
        "plt.hist(X, density=True, histtype='step', cumulative=True,label='Reversed emp.')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.03157895, 0.11578947, 0.27368421, 0.56842105, 0.85263158,\n",
              "         0.93684211, 0.97894737, 0.97894737, 0.98947368, 1.        ],\n",
              "        [0.28      , 0.28      , 0.52      , 0.68      , 0.8       ,\n",
              "         0.96      , 1.        , 1.        , 1.        , 1.        ]]),\n",
              " array([0.60947139, 0.78026817, 0.95106495, 1.12186173, 1.29265851,\n",
              "        1.46345529, 1.63425207, 1.80504885, 1.97584563, 2.14664241,\n",
              "        2.31743919]),\n",
              " <a list of 2 Lists of Patches objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "9xENlBUUxfTu",
        "outputId": "af3fb0cc-4450-402d-d4d5-62978ace39f7"
      },
      "source": [
        "Obj = plt.hist(X, density=True, histtype='step', cumulative=True,label='Reversed emp.')\n",
        "Y1, Y2 = Obj[0]\n",
        "Rsquared = r2_score(Y1, Y2)\n",
        "print('r_squared =',Rsquared)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "r_squared = 0.8803693270235976\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euTd_-CYN1v0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6b53e39d-36ed-46ea-d7d1-c66f8d158276"
      },
      "source": [
        "\n",
        "df = pd.DataFrame({'N1':N1, 'N2':N2,'R^2':Rsquared,'Details':Description},\n",
        "                  index= [0])\n",
        "Arq = \"output.xlsx\"\n",
        "df.to_excel(Arq)\n",
        "files.download(Arq)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_de865704-8a78-423b-9131-d82a4a888f2f\", \"output.xlsx\", 5052)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "-KukfpGTTKlj",
        "outputId": "94533101-5e33-40bf-d03b-efe419f55dce"
      },
      "source": [
        "df"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>N1</th>\n",
              "      <th>N2</th>\n",
              "      <th>R^2</th>\n",
              "      <th>Details</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>200</td>\n",
              "      <td>10</td>\n",
              "      <td>0.880369</td>\n",
              "      <td>3 layers of Convolution: 32, 64, 128</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    N1  N2       R^2                                Details\n",
              "0  200  10  0.880369  3 layers of Convolution: 32, 64, 128 "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "ZZHa1j4HT9Dq",
        "outputId": "e39931f0-e506-4561-f5df-8e86169531fc"
      },
      "source": [
        "counts, bins, bars = plt.hist(X,weights=wts)\n",
        "print(bars)\n",
        "print(bins)\n",
        "print(counts)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<a list of 2 Lists of Patches objects>\n",
            "[0.60947139 0.78026817 0.95106495 1.12186173 1.29265851 1.46345529\n",
            " 1.63425207 1.80504885 1.97584563 2.14664241 2.31743919]\n",
            "[[ 3.15789474  8.42105263 15.78947368 29.47368421 28.42105263  8.42105263\n",
            "   4.21052632  0.          1.05263158  1.05263158]\n",
            " [28.          0.         24.         16.         12.         16.\n",
            "   4.          0.          0.          0.        ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8o_vDGeWUwIZ",
        "outputId": "fa4f8b90-c55e-415f-8cbf-2bff09aecede"
      },
      "source": [
        "print(counts.sum())"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200.0000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "KcH52-6iJQ8t",
        "outputId": "2223db6e-d346-497c-d693-2d0decebdb82"
      },
      "source": [
        "\n",
        "plt.hist([Diam1,Diameter_All])\n",
        "plt.legend(['Image J','CNN'])\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fcb3ad3d850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r11AxFK_JIii",
        "outputId": "48e33b9b-c53d-408e-95e5-9a6009215335"
      },
      "source": [
        "[Diam1,Diameter_All]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1.59616801403081,\n",
              "  1.0217907939900581,\n",
              "  1.2716187407449044,\n",
              "  1.104429030701514,\n",
              "  1.2163487785097904,\n",
              "  1.6013445735058454,\n",
              "  1.1715597420637607,\n",
              "  1.2534662333717612,\n",
              "  1.2676073151634049,\n",
              "  1.309600575274104,\n",
              "  1.292966945531582,\n",
              "  1.7658322811231006,\n",
              "  1.3564037533648712,\n",
              "  1.2407040781688483,\n",
              "  2.130217298173151,\n",
              "  1.4228319915327,\n",
              "  1.0651086490865755,\n",
              "  1.3008210311003705,\n",
              "  1.336545951796433,\n",
              "  0.8927754224911278,\n",
              "  1.4494292838262302,\n",
              "  1.4052738287907582,\n",
              "  1.6421697097891788,\n",
              "  1.2329833804288621,\n",
              "  1.19042665178928,\n",
              "  1.1682948223612457,\n",
              "  1.1518314137121108,\n",
              "  0.9607802401865855,\n",
              "  2.317439190074449,\n",
              "  1.0591147430338594,\n",
              "  1.4308630919602832,\n",
              "  0.7535680705496237,\n",
              "  0.8608283307581511,\n",
              "  1.2776122636975893,\n",
              "  1.3745862957220916,\n",
              "  1.259546137598783,\n",
              "  1.2978813187979172,\n",
              "  1.2412170838050638,\n",
              "  1.6009469708743893,\n",
              "  1.3149369953539032,\n",
              "  1.417901703622935,\n",
              "  1.2478669653497139,\n",
              "  1.1055812783082735,\n",
              "  0.9561307405997607,\n",
              "  0.9487783503683882,\n",
              "  1.1238565871041026,\n",
              "  1.2058356273089446,\n",
              "  1.2801012827406097,\n",
              "  0.8733100751144249,\n",
              "  0.9194732501297403,\n",
              "  1.6425573339441792,\n",
              "  1.085826790250066,\n",
              "  1.0639125693728595,\n",
              "  1.0875842666474016,\n",
              "  1.417901703622935,\n",
              "  1.550443891425932,\n",
              "  0.7825779328716171,\n",
              "  1.4690612745308145,\n",
              "  1.053086721720641,\n",
              "  1.2676073151634049,\n",
              "  0.7744003006005755,\n",
              "  1.3787482149724068,\n",
              "  1.363892581861956,\n",
              "  1.299352006316543,\n",
              "  1.2870449283923413,\n",
              "  1.11817763925502,\n",
              "  0.9474354220939228,\n",
              "  1.5218484589055707,\n",
              "  1.3526437911676632,\n",
              "  1.1556938532445284,\n",
              "  1.6013445735058454,\n",
              "  1.274619025074578,\n",
              "  1.422384489715834,\n",
              "  1.3408259533459403,\n",
              "  1.172646028567008,\n",
              "  1.1490645795125545,\n",
              "  1.459060149136146,\n",
              "  1.2483770274864237,\n",
              "  1.336545951796433,\n",
              "  0.9601174044814821,\n",
              "  1.4867225193896279,\n",
              "  1.4277452542806772,\n",
              "  1.35028849808504,\n",
              "  0.7560982446653928,\n",
              "  1.259040600296622,\n",
              "  1.13456827900627,\n",
              "  1.6549133695530214,\n",
              "  1.1204526724091788,\n",
              "  1.1176081573544434,\n",
              "  0.9153095762832032,\n",
              "  1.1639273497938836,\n",
              "  1.3066806149514323,\n",
              "  1.1529362882239027,\n",
              "  1.3047303442899274,\n",
              "  1.3066806149514323],\n",
              " [1.1276636358396377,\n",
              "  0.7723328279186659,\n",
              "  1.3884426788254527,\n",
              "  1.0709097371582945,\n",
              "  1.1866616407416226,\n",
              "  0.7796741380500972,\n",
              "  1.1656232637143638,\n",
              "  1.4828314011688575,\n",
              "  1.5920838330870288,\n",
              "  0.9523150153084252,\n",
              "  1.1177252617261335,\n",
              "  0.7700193837825663,\n",
              "  0.609471390783992,\n",
              "  1.4785803921931107,\n",
              "  1.143782707605952,\n",
              "  1.547184862502762,\n",
              "  0.7134397338680607,\n",
              "  1.7556084099466447,\n",
              "  1.4282309656410894,\n",
              "  0.9724687640474184,\n",
              "  1.0803701982327791,\n",
              "  0.7598602897771718,\n",
              "  1.0478443853327923,\n",
              "  0.647584569064857,\n",
              "  1.3442020170093205]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    }
  ]
}