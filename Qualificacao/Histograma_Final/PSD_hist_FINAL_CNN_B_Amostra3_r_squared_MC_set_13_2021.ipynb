{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PSD_hist_FINAL_CNN_B_Amostra3_r_squared_MC_set_13_2021.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ucfilho/marquesgabi_paper_fev_2021/blob/main/Qualificacao/Histograma_Final/PSD_hist_FINAL_CNN_B_Amostra3_r_squared_MC_set_13_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sog7Z9pyhUD_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import zipfile\n",
        "#import random\n",
        "from random import randint\n",
        "from PIL import Image\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "#import scikit-image\n",
        "import skimage\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
        "from sklearn.metrics import r2_score\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZEvJvfoibE4",
        "outputId": "027e0e52-10b5-4b25-a735-43bc7fb093bc"
      },
      "source": [
        "!pip install mahotas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mahotas in /usr/local/lib/python3.7/dist-packages (1.4.11)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mahotas) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf_a6PJ1iUnT"
      },
      "source": [
        "import mahotas.features.texture as mht\n",
        "import mahotas.features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VcTdaNVh9EE",
        "outputId": "e2d93dd0-e458-4618-bd01-3aa0f229b805"
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_fev_2020 #clonar do Github\n",
        "%cd marquesgabi_fev_2020\n",
        "import Go2BlackWhite\n",
        "import Go2Mahotas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'marquesgabi_fev_2020' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v7SRrc8mH2N",
        "outputId": "0f332733-61f1-423c-f475-b391b9a47de2"
      },
      "source": [
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "%cd Doutorado\n",
        "\n",
        "Transfere='Fotos_Grandes_3cdAmostra.zip' \n",
        "file_name = zipfile.ZipFile(Transfere, 'r')\n",
        "file_name.extractall()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Doutorado'...\n",
            "remote: Enumerating objects: 455, done.\u001b[K\n",
            "remote: Counting objects: 100% (205/205), done.\u001b[K\n",
            "remote: Compressing objects: 100% (201/201), done.\u001b[K\n",
            "remote: Total 455 (delta 96), reused 4 (delta 3), pack-reused 250\u001b[K\n",
            "Receiving objects: 100% (455/455), 165.99 MiB | 29.21 MiB/s, done.\n",
            "Resolving deltas: 100% (219/219), done.\n",
            "/content/marquesgabi_fev_2020/Doutorado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqIYzUcnrdMp",
        "outputId": "d48c2ac6-ab91-4f66-b174-e71b7e9e2427"
      },
      "source": [
        "labels =[]\n",
        "with zipfile.ZipFile(Transfere, \"r\") as f:\n",
        "  for f in f.namelist():\n",
        "    labels.append(f)\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Fotos_Grandes-3cdAmostra/Q6-8-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-8-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-8-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-4.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-7-3.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-9-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-1-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-6-5.jpg', 'Fotos_Grandes-3cdAmostra/Q6-2-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-2.jpg', 'Fotos_Grandes-3cdAmostra/Q6-4-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-3-1.jpg', 'Fotos_Grandes-3cdAmostra/Q6-5-4.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kA4IWSmasoD"
      },
      "source": [
        "Size=1200 # tamanho da foto\n",
        "ww,img_name=Go2BlackWhite.BlackWhite(Transfere,Size) #Pegamos a primeira foto Grande\n",
        "img=ww[4] \n",
        "# this is the big image we want to segment \n",
        "# ww[0], change it if you want to segment another picture"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHgqAnaFyCjp",
        "outputId": "e6ce83ac-594d-4f91-b696-5e855859d73d"
      },
      "source": [
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MarquesGabi_Routines'...\n",
            "remote: Enumerating objects: 163, done.\u001b[K\n",
            "remote: Counting objects: 100% (163/163), done.\u001b[K\n",
            "remote: Compressing objects: 100% (160/160), done.\u001b[K\n",
            "remote: Total 163 (delta 65), reused 3 (delta 1), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (163/163), 211.71 MiB | 22.82 MiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n",
            "Checking out files: 100% (46/46), done.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc4rFvzkyWCi"
      },
      "source": [
        "from segment_filter_not_conclude import Segmenta  # got image provided segmented"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnTtH3KDP863"
      },
      "source": [
        "df=Segmenta(img)\n",
        "Img_Size = 28"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YN5MN5a_v4np",
        "outputId": "42699bf6-1e59-4518-ff26-e0497da4a8ac"
      },
      "source": [
        "print(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Width           0           1  ...         781         782         783\n",
            "0     126  119.518524  122.604935  ...  130.543213  160.975311  172.654312\n",
            "1     164  168.534210  174.939911  ...  113.353355  122.657349  122.289108\n",
            "2     135  199.403015  197.452179  ...  227.695007  116.212395   87.197304\n",
            "3     129  172.691589  161.248276  ...  172.054977  166.377197  155.460297\n",
            "4     152   56.573410   42.761082  ...    0.639197    0.323407    1.402355\n",
            "5     158  151.765427  143.214554  ...   85.991989   90.273834   96.769913\n",
            "6     179  163.327713  144.388901  ...    0.007303    0.571518    0.926001\n",
            "7     105   71.471115   74.022232  ...  166.848907  194.257797  196.684479\n",
            "8     177  143.665817  141.909622  ...    1.130007    0.148457    1.341409\n",
            "9     192  160.491318  185.227432  ...  128.957458  141.958755  144.322037\n",
            "10    185  105.121254  103.989204  ...  174.473419  180.232681  175.620026\n",
            "11    187  230.163071  220.237854  ...  165.797546  180.779617  191.928696\n",
            "12    189  171.241440  174.596710  ...  148.028809  152.927307  149.089157\n",
            "13    172  111.685776   97.328293  ...  129.308273  129.312073  135.787460\n",
            "14    119  240.951553  245.159164  ...  131.456757  132.370239  131.768173\n",
            "15    145  103.023964  107.211174  ...  126.906715  126.597290  133.048950\n",
            "16    163  146.184692  142.369797  ...    0.810079    0.231962    1.373066\n",
            "17    120  152.781113  156.222229  ...    4.712222    1.704445    1.121111\n",
            "18    192  151.497391  144.323334  ...  107.317696  116.172302  126.139320\n",
            "19    158  162.846817  185.445770  ...  120.076752  126.888474  152.833038\n",
            "20    106  112.358856  129.964401  ...  142.195084  139.650757  139.772522\n",
            "21    198  134.011414  126.975609  ...  142.138428  144.915192  146.282410\n",
            "22    191  134.794754  143.271118  ...    1.382747    0.163400    1.314685\n",
            "23    144  239.858032  228.423615  ...   68.245377   62.229168   51.924385\n",
            "24    138  182.045990  167.285645  ...  237.460602  229.612885  206.045151\n",
            "25    132  137.228653  142.860443  ...  176.248840  174.542709  189.191010\n",
            "26    183  185.039398  179.274521  ...  167.318726  170.615524  172.210007\n",
            "27    164  177.866745  116.381325  ...   92.689468  101.332550  106.047592\n",
            "28    135   61.161861   63.044224  ...  160.639877  147.262985  137.041641\n",
            "29    110   45.802639   63.341156  ...    0.916694    0.107107    0.000000\n",
            "30    194   37.467739   49.955570  ...  206.294800  182.810699  166.755859\n",
            "31    197  146.225311  137.498413  ...    1.462548    0.193383    1.300858\n",
            "32    143  108.660034  151.415466  ...  151.921539  150.287491  147.994965\n",
            "33    136  167.406586  194.841705  ...   64.199821   57.655708  130.540665\n",
            "34    123  205.306503  203.513000  ...  132.673416  134.708191  136.539764\n",
            "35    180  145.820267  146.975815  ...  224.629639  197.010391  136.748169\n",
            "36    172   68.348305  107.181183  ...    0.998919    0.173607    1.352082\n",
            "37    115  101.400070  102.292175  ...    0.019055    0.763629    1.546238\n",
            "38    173  140.874451  180.842270  ...  184.141739  183.699783  186.809753\n",
            "39    138  129.164246  142.327881  ...  193.724014  190.419861  194.773163\n",
            "40    172   91.905899   93.028664  ...    0.998919    0.173607    1.352082\n",
            "41    129  188.059906  176.936905  ...  219.410492  181.604355  184.178467\n",
            "42    197  141.266464  150.185532  ...  204.493164  185.103821  171.312195\n",
            "43    113   61.329704  126.202438  ...  156.452591  143.931946  145.033981\n",
            "44    181  177.080200  127.697266  ...  161.874100  164.186523  165.208008\n",
            "45    172  132.214188  133.091400  ...    1.000000    1.000000    1.000000\n",
            "46    108    0.326475    0.252401  ...   10.759945   13.794237   28.572014\n",
            "47    157  162.196960  156.366791  ...  176.068817  171.153442  157.887512\n",
            "48    170  168.380341  168.684021  ...  135.629913  140.412598  137.449829\n",
            "49    114  145.191147  136.996613  ...  153.431519  152.296402  150.092651\n",
            "\n",
            "[50 rows x 785 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "xzpQ1Pz0fX5L",
        "outputId": "7fb6d602-c244-4760-a43f-a840a606c458"
      },
      "source": [
        "'''\n",
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines\n",
        "# filename = 'model_ANN.pkl'\n",
        "filename = 'model_ANN_new.pkl'\n",
        "model = joblib.load(filename)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n!git clone https://github.com/ucfilho/MarquesGabi_Routines\\n%cd MarquesGabi_Routines\\n# filename = 'model_ANN.pkl'\\nfilename = 'model_ANN_new.pkl'\\nmodel = joblib.load(filename)\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR2emP4rNjQy",
        "outputId": "e97f3ed1-856c-48bb-ae45-e5bf7d127497"
      },
      "source": [
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MarquesGabi_Routines'...\n",
            "remote: Enumerating objects: 163, done.\u001b[K\n",
            "remote: Counting objects: 100% (163/163), done.\u001b[K\n",
            "remote: Compressing objects: 100% (160/160), done.\u001b[K\n",
            "remote: Total 163 (delta 65), reused 3 (delta 1), pack-reused 0\n",
            "Receiving objects: 100% (163/163), 211.71 MiB | 22.36 MiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n",
            "Checking out files: 100% (46/46), done.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6cMHOrlNliO"
      },
      "source": [
        "# leitura dos dados\n",
        "df=pd.read_excel(\"FotosTreinoRede.xlsx\")\n",
        "y = df['y']\n",
        "df.drop(['Unnamed: 0','y'], axis='columns', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQO8d2QbNqj0"
      },
      "source": [
        "X =np.array(df.copy())/255.0 \n",
        "\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIFPGE_-vx3T"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23iKv6bDPWQl"
      },
      "source": [
        "# helper\n",
        "def ynindicator(Y):\n",
        "  N = len(Y)\n",
        "  K = len(set(Y))\n",
        "  I = np.zeros((N, K))\n",
        "  I[np.arange(N), Y] = 1\n",
        "  return I\n",
        "\n",
        "def yback(Y_test):\n",
        "  nrow, ncol = Y_test.shape\n",
        "  y_class = np.zeros(nrow,dtype=int)\n",
        "  y_resp = Y_test\n",
        "  for k in range(nrow):\n",
        "    for kk in range(K):\n",
        "      if(y_resp[k,kk] == 1):\n",
        "        y_class[k] = kk\n",
        "  Y_test = y_class.copy()\n",
        "  return Y_test\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train)\n",
        "K = len(set(Y_train))\n",
        "\n",
        "X_train = X_train.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "Y_train = Y_train.astype(np.int32)\n",
        "Y_train = ynindicator(Y_train)\n",
        "\n",
        "X_test = np.array(X_test )\n",
        "Y_test = np.array(Y_test)\n",
        "X_test = X_test.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "Y_test = Y_test.astype(np.int32)\n",
        "Y_test = ynindicator(Y_test)\n",
        "\n",
        "# the model will be a sequence of layers\n",
        "\n",
        "Description = '3 layers of Convolution: 64, 128, 256 '\n",
        "N1 = 20\n",
        "N2 = 20\n",
        "\n",
        "# make the CNN\n",
        "model = Sequential()\n",
        "model.add(Conv2D(input_shape=(Img_Size, Img_Size, 1), filters=64, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=N1))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=N2))\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(units=K))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "# list of losses: https://keras.io/losses/\n",
        "# list of optimizers: https://keras.io/optimizers/\n",
        "# list of metrics: https://keras.io/metrics/\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpbPQ1FSRG6A",
        "outputId": "57416385-4a0f-4cdb-d2cf-3457dd768a9e"
      },
      "source": [
        "\n",
        "# training the model\n",
        "r = model.fit(X_train, Y_train, validation_data=(X_test,Y_test), \n",
        "              epochs=200, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "11/11 [==============================] - 4s 193ms/step - loss: 0.4652 - accuracy: 0.7580 - val_loss: 0.6928 - val_accuracy: 0.5102\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 2s 207ms/step - loss: 0.2750 - accuracy: 0.8805 - val_loss: 0.6929 - val_accuracy: 0.5102\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.1817 - accuracy: 0.9417 - val_loss: 0.6933 - val_accuracy: 0.5102\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 0.1087 - accuracy: 0.9621 - val_loss: 0.6935 - val_accuracy: 0.5102\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 0.1152 - accuracy: 0.9592 - val_loss: 0.6938 - val_accuracy: 0.5102\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 0.0579 - accuracy: 0.9796 - val_loss: 0.6934 - val_accuracy: 0.5102\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 0.0443 - accuracy: 0.9854 - val_loss: 0.6941 - val_accuracy: 0.5102\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0358 - accuracy: 0.9883 - val_loss: 0.6942 - val_accuracy: 0.5102\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0263 - accuracy: 0.9942 - val_loss: 0.6938 - val_accuracy: 0.5102\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.0173 - accuracy: 0.9971 - val_loss: 0.6935 - val_accuracy: 0.5102\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.6936 - val_accuracy: 0.5102\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.6928 - val_accuracy: 0.5102\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.6922 - val_accuracy: 0.5102\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 0.0156 - accuracy: 0.9942 - val_loss: 0.6912 - val_accuracy: 0.5102\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 0.0101 - accuracy: 0.9971 - val_loss: 0.6931 - val_accuracy: 0.5102\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 0.0108 - accuracy: 0.9971 - val_loss: 0.6910 - val_accuracy: 0.5102\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 0.0070 - accuracy: 0.9971 - val_loss: 0.6959 - val_accuracy: 0.5102\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6993 - val_accuracy: 0.5102\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 2s 148ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6963 - val_accuracy: 0.5102\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6900 - val_accuracy: 0.5102\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6899 - val_accuracy: 0.5102\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6895 - val_accuracy: 0.5102\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6879 - val_accuracy: 0.5102\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6852 - val_accuracy: 0.5102\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6834 - val_accuracy: 0.5102\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 2s 145ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6811 - val_accuracy: 0.5102\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6847 - val_accuracy: 0.5102\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6911 - val_accuracy: 0.5102\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7905 - val_accuracy: 0.5102\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.8137 - val_accuracy: 0.5102\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7563 - val_accuracy: 0.5102\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 7.6728e-04 - accuracy: 1.0000 - val_loss: 0.6906 - val_accuracy: 0.5102\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 7.8850e-04 - accuracy: 1.0000 - val_loss: 0.6981 - val_accuracy: 0.5102\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7424 - val_accuracy: 0.5102\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 2s 137ms/step - loss: 6.5717e-04 - accuracy: 1.0000 - val_loss: 0.7804 - val_accuracy: 0.5102\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 3.2098e-04 - accuracy: 1.0000 - val_loss: 0.7918 - val_accuracy: 0.5102\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 3.8722e-04 - accuracy: 1.0000 - val_loss: 0.7592 - val_accuracy: 0.5102\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 4.6550e-04 - accuracy: 1.0000 - val_loss: 0.7237 - val_accuracy: 0.5102\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 4.6957e-04 - accuracy: 1.0000 - val_loss: 0.6970 - val_accuracy: 0.5102\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 2.7034e-04 - accuracy: 1.0000 - val_loss: 0.6794 - val_accuracy: 0.5102\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 7.6882e-04 - accuracy: 1.0000 - val_loss: 0.6350 - val_accuracy: 0.5102\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 1.5611e-04 - accuracy: 1.0000 - val_loss: 0.5958 - val_accuracy: 0.5238\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 2.9901e-04 - accuracy: 1.0000 - val_loss: 0.5564 - val_accuracy: 0.5986\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 1.9820e-04 - accuracy: 1.0000 - val_loss: 0.5113 - val_accuracy: 0.8163\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 1.3027e-04 - accuracy: 1.0000 - val_loss: 0.4688 - val_accuracy: 0.9524\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 2.9895e-04 - accuracy: 1.0000 - val_loss: 0.4674 - val_accuracy: 0.9184\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 2.5792e-04 - accuracy: 1.0000 - val_loss: 0.5127 - val_accuracy: 0.7211\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 5.1510e-04 - accuracy: 1.0000 - val_loss: 0.5159 - val_accuracy: 0.6939\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 2.3415e-04 - accuracy: 1.0000 - val_loss: 0.5453 - val_accuracy: 0.5986\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 2s 145ms/step - loss: 3.1052e-04 - accuracy: 1.0000 - val_loss: 0.5283 - val_accuracy: 0.6054\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 1.9571e-04 - accuracy: 1.0000 - val_loss: 0.4350 - val_accuracy: 0.7619\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 3.0703e-04 - accuracy: 1.0000 - val_loss: 0.4169 - val_accuracy: 0.7279\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 2.4197e-04 - accuracy: 1.0000 - val_loss: 0.4213 - val_accuracy: 0.7211\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 2s 145ms/step - loss: 1.4560e-04 - accuracy: 1.0000 - val_loss: 0.4095 - val_accuracy: 0.7211\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 1s 138ms/step - loss: 1.6775e-04 - accuracy: 1.0000 - val_loss: 0.5914 - val_accuracy: 0.6395\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 1.9750e-04 - accuracy: 1.0000 - val_loss: 0.6345 - val_accuracy: 0.6259\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 1.3951e-04 - accuracy: 1.0000 - val_loss: 0.5861 - val_accuracy: 0.6599\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 1.1690e-04 - accuracy: 1.0000 - val_loss: 0.6025 - val_accuracy: 0.6803\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 2.3189e-04 - accuracy: 1.0000 - val_loss: 0.4052 - val_accuracy: 0.7483\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 2.1160e-04 - accuracy: 1.0000 - val_loss: 0.3467 - val_accuracy: 0.7687\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 4.9287e-04 - accuracy: 1.0000 - val_loss: 0.1287 - val_accuracy: 0.9728\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 5.9460e-05 - accuracy: 1.0000 - val_loss: 0.1374 - val_accuracy: 0.9456\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 1s 138ms/step - loss: 1.8251e-04 - accuracy: 1.0000 - val_loss: 0.1321 - val_accuracy: 0.9456\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 5.7900e-04 - accuracy: 1.0000 - val_loss: 0.1501 - val_accuracy: 0.9456\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 6.8643e-05 - accuracy: 1.0000 - val_loss: 0.4342 - val_accuracy: 0.7687\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 8.7394e-05 - accuracy: 1.0000 - val_loss: 0.4322 - val_accuracy: 0.7687\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 7.6453e-05 - accuracy: 1.0000 - val_loss: 0.3564 - val_accuracy: 0.7959\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 4.9022e-05 - accuracy: 1.0000 - val_loss: 0.2956 - val_accuracy: 0.8299\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 9.0239e-05 - accuracy: 1.0000 - val_loss: 0.2467 - val_accuracy: 0.8844\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 7.7210e-05 - accuracy: 1.0000 - val_loss: 0.1981 - val_accuracy: 0.9116\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 1.5403e-04 - accuracy: 1.0000 - val_loss: 0.1516 - val_accuracy: 0.9456\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 2s 137ms/step - loss: 1.2791e-04 - accuracy: 1.0000 - val_loss: 0.1571 - val_accuracy: 0.9320\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 2s 137ms/step - loss: 6.2889e-05 - accuracy: 1.0000 - val_loss: 0.1534 - val_accuracy: 0.9320\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 3.4131e-05 - accuracy: 1.0000 - val_loss: 0.1399 - val_accuracy: 0.9456\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 1.4878e-04 - accuracy: 1.0000 - val_loss: 0.1360 - val_accuracy: 0.9388\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 3.1855e-04 - accuracy: 1.0000 - val_loss: 0.3332 - val_accuracy: 0.8367\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 2.0922e-04 - accuracy: 1.0000 - val_loss: 0.6755 - val_accuracy: 0.7075\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 2.2669e-04 - accuracy: 1.0000 - val_loss: 1.1380 - val_accuracy: 0.5918\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 1.5123e-04 - accuracy: 1.0000 - val_loss: 1.4876 - val_accuracy: 0.5578\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 2.3440e-04 - accuracy: 1.0000 - val_loss: 1.5010 - val_accuracy: 0.5646\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 1.6941e-04 - accuracy: 1.0000 - val_loss: 1.6278 - val_accuracy: 0.5442\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 1.4860e-04 - accuracy: 1.0000 - val_loss: 1.7231 - val_accuracy: 0.5374\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 7.6608e-05 - accuracy: 1.0000 - val_loss: 1.5954 - val_accuracy: 0.5374\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 4.4645e-04 - accuracy: 1.0000 - val_loss: 0.9792 - val_accuracy: 0.6803\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 3.6402e-04 - accuracy: 1.0000 - val_loss: 1.6939 - val_accuracy: 0.6122\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 6.5368e-05 - accuracy: 1.0000 - val_loss: 1.9933 - val_accuracy: 0.5918\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 1.8501e-04 - accuracy: 1.0000 - val_loss: 2.4959 - val_accuracy: 0.5374\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 1.5623e-04 - accuracy: 1.0000 - val_loss: 2.0814 - val_accuracy: 0.5442\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 5.1014e-05 - accuracy: 1.0000 - val_loss: 1.7276 - val_accuracy: 0.5782\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 4.7299e-05 - accuracy: 1.0000 - val_loss: 1.2265 - val_accuracy: 0.6531\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 6.6109e-05 - accuracy: 1.0000 - val_loss: 1.0086 - val_accuracy: 0.6871\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 4.9030e-05 - accuracy: 1.0000 - val_loss: 0.9940 - val_accuracy: 0.7007\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 5.0782e-05 - accuracy: 1.0000 - val_loss: 0.8744 - val_accuracy: 0.7143\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 1.3127e-04 - accuracy: 1.0000 - val_loss: 1.2057 - val_accuracy: 0.6939\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 2s 146ms/step - loss: 2.9082e-04 - accuracy: 1.0000 - val_loss: 1.3511 - val_accuracy: 0.6735\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 1.0142e-04 - accuracy: 1.0000 - val_loss: 5.3705 - val_accuracy: 0.5102\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 7.1901e-05 - accuracy: 1.0000 - val_loss: 5.3508 - val_accuracy: 0.5102\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 2s 150ms/step - loss: 3.0830e-04 - accuracy: 1.0000 - val_loss: 2.4571 - val_accuracy: 0.5442\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 3.0737e-05 - accuracy: 1.0000 - val_loss: 2.9264 - val_accuracy: 0.5102\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 2.4572e-05 - accuracy: 1.0000 - val_loss: 2.9236 - val_accuracy: 0.5170\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 2.7218e-05 - accuracy: 1.0000 - val_loss: 2.7367 - val_accuracy: 0.5170\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 2s 145ms/step - loss: 8.5623e-05 - accuracy: 1.0000 - val_loss: 2.1601 - val_accuracy: 0.5510\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 1.8959e-04 - accuracy: 1.0000 - val_loss: 1.6847 - val_accuracy: 0.5918\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 2s 145ms/step - loss: 2.8269e-05 - accuracy: 1.0000 - val_loss: 1.3543 - val_accuracy: 0.6122\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 2s 145ms/step - loss: 4.8682e-05 - accuracy: 1.0000 - val_loss: 1.3552 - val_accuracy: 0.6259\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 6.2402e-05 - accuracy: 1.0000 - val_loss: 1.0832 - val_accuracy: 0.6735\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 2.7112e-05 - accuracy: 1.0000 - val_loss: 1.3828 - val_accuracy: 0.6463\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 5.3428e-05 - accuracy: 1.0000 - val_loss: 1.1324 - val_accuracy: 0.6939\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 2.1107e-05 - accuracy: 1.0000 - val_loss: 0.8090 - val_accuracy: 0.7823\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 2.7951e-05 - accuracy: 1.0000 - val_loss: 0.6143 - val_accuracy: 0.8095\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 5.7074e-05 - accuracy: 1.0000 - val_loss: 0.3522 - val_accuracy: 0.8912\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 4.1562e-05 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 0.9320\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 1.2352e-04 - accuracy: 1.0000 - val_loss: 0.1328 - val_accuracy: 0.9592\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 2s 137ms/step - loss: 4.6544e-05 - accuracy: 1.0000 - val_loss: 0.3600 - val_accuracy: 0.8639\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 3.4999e-05 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9252\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 1.5831e-05 - accuracy: 1.0000 - val_loss: 0.1463 - val_accuracy: 0.9456\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 2s 147ms/step - loss: 2.5928e-05 - accuracy: 1.0000 - val_loss: 0.1221 - val_accuracy: 0.9524\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 1.5747e-05 - accuracy: 1.0000 - val_loss: 0.1003 - val_accuracy: 0.9592\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 3.4533e-05 - accuracy: 1.0000 - val_loss: 0.0870 - val_accuracy: 0.9728\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 2.1221e-05 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9728\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 2s 147ms/step - loss: 5.0066e-05 - accuracy: 1.0000 - val_loss: 0.0956 - val_accuracy: 0.9796\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 3.5777e-04 - accuracy: 1.0000 - val_loss: 0.2508 - val_accuracy: 0.9320\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 9.6080e-05 - accuracy: 1.0000 - val_loss: 2.9052 - val_accuracy: 0.5714\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 2.5774e-05 - accuracy: 1.0000 - val_loss: 2.0168 - val_accuracy: 0.6531\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 2s 145ms/step - loss: 3.5773e-05 - accuracy: 1.0000 - val_loss: 1.6143 - val_accuracy: 0.6803\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 2.6924e-05 - accuracy: 1.0000 - val_loss: 1.2177 - val_accuracy: 0.6939\n",
            "Epoch 127/200\n",
            "11/11 [==============================] - 2s 146ms/step - loss: 1.7359e-05 - accuracy: 1.0000 - val_loss: 0.9129 - val_accuracy: 0.7619\n",
            "Epoch 128/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 2.3344e-05 - accuracy: 1.0000 - val_loss: 0.7229 - val_accuracy: 0.7891\n",
            "Epoch 129/200\n",
            "11/11 [==============================] - 2s 146ms/step - loss: 3.6081e-05 - accuracy: 1.0000 - val_loss: 0.4063 - val_accuracy: 0.8776\n",
            "Epoch 130/200\n",
            "11/11 [==============================] - 2s 147ms/step - loss: 4.7268e-05 - accuracy: 1.0000 - val_loss: 0.3219 - val_accuracy: 0.8980\n",
            "Epoch 131/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 4.2176e-05 - accuracy: 1.0000 - val_loss: 0.3630 - val_accuracy: 0.8980\n",
            "Epoch 132/200\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 3.0112e-05 - accuracy: 1.0000 - val_loss: 0.3335 - val_accuracy: 0.8980\n",
            "Epoch 133/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 2.5115e-05 - accuracy: 1.0000 - val_loss: 0.2536 - val_accuracy: 0.9252\n",
            "Epoch 134/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 4.7332e-05 - accuracy: 1.0000 - val_loss: 0.1467 - val_accuracy: 0.9592\n",
            "Epoch 135/200\n",
            "11/11 [==============================] - 2s 137ms/step - loss: 3.6873e-05 - accuracy: 1.0000 - val_loss: 0.0989 - val_accuracy: 0.9864\n",
            "Epoch 136/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 1.5920e-05 - accuracy: 1.0000 - val_loss: 0.1002 - val_accuracy: 0.9796\n",
            "Epoch 137/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 3.4178e-05 - accuracy: 1.0000 - val_loss: 0.0926 - val_accuracy: 0.9864\n",
            "Epoch 138/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 6.4282e-05 - accuracy: 1.0000 - val_loss: 0.1177 - val_accuracy: 0.9796\n",
            "Epoch 139/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 6.0895e-05 - accuracy: 1.0000 - val_loss: 0.1388 - val_accuracy: 0.9592\n",
            "Epoch 140/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 3.8082e-05 - accuracy: 1.0000 - val_loss: 0.1503 - val_accuracy: 0.9524\n",
            "Epoch 141/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 4.6071e-05 - accuracy: 1.0000 - val_loss: 0.1126 - val_accuracy: 0.9728\n",
            "Epoch 142/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 1.3265e-05 - accuracy: 1.0000 - val_loss: 0.1236 - val_accuracy: 0.9660\n",
            "Epoch 143/200\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 2.6021e-05 - accuracy: 1.0000 - val_loss: 0.1519 - val_accuracy: 0.9524\n",
            "Epoch 144/200\n",
            "11/11 [==============================] - 2s 147ms/step - loss: 7.8718e-05 - accuracy: 1.0000 - val_loss: 0.1575 - val_accuracy: 0.9524\n",
            "Epoch 145/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 5.3919e-05 - accuracy: 1.0000 - val_loss: 0.1216 - val_accuracy: 0.9524\n",
            "Epoch 146/200\n",
            "11/11 [==============================] - 2s 145ms/step - loss: 9.6824e-06 - accuracy: 1.0000 - val_loss: 0.1389 - val_accuracy: 0.9456\n",
            "Epoch 147/200\n",
            "11/11 [==============================] - 2s 145ms/step - loss: 8.7210e-06 - accuracy: 1.0000 - val_loss: 0.1325 - val_accuracy: 0.9524\n",
            "Epoch 148/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 1.2558e-05 - accuracy: 1.0000 - val_loss: 0.1222 - val_accuracy: 0.9592\n",
            "Epoch 149/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 8.4280e-05 - accuracy: 1.0000 - val_loss: 0.1185 - val_accuracy: 0.9660\n",
            "Epoch 150/200\n",
            "11/11 [==============================] - 2s 137ms/step - loss: 5.1285e-05 - accuracy: 1.0000 - val_loss: 0.1568 - val_accuracy: 0.9592\n",
            "Epoch 151/200\n",
            "11/11 [==============================] - 1s 137ms/step - loss: 3.5235e-05 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 0.9660\n",
            "Epoch 152/200\n",
            "11/11 [==============================] - 2s 146ms/step - loss: 6.5402e-05 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 0.9592\n",
            "Epoch 153/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 4.1729e-05 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.9592\n",
            "Epoch 154/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 2.7850e-05 - accuracy: 1.0000 - val_loss: 0.1619 - val_accuracy: 0.9592\n",
            "Epoch 155/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 1.0542e-04 - accuracy: 1.0000 - val_loss: 0.1001 - val_accuracy: 0.9728\n",
            "Epoch 156/200\n",
            "11/11 [==============================] - 2s 146ms/step - loss: 1.7804e-05 - accuracy: 1.0000 - val_loss: 0.1139 - val_accuracy: 0.9524\n",
            "Epoch 157/200\n",
            "11/11 [==============================] - 2s 147ms/step - loss: 7.4786e-05 - accuracy: 1.0000 - val_loss: 0.3027 - val_accuracy: 0.9048\n",
            "Epoch 158/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 1.5821e-04 - accuracy: 1.0000 - val_loss: 0.2373 - val_accuracy: 0.9388\n",
            "Epoch 159/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 8.1007e-05 - accuracy: 1.0000 - val_loss: 0.1966 - val_accuracy: 0.9252\n",
            "Epoch 160/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 3.9150e-05 - accuracy: 1.0000 - val_loss: 0.1715 - val_accuracy: 0.9456\n",
            "Epoch 161/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 8.6115e-06 - accuracy: 1.0000 - val_loss: 0.1428 - val_accuracy: 0.9388\n",
            "Epoch 162/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 3.3500e-05 - accuracy: 1.0000 - val_loss: 0.1071 - val_accuracy: 0.9660\n",
            "Epoch 163/200\n",
            "11/11 [==============================] - 1s 138ms/step - loss: 1.0228e-05 - accuracy: 1.0000 - val_loss: 0.0901 - val_accuracy: 0.9728\n",
            "Epoch 164/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 3.8276e-05 - accuracy: 1.0000 - val_loss: 0.1015 - val_accuracy: 0.9592\n",
            "Epoch 165/200\n",
            "11/11 [==============================] - 2s 147ms/step - loss: 1.1691e-05 - accuracy: 1.0000 - val_loss: 0.0999 - val_accuracy: 0.9592\n",
            "Epoch 166/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 9.5233e-06 - accuracy: 1.0000 - val_loss: 0.0986 - val_accuracy: 0.9524\n",
            "Epoch 167/200\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 1.6279e-05 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 0.9728\n",
            "Epoch 168/200\n",
            "11/11 [==============================] - 2s 146ms/step - loss: 5.9030e-06 - accuracy: 1.0000 - val_loss: 0.0936 - val_accuracy: 0.9660\n",
            "Epoch 169/200\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 3.8715e-05 - accuracy: 1.0000 - val_loss: 0.0831 - val_accuracy: 0.9864\n",
            "Epoch 170/200\n",
            "11/11 [==============================] - 2s 145ms/step - loss: 2.0726e-05 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9796\n",
            "Epoch 171/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 6.2681e-05 - accuracy: 1.0000 - val_loss: 0.2816 - val_accuracy: 0.9048\n",
            "Epoch 172/200\n",
            "11/11 [==============================] - 2s 148ms/step - loss: 5.1570e-05 - accuracy: 1.0000 - val_loss: 0.3505 - val_accuracy: 0.8776\n",
            "Epoch 173/200\n",
            "11/11 [==============================] - 2s 147ms/step - loss: 3.3559e-05 - accuracy: 1.0000 - val_loss: 0.2078 - val_accuracy: 0.9252\n",
            "Epoch 174/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 1.1343e-05 - accuracy: 1.0000 - val_loss: 0.1429 - val_accuracy: 0.9524\n",
            "Epoch 175/200\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 1.5104e-05 - accuracy: 1.0000 - val_loss: 0.1384 - val_accuracy: 0.9524\n",
            "Epoch 176/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 2.3046e-05 - accuracy: 1.0000 - val_loss: 0.1257 - val_accuracy: 0.9660\n",
            "Epoch 177/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 3.3051e-05 - accuracy: 1.0000 - val_loss: 0.0833 - val_accuracy: 0.9728\n",
            "Epoch 178/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 9.4291e-05 - accuracy: 1.0000 - val_loss: 0.0940 - val_accuracy: 0.9660\n",
            "Epoch 179/200\n",
            "11/11 [==============================] - 2s 146ms/step - loss: 1.9481e-05 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.8980\n",
            "Epoch 180/200\n",
            "11/11 [==============================] - 2s 147ms/step - loss: 1.5519e-05 - accuracy: 1.0000 - val_loss: 0.1776 - val_accuracy: 0.9252\n",
            "Epoch 181/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 3.8905e-05 - accuracy: 1.0000 - val_loss: 0.1291 - val_accuracy: 0.9592\n",
            "Epoch 182/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 6.1819e-06 - accuracy: 1.0000 - val_loss: 0.1374 - val_accuracy: 0.9592\n",
            "Epoch 183/200\n",
            "11/11 [==============================] - 2s 146ms/step - loss: 1.2729e-05 - accuracy: 1.0000 - val_loss: 0.1440 - val_accuracy: 0.9660\n",
            "Epoch 184/200\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 7.7605e-05 - accuracy: 1.0000 - val_loss: 0.2044 - val_accuracy: 0.9252\n",
            "Epoch 185/200\n",
            "11/11 [==============================] - 2s 148ms/step - loss: 1.3107e-05 - accuracy: 1.0000 - val_loss: 0.4162 - val_accuracy: 0.8571\n",
            "Epoch 186/200\n",
            "11/11 [==============================] - 2s 149ms/step - loss: 1.1594e-05 - accuracy: 1.0000 - val_loss: 0.4755 - val_accuracy: 0.8299\n",
            "Epoch 187/200\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 5.5670e-06 - accuracy: 1.0000 - val_loss: 0.4286 - val_accuracy: 0.8571\n",
            "Epoch 188/200\n",
            "11/11 [==============================] - 2s 146ms/step - loss: 1.4488e-05 - accuracy: 1.0000 - val_loss: 0.4812 - val_accuracy: 0.8503\n",
            "Epoch 189/200\n",
            "11/11 [==============================] - 2s 145ms/step - loss: 8.5419e-06 - accuracy: 1.0000 - val_loss: 0.4064 - val_accuracy: 0.8912\n",
            "Epoch 190/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 1.0668e-05 - accuracy: 1.0000 - val_loss: 0.3272 - val_accuracy: 0.9184\n",
            "Epoch 191/200\n",
            "11/11 [==============================] - 2s 150ms/step - loss: 5.7591e-06 - accuracy: 1.0000 - val_loss: 0.2641 - val_accuracy: 0.9388\n",
            "Epoch 192/200\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 1.9504e-05 - accuracy: 1.0000 - val_loss: 0.2382 - val_accuracy: 0.9456\n",
            "Epoch 193/200\n",
            "11/11 [==============================] - 2s 148ms/step - loss: 3.0119e-05 - accuracy: 1.0000 - val_loss: 0.1966 - val_accuracy: 0.9660\n",
            "Epoch 194/200\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 9.7135e-06 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9524\n",
            "Epoch 195/200\n",
            "11/11 [==============================] - 2s 148ms/step - loss: 2.7200e-05 - accuracy: 1.0000 - val_loss: 0.1822 - val_accuracy: 0.9592\n",
            "Epoch 196/200\n",
            "11/11 [==============================] - 2s 150ms/step - loss: 1.3342e-05 - accuracy: 1.0000 - val_loss: 0.1494 - val_accuracy: 0.9524\n",
            "Epoch 197/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 4.7476e-05 - accuracy: 1.0000 - val_loss: 0.1227 - val_accuracy: 0.9660\n",
            "Epoch 198/200\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 1.3972e-05 - accuracy: 1.0000 - val_loss: 0.1225 - val_accuracy: 0.9728\n",
            "Epoch 199/200\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 5.9329e-06 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9660\n",
            "Epoch 200/200\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 7.9087e-06 - accuracy: 1.0000 - val_loss: 0.1428 - val_accuracy: 0.9660\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSTlOSUBWMpj"
      },
      "source": [
        "Y_test = yback(Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDVY6HbxMOlH",
        "outputId": "fc4945ec-64d8-4d7b-f537-6bf5a9a6dde2"
      },
      "source": [
        "# pred_test= model.predict_classes(X_test)\n",
        "pred_test = np.argmax(model.predict(X_test), axis=-1)\n",
        "\n",
        "data = {'y_true': Y_test,'y_predict': pred_test}  # este dado esta no formato de dicionario\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_true','y_predict'])\n",
        "\n",
        "\n",
        "confusion_matrix = pd.crosstab(df['y_true'], df['y_predict'], rownames=['Actual'], colnames=['Predict'])\n",
        "print(confusion_matrix)\n",
        "\n",
        "y_true = df['y_true']\n",
        "y_pred = df['y_predict']\n",
        "\n",
        "  \n",
        "METRICS=sklearn.metrics.classification_report(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predict   0   1\n",
            "Actual         \n",
            "0        71   1\n",
            "1         4  71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7pT2q7traXg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2152d19e-2bea-4a9d-b1a0-3df0e45b7bd2"
      },
      "source": [
        "print(METRICS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97        72\n",
            "           1       0.99      0.95      0.97        75\n",
            "\n",
            "    accuracy                           0.97       147\n",
            "   macro avg       0.97      0.97      0.97       147\n",
            "weighted avg       0.97      0.97      0.97       147\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElpxWbBnpgLX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "69c04b2a-bad9-47b8-d105-78eabd7e39e3"
      },
      "source": [
        "'''\n",
        "#X =np.array(df.copy())/255.0 \n",
        "X =np.array(df.copy())\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42)\n",
        "model = MLPClassifier(hidden_layer_sizes=(200,10), activation='tanh', solver='adam',random_state=1, max_iter=300).fit(X_train,y_train)  \n",
        "prediction = model.predict(X_test)  \n",
        "y =np.copy(y_test)\n",
        "data = {'y_true': y_test,'y_predict': prediction}  \n",
        "# este dado esta no formato de dicionario\n",
        "df = pd.DataFrame(data, columns=['y_true','y_predict'])\n",
        "confusion_matrix = pd.crosstab(df['y_true'], df['y_predict'], rownames=['Actual'], colnames=['Predict'])\n",
        "print(confusion_matrix)\n",
        "y_true = df['y_true']\n",
        "y_pred = df['y_predict']  \n",
        "METRICS=sklearn.metrics.classification_report(y_true, y_pred)\n",
        "print(METRICS)\n",
        "#X =np.array(df.copy())/255.0 X =np.array(df_all.copy())X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42)model = MLPClassifier(hidden_layer_sizes=(200,10), activation='tanh',                       solver='adam',random_state=1, max_iter=300).fit(X_train,y_train)  prediction = model.predict(X_test)  y =np.copy(y_test)data = {'y_true': y_test,'y_predict': prediction}  # este dado esta no formato de dicionariodf = pd.DataFrame(data, columns=['y_true','y_predict'])confusion_matrix = pd.crosstab(df['y_true'], df['y_predict'], rownames=['Actual'], colnames=['Predict'])print(confusion_matrix)y_true = df['y_true']y_pred = df['y_predict']\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n#X =np.array(df.copy())/255.0 \\nX =np.array(df.copy())\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42)\\nmodel = MLPClassifier(hidden_layer_sizes=(200,10), activation='tanh', solver='adam',random_state=1, max_iter=300).fit(X_train,y_train)  \\nprediction = model.predict(X_test)  \\ny =np.copy(y_test)\\ndata = {'y_true': y_test,'y_predict': prediction}  \\n# este dado esta no formato de dicionario\\ndf = pd.DataFrame(data, columns=['y_true','y_predict'])\\nconfusion_matrix = pd.crosstab(df['y_true'], df['y_predict'], rownames=['Actual'], colnames=['Predict'])\\nprint(confusion_matrix)\\ny_true = df['y_true']\\ny_pred = df['y_predict']  \\nMETRICS=sklearn.metrics.classification_report(y_true, y_pred)\\nprint(METRICS)\\n#X =np.array(df.copy())/255.0 X =np.array(df_all.copy())X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42)model = MLPClassifier(hidden_layer_sizes=(200,10), activation='tanh',                       solver='adam',random_state=1, max_iter=300).fit(X_train,y_train)  prediction = model.predict(X_test)  y =np.copy(y_test)data = {'y_true': y_test,'y_predict': prediction}  # este dado esta no formato de dicionariodf = pd.DataFrame(data, columns=['y_true','y_predict'])confusion_matrix = pd.crosstab(df['y_true'], df['y_predict'], rownames=['Actual'], colnames=['Predict'])print(confusion_matrix)y_true = df['y_true']y_pred = df['y_predict']\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iFNNrlWV9tH",
        "outputId": "b20c8f79-ae2c-4f2e-e94b-6e7342b3c16c"
      },
      "source": [
        "pred_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
              "       0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
              "       0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jv5I61yhPQmk",
        "outputId": "da77dbc9-4ad0-4e0f-96f1-3332c1b1c712"
      },
      "source": [
        "cont = 0; num =25\n",
        "img_graos = []\n",
        "Width_new = []\n",
        "img=ww[4] \n",
        "while( cont < num):\n",
        "  df=Segmenta(img)\n",
        "  df_ann =df.copy()\n",
        "  Width = df['Width']\n",
        "  del df_ann['Width']\n",
        "  result = np.array(df_ann)\n",
        "  result = result.reshape(-1, Img_Size, Img_Size, 1) / 255.0\n",
        "  #prediction = model.predict_classes(result)\n",
        "  prediction= np.argmax(model.predict(result), axis=-1)\n",
        "  loc_grao =[];k=0\n",
        "  for i in prediction:\n",
        "    if( i == 0):\n",
        "      img_graos.append(df.iloc[k,:])\n",
        "      Width_new.append(Width.iloc[k])\n",
        "      cont = cont + 1\n",
        "    k = k +1\n",
        "img_graos = pd.DataFrame(img_graos)\n",
        "print(img_graos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Width           0           1  ...         781         782         783\n",
            "2   139.0  136.973969  138.356705  ...  115.519432  119.076950  136.585159\n",
            "3   100.0  110.955200  113.359993  ...  118.467201  111.003189   67.027199\n",
            "5   115.0  165.761444  161.047333  ...  125.364380  113.110237  116.386154\n",
            "6   195.0  161.339355  159.899109  ...  145.053558  162.570831  171.153687\n",
            "7   188.0  114.520149  187.033478  ...  217.765961  210.626526  205.831131\n",
            "8   105.0    0.853333    0.017778  ...  180.657791  161.071121  150.680023\n",
            "10  199.0  158.101349  141.117599  ...  129.661438  145.410309  153.078949\n",
            "11  161.0  193.992432  178.079407  ...    1.081285    1.124764    1.000000\n",
            "12  152.0  139.393341  138.092102  ...   75.128807   65.021469   76.177971\n",
            "13  138.0  253.076431  252.600479  ...  175.817688  184.126862  190.608261\n",
            "14  157.0  107.179810  104.488586  ...  102.286064  120.939545  150.445007\n",
            "15  110.0  100.498833   47.269749  ...   39.987106   37.842976   30.538513\n",
            "16  121.0  126.248627  126.771255  ...  121.510345  125.786018  122.902740\n",
            "17  186.0  148.597992  139.822647  ...  202.011795  191.445374  174.306747\n",
            "19  183.0  174.973999  173.000931  ...  170.174484  170.805161  174.273346\n",
            "20  186.0  129.102448  129.298309  ...  181.271713  178.257614  174.276810\n",
            "22  183.0  113.596405  122.955780  ...  125.928192  127.467224  128.013260\n",
            "23  159.0  133.204254  140.186432  ...    1.000000    1.000000    1.383213\n",
            "24  128.0  114.678711  117.689453  ...  170.416016  169.656250  165.430664\n",
            "25  200.0  117.830795  120.249619  ...  171.332397  168.531616  161.836792\n",
            "26  184.0  112.214073  125.973053  ...   46.441868   49.552925   49.063789\n",
            "27  173.0  125.234283  131.431549  ...  147.989090  112.108826  116.423622\n",
            "28  182.0  132.260345  139.088776  ...    1.000000    1.000000    1.177515\n",
            "29  131.0  136.753510  144.110886  ...  148.673096  135.631546  136.877396\n",
            "30  197.0  112.060356  108.584572  ...  191.932037  198.677567  190.358643\n",
            "32  166.0  105.652641  112.496872  ...    1.000000    1.544491    1.670779\n",
            "33  113.0  176.773834  175.914230  ...  252.535507  249.675461  234.464264\n",
            "35  100.0  130.270386  119.516800  ...  167.307205  157.104004  142.555191\n",
            "36  195.0  175.820755  184.080292  ...  134.696365  112.295891  116.259720\n",
            "37  188.0  193.861008  193.255310  ...    1.000000    0.146220    0.263015\n",
            "38  123.0  118.375778  123.832718  ...  122.941643  123.577507  124.994659\n",
            "39  149.0  122.428497  115.741058  ...    0.592361    0.350750    1.411153\n",
            "40  152.0  208.389877  224.716766  ...  206.958435  202.137115  200.092773\n",
            "41  140.0  171.879990  171.160004  ...  126.320000  138.919998  141.399994\n",
            "46  127.0    1.466985    0.569347  ...  133.750885  136.532944  139.407654\n",
            "47  176.0  193.458160  188.632736  ...  209.913727  207.935455  207.607941\n",
            "48  111.0  128.889053  131.193573  ...  141.404755  146.935959  155.122314\n",
            "49  197.0  147.147476  146.218918  ...  236.744019  218.253845  209.359467\n",
            "\n",
            "[38 rows x 785 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LkA4vHp-f6_"
      },
      "source": [
        "Width=np.array(Width_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjRbWgmX_LFH",
        "outputId": "710926ee-0e2a-4a31-e6ca-a0bb45291dfd"
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_paper_fev_2021\n",
        "%cd marquesgabi_paper_fev_2021\n",
        "\n",
        "from Get_PSDArea_New import PSDArea\n",
        "from histogram_fev_2021 import PSD\n",
        "from GetBetterSegm import GetBetter"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'marquesgabi_paper_fev_2021'...\n",
            "remote: Enumerating objects: 692, done.\u001b[K\n",
            "remote: Counting objects: 100% (453/453), done.\u001b[K\n",
            "remote: Compressing objects: 100% (451/451), done.\u001b[K\n",
            "remote: Total 692 (delta 285), reused 0 (delta 0), pack-reused 239\u001b[K\n",
            "Receiving objects: 100% (692/692), 5.65 MiB | 10.91 MiB/s, done.\n",
            "Resolving deltas: 100% (422/422), done.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines/marquesgabi_paper_fev_2021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAG_I6FwCvFr",
        "outputId": "1df5d2f0-77d3-4224-9600-2942eef1755e"
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_out_2020\n",
        "#!git clone https://github.com/marquesgabi/Doutorado\n",
        "%cd marquesgabi_out_2020\n",
        "#%cd Doutorado\n",
        "#PSD_imageJ = 'Amostra7.csv' \n",
        "#PSD_new = pd.read_csv(PSD_imageJ,sep=';')\n",
        "#encoding='utf8'\n",
        "\n",
        "PSD_imageJ = 'Areas_ImageJ.csv'\n",
        "PSD_new = pd.read_csv(PSD_imageJ)\n",
        "print(PSD_new.head(3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'marquesgabi_out_2020'...\n",
            "remote: Enumerating objects: 146, done.\u001b[K\n",
            "remote: Counting objects: 100% (146/146), done.\u001b[K\n",
            "remote: Compressing objects: 100% (142/142), done.\u001b[K\n",
            "remote: Total 146 (delta 75), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (146/146), 1.00 MiB | 6.01 MiB/s, done.\n",
            "Resolving deltas: 100% (75/75), done.\n",
            "/content/marquesgabi_fev_2020/Doutorado/MarquesGabi_Routines/MarquesGabi_Routines/marquesgabi_paper_fev_2021/marquesgabi_out_2020\n",
            "   Juntas   Area\n",
            "0       1  2.001\n",
            "1       2  0.820\n",
            "2       3  1.270\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tEPjIBnv_xM",
        "outputId": "9c372d49-bd13-47a8-fbd4-f4d7bf5d8339"
      },
      "source": [
        "PSD_new.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(95, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_1WIM8w7poO"
      },
      "source": [
        "Area_All, Diameter_All=PSDArea(img_graos) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "PekBHQOT_6CP",
        "outputId": "425cf827-342d-4ccb-c65f-fc4e5ada82e4"
      },
      "source": [
        "img_graos.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Width</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "      <th>769</th>\n",
              "      <th>770</th>\n",
              "      <th>771</th>\n",
              "      <th>772</th>\n",
              "      <th>773</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>139.0</td>\n",
              "      <td>136.973969</td>\n",
              "      <td>138.356705</td>\n",
              "      <td>140.240402</td>\n",
              "      <td>141.522430</td>\n",
              "      <td>139.922058</td>\n",
              "      <td>153.007385</td>\n",
              "      <td>185.546600</td>\n",
              "      <td>195.575180</td>\n",
              "      <td>175.499664</td>\n",
              "      <td>141.768280</td>\n",
              "      <td>137.263443</td>\n",
              "      <td>149.849335</td>\n",
              "      <td>168.178131</td>\n",
              "      <td>169.162155</td>\n",
              "      <td>177.227783</td>\n",
              "      <td>177.001495</td>\n",
              "      <td>183.860962</td>\n",
              "      <td>187.628052</td>\n",
              "      <td>194.133514</td>\n",
              "      <td>189.988190</td>\n",
              "      <td>178.691055</td>\n",
              "      <td>184.833893</td>\n",
              "      <td>188.042480</td>\n",
              "      <td>186.204697</td>\n",
              "      <td>181.119400</td>\n",
              "      <td>182.360840</td>\n",
              "      <td>180.506378</td>\n",
              "      <td>176.510208</td>\n",
              "      <td>139.750320</td>\n",
              "      <td>140.676361</td>\n",
              "      <td>134.089600</td>\n",
              "      <td>144.987473</td>\n",
              "      <td>156.908234</td>\n",
              "      <td>140.523880</td>\n",
              "      <td>175.236053</td>\n",
              "      <td>183.820404</td>\n",
              "      <td>184.970901</td>\n",
              "      <td>191.503693</td>\n",
              "      <td>170.396408</td>\n",
              "      <td>...</td>\n",
              "      <td>115.542099</td>\n",
              "      <td>123.221809</td>\n",
              "      <td>111.708900</td>\n",
              "      <td>96.454529</td>\n",
              "      <td>92.979385</td>\n",
              "      <td>109.502243</td>\n",
              "      <td>114.418396</td>\n",
              "      <td>120.040680</td>\n",
              "      <td>123.395737</td>\n",
              "      <td>122.471443</td>\n",
              "      <td>123.172081</td>\n",
              "      <td>136.178253</td>\n",
              "      <td>136.825531</td>\n",
              "      <td>143.038147</td>\n",
              "      <td>151.990524</td>\n",
              "      <td>157.342224</td>\n",
              "      <td>163.103485</td>\n",
              "      <td>161.452866</td>\n",
              "      <td>150.390640</td>\n",
              "      <td>140.597900</td>\n",
              "      <td>147.748459</td>\n",
              "      <td>135.850433</td>\n",
              "      <td>115.279686</td>\n",
              "      <td>108.378189</td>\n",
              "      <td>107.755905</td>\n",
              "      <td>107.111435</td>\n",
              "      <td>100.343979</td>\n",
              "      <td>97.436874</td>\n",
              "      <td>98.631073</td>\n",
              "      <td>95.543236</td>\n",
              "      <td>96.356812</td>\n",
              "      <td>97.960342</td>\n",
              "      <td>105.445831</td>\n",
              "      <td>108.072296</td>\n",
              "      <td>110.001541</td>\n",
              "      <td>114.259506</td>\n",
              "      <td>113.523567</td>\n",
              "      <td>115.519432</td>\n",
              "      <td>119.076950</td>\n",
              "      <td>136.585159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100.0</td>\n",
              "      <td>110.955200</td>\n",
              "      <td>113.359993</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>114.244797</td>\n",
              "      <td>111.724800</td>\n",
              "      <td>113.990395</td>\n",
              "      <td>124.809601</td>\n",
              "      <td>130.895996</td>\n",
              "      <td>125.927994</td>\n",
              "      <td>119.798401</td>\n",
              "      <td>115.559998</td>\n",
              "      <td>103.888000</td>\n",
              "      <td>98.552002</td>\n",
              "      <td>96.433601</td>\n",
              "      <td>92.851204</td>\n",
              "      <td>91.156792</td>\n",
              "      <td>89.332794</td>\n",
              "      <td>88.054398</td>\n",
              "      <td>87.056000</td>\n",
              "      <td>86.985603</td>\n",
              "      <td>87.776001</td>\n",
              "      <td>85.913597</td>\n",
              "      <td>86.201607</td>\n",
              "      <td>90.820801</td>\n",
              "      <td>94.006401</td>\n",
              "      <td>95.100800</td>\n",
              "      <td>97.798401</td>\n",
              "      <td>102.580795</td>\n",
              "      <td>107.636803</td>\n",
              "      <td>111.806396</td>\n",
              "      <td>114.075195</td>\n",
              "      <td>113.590401</td>\n",
              "      <td>112.835197</td>\n",
              "      <td>114.161598</td>\n",
              "      <td>117.107201</td>\n",
              "      <td>116.431999</td>\n",
              "      <td>110.673607</td>\n",
              "      <td>105.614403</td>\n",
              "      <td>100.880005</td>\n",
              "      <td>...</td>\n",
              "      <td>160.774414</td>\n",
              "      <td>162.288010</td>\n",
              "      <td>157.214386</td>\n",
              "      <td>145.235199</td>\n",
              "      <td>128.025604</td>\n",
              "      <td>100.921608</td>\n",
              "      <td>110.177597</td>\n",
              "      <td>119.251190</td>\n",
              "      <td>124.518402</td>\n",
              "      <td>124.950401</td>\n",
              "      <td>116.406387</td>\n",
              "      <td>103.521599</td>\n",
              "      <td>156.550385</td>\n",
              "      <td>159.521606</td>\n",
              "      <td>155.755203</td>\n",
              "      <td>156.870407</td>\n",
              "      <td>151.446396</td>\n",
              "      <td>154.412781</td>\n",
              "      <td>159.481613</td>\n",
              "      <td>167.334412</td>\n",
              "      <td>173.203201</td>\n",
              "      <td>169.713608</td>\n",
              "      <td>159.827209</td>\n",
              "      <td>150.659195</td>\n",
              "      <td>148.395203</td>\n",
              "      <td>151.158401</td>\n",
              "      <td>152.935989</td>\n",
              "      <td>155.686401</td>\n",
              "      <td>164.078400</td>\n",
              "      <td>167.611206</td>\n",
              "      <td>169.478394</td>\n",
              "      <td>160.392014</td>\n",
              "      <td>134.675201</td>\n",
              "      <td>92.367996</td>\n",
              "      <td>99.307205</td>\n",
              "      <td>110.937599</td>\n",
              "      <td>117.140793</td>\n",
              "      <td>118.467201</td>\n",
              "      <td>111.003189</td>\n",
              "      <td>67.027199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>115.0</td>\n",
              "      <td>165.761444</td>\n",
              "      <td>161.047333</td>\n",
              "      <td>154.624786</td>\n",
              "      <td>149.056549</td>\n",
              "      <td>148.639236</td>\n",
              "      <td>151.272720</td>\n",
              "      <td>156.898209</td>\n",
              "      <td>159.159241</td>\n",
              "      <td>164.594788</td>\n",
              "      <td>170.752640</td>\n",
              "      <td>174.185715</td>\n",
              "      <td>175.291046</td>\n",
              "      <td>173.170578</td>\n",
              "      <td>175.408310</td>\n",
              "      <td>182.138199</td>\n",
              "      <td>188.021622</td>\n",
              "      <td>191.981918</td>\n",
              "      <td>204.781769</td>\n",
              "      <td>232.847412</td>\n",
              "      <td>250.652328</td>\n",
              "      <td>251.746521</td>\n",
              "      <td>244.687622</td>\n",
              "      <td>243.893295</td>\n",
              "      <td>242.523163</td>\n",
              "      <td>215.452240</td>\n",
              "      <td>145.908035</td>\n",
              "      <td>124.181313</td>\n",
              "      <td>129.907593</td>\n",
              "      <td>175.133682</td>\n",
              "      <td>170.076889</td>\n",
              "      <td>164.734131</td>\n",
              "      <td>159.592056</td>\n",
              "      <td>158.394852</td>\n",
              "      <td>159.161865</td>\n",
              "      <td>160.458130</td>\n",
              "      <td>163.412994</td>\n",
              "      <td>167.665924</td>\n",
              "      <td>167.894440</td>\n",
              "      <td>165.453613</td>\n",
              "      <td>...</td>\n",
              "      <td>135.442871</td>\n",
              "      <td>134.057007</td>\n",
              "      <td>129.782379</td>\n",
              "      <td>132.868652</td>\n",
              "      <td>135.261765</td>\n",
              "      <td>136.081421</td>\n",
              "      <td>137.662369</td>\n",
              "      <td>136.560516</td>\n",
              "      <td>132.491486</td>\n",
              "      <td>128.343430</td>\n",
              "      <td>118.667740</td>\n",
              "      <td>113.804825</td>\n",
              "      <td>122.590698</td>\n",
              "      <td>128.726807</td>\n",
              "      <td>144.221375</td>\n",
              "      <td>156.921432</td>\n",
              "      <td>160.923248</td>\n",
              "      <td>156.760666</td>\n",
              "      <td>122.666382</td>\n",
              "      <td>66.817612</td>\n",
              "      <td>126.247253</td>\n",
              "      <td>136.542908</td>\n",
              "      <td>135.988647</td>\n",
              "      <td>136.633484</td>\n",
              "      <td>135.274185</td>\n",
              "      <td>135.793640</td>\n",
              "      <td>136.947510</td>\n",
              "      <td>136.618607</td>\n",
              "      <td>134.167252</td>\n",
              "      <td>129.811874</td>\n",
              "      <td>130.448837</td>\n",
              "      <td>138.882538</td>\n",
              "      <td>141.763855</td>\n",
              "      <td>142.368454</td>\n",
              "      <td>142.086884</td>\n",
              "      <td>137.901459</td>\n",
              "      <td>132.499207</td>\n",
              "      <td>125.364380</td>\n",
              "      <td>113.110237</td>\n",
              "      <td>116.386154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>195.0</td>\n",
              "      <td>161.339355</td>\n",
              "      <td>159.899109</td>\n",
              "      <td>162.395569</td>\n",
              "      <td>159.002899</td>\n",
              "      <td>147.562637</td>\n",
              "      <td>138.625626</td>\n",
              "      <td>139.815948</td>\n",
              "      <td>156.050049</td>\n",
              "      <td>188.650497</td>\n",
              "      <td>191.926651</td>\n",
              "      <td>188.229828</td>\n",
              "      <td>181.237656</td>\n",
              "      <td>175.427261</td>\n",
              "      <td>170.332764</td>\n",
              "      <td>164.716599</td>\n",
              "      <td>168.373550</td>\n",
              "      <td>174.612366</td>\n",
              "      <td>173.128647</td>\n",
              "      <td>174.600906</td>\n",
              "      <td>182.183624</td>\n",
              "      <td>190.571030</td>\n",
              "      <td>189.523102</td>\n",
              "      <td>174.667084</td>\n",
              "      <td>150.468994</td>\n",
              "      <td>151.554169</td>\n",
              "      <td>216.461304</td>\n",
              "      <td>224.926758</td>\n",
              "      <td>232.759460</td>\n",
              "      <td>144.413239</td>\n",
              "      <td>145.741669</td>\n",
              "      <td>146.908691</td>\n",
              "      <td>146.188187</td>\n",
              "      <td>138.518646</td>\n",
              "      <td>134.661758</td>\n",
              "      <td>137.641693</td>\n",
              "      <td>158.585754</td>\n",
              "      <td>190.516418</td>\n",
              "      <td>197.039261</td>\n",
              "      <td>203.870758</td>\n",
              "      <td>...</td>\n",
              "      <td>154.652069</td>\n",
              "      <td>150.097488</td>\n",
              "      <td>152.055588</td>\n",
              "      <td>154.936478</td>\n",
              "      <td>153.976273</td>\n",
              "      <td>139.072281</td>\n",
              "      <td>110.787491</td>\n",
              "      <td>199.448166</td>\n",
              "      <td>139.184982</td>\n",
              "      <td>124.250092</td>\n",
              "      <td>142.341827</td>\n",
              "      <td>158.741150</td>\n",
              "      <td>67.431068</td>\n",
              "      <td>80.733948</td>\n",
              "      <td>116.677391</td>\n",
              "      <td>124.390518</td>\n",
              "      <td>122.352997</td>\n",
              "      <td>117.966560</td>\n",
              "      <td>107.928398</td>\n",
              "      <td>95.078537</td>\n",
              "      <td>124.101372</td>\n",
              "      <td>174.971649</td>\n",
              "      <td>180.724869</td>\n",
              "      <td>156.538040</td>\n",
              "      <td>84.925194</td>\n",
              "      <td>92.440453</td>\n",
              "      <td>144.962936</td>\n",
              "      <td>143.833099</td>\n",
              "      <td>150.546112</td>\n",
              "      <td>160.690399</td>\n",
              "      <td>160.352646</td>\n",
              "      <td>154.269669</td>\n",
              "      <td>140.109283</td>\n",
              "      <td>124.492920</td>\n",
              "      <td>102.936073</td>\n",
              "      <td>157.828125</td>\n",
              "      <td>130.510696</td>\n",
              "      <td>145.053558</td>\n",
              "      <td>162.570831</td>\n",
              "      <td>171.153687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>188.0</td>\n",
              "      <td>114.520149</td>\n",
              "      <td>187.033478</td>\n",
              "      <td>241.153015</td>\n",
              "      <td>226.943863</td>\n",
              "      <td>216.986404</td>\n",
              "      <td>224.195541</td>\n",
              "      <td>229.019012</td>\n",
              "      <td>233.362152</td>\n",
              "      <td>237.185150</td>\n",
              "      <td>236.657745</td>\n",
              "      <td>238.249878</td>\n",
              "      <td>242.444077</td>\n",
              "      <td>250.900391</td>\n",
              "      <td>251.854233</td>\n",
              "      <td>149.060196</td>\n",
              "      <td>117.754181</td>\n",
              "      <td>108.774567</td>\n",
              "      <td>128.033035</td>\n",
              "      <td>165.541412</td>\n",
              "      <td>173.653229</td>\n",
              "      <td>167.895874</td>\n",
              "      <td>164.665909</td>\n",
              "      <td>164.086456</td>\n",
              "      <td>185.005432</td>\n",
              "      <td>208.883209</td>\n",
              "      <td>226.943405</td>\n",
              "      <td>229.921204</td>\n",
              "      <td>207.825256</td>\n",
              "      <td>117.750107</td>\n",
              "      <td>148.761887</td>\n",
              "      <td>201.745575</td>\n",
              "      <td>212.464905</td>\n",
              "      <td>211.382080</td>\n",
              "      <td>221.127197</td>\n",
              "      <td>231.864624</td>\n",
              "      <td>239.641464</td>\n",
              "      <td>251.866913</td>\n",
              "      <td>252.454956</td>\n",
              "      <td>251.559082</td>\n",
              "      <td>...</td>\n",
              "      <td>101.081482</td>\n",
              "      <td>113.776367</td>\n",
              "      <td>120.261658</td>\n",
              "      <td>131.786331</td>\n",
              "      <td>136.112701</td>\n",
              "      <td>130.734268</td>\n",
              "      <td>218.665894</td>\n",
              "      <td>214.209137</td>\n",
              "      <td>182.173828</td>\n",
              "      <td>193.047516</td>\n",
              "      <td>199.848801</td>\n",
              "      <td>200.383438</td>\n",
              "      <td>138.475784</td>\n",
              "      <td>147.454498</td>\n",
              "      <td>153.243088</td>\n",
              "      <td>147.821182</td>\n",
              "      <td>141.390213</td>\n",
              "      <td>142.990936</td>\n",
              "      <td>136.820740</td>\n",
              "      <td>129.784515</td>\n",
              "      <td>132.555923</td>\n",
              "      <td>132.828873</td>\n",
              "      <td>99.782257</td>\n",
              "      <td>58.961517</td>\n",
              "      <td>80.549118</td>\n",
              "      <td>100.369850</td>\n",
              "      <td>126.341782</td>\n",
              "      <td>133.871429</td>\n",
              "      <td>135.216370</td>\n",
              "      <td>144.537796</td>\n",
              "      <td>162.439560</td>\n",
              "      <td>139.119965</td>\n",
              "      <td>147.101837</td>\n",
              "      <td>157.630585</td>\n",
              "      <td>132.515610</td>\n",
              "      <td>218.523300</td>\n",
              "      <td>227.712524</td>\n",
              "      <td>217.765961</td>\n",
              "      <td>210.626526</td>\n",
              "      <td>205.831131</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Width           0           1  ...         781         782         783\n",
              "2  139.0  136.973969  138.356705  ...  115.519432  119.076950  136.585159\n",
              "3  100.0  110.955200  113.359993  ...  118.467201  111.003189   67.027199\n",
              "5  115.0  165.761444  161.047333  ...  125.364380  113.110237  116.386154\n",
              "6  195.0  161.339355  159.899109  ...  145.053558  162.570831  171.153687\n",
              "7  188.0  114.520149  187.033478  ...  217.765961  210.626526  205.831131\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "VaZPe_AxNBK9",
        "outputId": "0c7976f6-907e-4953-d538-b75ddddafb62"
      },
      "source": [
        "PSD_new.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Juntas</th>\n",
              "      <th>Area</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2.001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1.270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1.162</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Juntas   Area\n",
              "0       1  2.001\n",
              "1       2  0.820\n",
              "2       3  1.270\n",
              "3       4  0.958\n",
              "4       5  1.162"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vmhG2LgCabC"
      },
      "source": [
        "#lost_value = float(PSD_new.columns[1])\n",
        "\n",
        "# Area = np.array(PSD_new.iloc[:,1])\n",
        "Area = PSD_new['Area'].values\n",
        "# Area = np.concatenate( (Area, [lost_value] ) )\n",
        "# Area = np.concatenate( (Area, [lost_value] ) )\n",
        "diam_teste = []\n",
        "for A in Area:\n",
        "  diam_teste.append((4*A/np.pi)**0.5) \n",
        "\n",
        "Diam1 = [ (4*A/np.pi)**0.5 for A in Area]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aUb2_-jsY1Z",
        "outputId": "8b16fa5e-885f-41f1-b951-03cf56e8755b"
      },
      "source": [
        "PSD_new.iloc[:,1].values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.001, 0.82 , 1.27 , 0.958, 1.162, 2.014, 1.078, 1.234, 1.262,\n",
              "       1.347, 1.313, 2.449, 1.445, 1.209, 3.564, 1.59 , 0.891, 1.329,\n",
              "       1.403, 0.626, 1.65 , 1.551, 2.118, 1.194, 1.113, 1.072, 1.042,\n",
              "       0.725, 4.218, 0.881, 1.608, 0.446, 0.582, 1.282, 1.484, 1.246,\n",
              "       1.323, 1.21 , 2.013, 1.358, 1.579, 1.223, 0.96 , 0.718, 0.707,\n",
              "       0.992, 1.142, 1.287, 0.599, 0.664, 2.119, 0.926, 0.889, 0.929,\n",
              "       1.579, 1.888, 0.481, 1.695, 0.871, 1.262, 0.471, 1.493, 1.461,\n",
              "       1.326, 1.301, 0.982, 0.705, 1.819, 1.437, 1.049, 2.014, 1.276,\n",
              "       1.589, 1.412, 1.08 , 1.037, 1.672, 1.224, 1.403, 0.724, 1.736,\n",
              "       1.601, 1.432, 0.449, 1.245, 1.011, 2.151, 0.986, 0.981, 0.658,\n",
              "       1.064, 1.341, 1.044, 1.337, 1.341])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J705kDqsE8f",
        "outputId": "d90b1603-73a4-46b5-b90b-2bb4d3b80c27"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(490, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "mK1GBUHWiIr4",
        "outputId": "313ad5c3-0ca1-473d-d3fe-8351b065304f"
      },
      "source": [
        "Freq = [19.12043703, 29.22484843, 19.35872174, 20.82190224, 11.47409056, 0.]\n",
        "\n",
        "\n",
        "Freq2 = [16.93792791, 31.38008965, 24.93810752, 18.56158392, 6.233810752, 0.4]\n",
        "Freq3 = [22.22489, 30.15078, 25.10463, 19.30926, 2.810434, 0.]\n",
        "barWidth = 0.25\n",
        "\n",
        "br1 = range(len(Freq))\n",
        "# Set position of bar on X axis\n",
        "br2 = [x + barWidth for x in br1]\n",
        "br3 = [x + barWidth for x in br2]\n",
        "labels = [0.8, 1.0, 1.2, 1.4, 1.6, 1.8]\n",
        "\n",
        "xx=[]\n",
        "for a in labels:\n",
        "  xx.append(str(a))\n",
        "plt.bar(br1, Freq , color=\"green\", align=\"center\", width=0.3, tick_label= xx) \n",
        "plt.bar(br2, Freq2 , color=\"red\", align=\"center\", width=0.3, tick_label= xx)\n",
        "plt.bar(br3, Freq3 , color=\"blue\", align=\"center\", width=0.3, tick_label= xx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 6 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfk_fNXGDK5_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "96c9965d-e73f-40b3-e2b0-1f21e912356b"
      },
      "source": [
        " wt1 = np.ones(len(Diam1)) / len(Diam1)*100\n",
        " wt2 = np.ones(len(Diameter_All)) / len(Diameter_All)*100\n",
        " X = pd.DataFrame([Diam1,Diameter_All])\n",
        " wts = pd.DataFrame([wt1,wt2])\n",
        "plt.hist(X,weights=wts)\n",
        "plt.legend(['Image J','CNN'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f9912c349d0>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nGDbBEeiUij",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "5887f988-3bb3-4f7c-9d3c-e3f20f0d6cd6"
      },
      "source": [
        "# plt.hist(x, bins=bins, density=True, histtype='step', cumulative=-1,label='Reversed emp.')\n",
        "plt.hist(X, density=True, histtype='step', cumulative=True,label='Reversed emp.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.07368421, 0.2       , 0.41052632, 0.75789474, 0.88421053,\n",
              "         0.96842105, 0.97894737, 0.97894737, 0.98947368, 1.        ],\n",
              "        [0.07894737, 0.26315789, 0.42105263, 0.57894737, 0.65789474,\n",
              "         0.89473684, 1.        , 1.        , 1.        , 1.        ]]),\n",
              " array([0.75356807, 0.90995518, 1.06634229, 1.22272941, 1.37911652,\n",
              "        1.53550363, 1.69189074, 1.84827785, 2.00466497, 2.16105208,\n",
              "        2.31743919]),\n",
              " <a list of 2 Lists of Patches objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xENlBUUxfTu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "1beb63a7-ad51-4b91-e6e2-5bb8bef1dee3"
      },
      "source": [
        "Obj = plt.hist(X, density=True, histtype='step', cumulative=True,label='Reversed emp.')\n",
        "Y1, Y2 = Obj[0]\n",
        "Rsquared = r2_score(Y1, Y2)\n",
        "print('r_squared =',Rsquared)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r_squared = 0.9190695628895944\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2XboMiFbkaa"
      },
      "source": [
        "acc_train = r.history['accuracy'][-1]\n",
        "acc_test = r.history['val_accuracy'][-1]\n",
        "loss_train = r.history['loss'][-1]\n",
        "loss_test = r.history['val_loss'][-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euTd_-CYN1v0"
      },
      "source": [
        "df = pd.DataFrame({'N1':N1, 'N2':N2,'R^2':Rsquared,\n",
        "                   'acc train':acc_train,'acc test':acc_test,\n",
        "                   'loss train':loss_train,'loss test':loss_test,\n",
        "                   'Details':Description},\n",
        "                  index= [0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KukfpGTTKlj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "4a76256b-69e9-411c-8058-85b22f8fe7cf"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>N1</th>\n",
              "      <th>N2</th>\n",
              "      <th>R^2</th>\n",
              "      <th>acc train</th>\n",
              "      <th>acc test</th>\n",
              "      <th>loss train</th>\n",
              "      <th>loss test</th>\n",
              "      <th>Details</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>0.91907</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.965986</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.142768</td>\n",
              "      <td>3 layers of Convolution: 64, 128, 256</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   N1  N2  ...  loss test                                 Details\n",
              "0  20  20  ...   0.142768  3 layers of Convolution: 64, 128, 256 \n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZHa1j4HT9Dq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "5e53aec5-b09c-41c5-a41e-843c273473b1"
      },
      "source": [
        "counts, bins, bars = plt.hist(X,weights=wts)\n",
        "print(bars)\n",
        "print(bins)\n",
        "print(counts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<a list of 2 Lists of Patches objects>\n",
            "[0.75356807 0.90995518 1.06634229 1.22272941 1.37911652 1.53550363\n",
            " 1.69189074 1.84827785 2.00466497 2.16105208 2.31743919]\n",
            "[[ 7.36842105 12.63157895 21.05263158 34.73684211 12.63157895  8.42105263\n",
            "   1.05263158  0.          1.05263158  1.05263158]\n",
            " [ 7.89473684 18.42105263 15.78947368 15.78947368  7.89473684 23.68421053\n",
            "  10.52631579  0.          0.          0.        ]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o_vDGeWUwIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19c1bcf5-bdfd-4598-9791-52a05aa0f972"
      },
      "source": [
        "print(counts.sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200.0000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcH52-6iJQ8t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "44fd8d47-b799-4448-c94b-b025595bab0f"
      },
      "source": [
        "\n",
        "plt.hist([Diam1,Diameter_All])\n",
        "plt.legend(['Image J','CNN'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f991c00c1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r11AxFK_JIii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "269b6816-407f-44a7-8fc0-e6ee345370fa"
      },
      "source": [
        "[Diam1,Diameter_All]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1.59616801403081,\n",
              "  1.0217907939900581,\n",
              "  1.2716187407449044,\n",
              "  1.104429030701514,\n",
              "  1.2163487785097904,\n",
              "  1.6013445735058454,\n",
              "  1.1715597420637607,\n",
              "  1.2534662333717612,\n",
              "  1.2676073151634049,\n",
              "  1.309600575274104,\n",
              "  1.292966945531582,\n",
              "  1.7658322811231006,\n",
              "  1.3564037533648712,\n",
              "  1.2407040781688483,\n",
              "  2.130217298173151,\n",
              "  1.4228319915327,\n",
              "  1.0651086490865755,\n",
              "  1.3008210311003705,\n",
              "  1.336545951796433,\n",
              "  0.8927754224911278,\n",
              "  1.4494292838262302,\n",
              "  1.4052738287907582,\n",
              "  1.6421697097891788,\n",
              "  1.2329833804288621,\n",
              "  1.19042665178928,\n",
              "  1.1682948223612457,\n",
              "  1.1518314137121108,\n",
              "  0.9607802401865855,\n",
              "  2.317439190074449,\n",
              "  1.0591147430338594,\n",
              "  1.4308630919602832,\n",
              "  0.7535680705496237,\n",
              "  0.8608283307581511,\n",
              "  1.2776122636975893,\n",
              "  1.3745862957220916,\n",
              "  1.259546137598783,\n",
              "  1.2978813187979172,\n",
              "  1.2412170838050638,\n",
              "  1.6009469708743893,\n",
              "  1.3149369953539032,\n",
              "  1.417901703622935,\n",
              "  1.2478669653497139,\n",
              "  1.1055812783082735,\n",
              "  0.9561307405997607,\n",
              "  0.9487783503683882,\n",
              "  1.1238565871041026,\n",
              "  1.2058356273089446,\n",
              "  1.2801012827406097,\n",
              "  0.8733100751144249,\n",
              "  0.9194732501297403,\n",
              "  1.6425573339441792,\n",
              "  1.085826790250066,\n",
              "  1.0639125693728595,\n",
              "  1.0875842666474016,\n",
              "  1.417901703622935,\n",
              "  1.550443891425932,\n",
              "  0.7825779328716171,\n",
              "  1.4690612745308145,\n",
              "  1.053086721720641,\n",
              "  1.2676073151634049,\n",
              "  0.7744003006005755,\n",
              "  1.3787482149724068,\n",
              "  1.363892581861956,\n",
              "  1.299352006316543,\n",
              "  1.2870449283923413,\n",
              "  1.11817763925502,\n",
              "  0.9474354220939228,\n",
              "  1.5218484589055707,\n",
              "  1.3526437911676632,\n",
              "  1.1556938532445284,\n",
              "  1.6013445735058454,\n",
              "  1.274619025074578,\n",
              "  1.422384489715834,\n",
              "  1.3408259533459403,\n",
              "  1.172646028567008,\n",
              "  1.1490645795125545,\n",
              "  1.459060149136146,\n",
              "  1.2483770274864237,\n",
              "  1.336545951796433,\n",
              "  0.9601174044814821,\n",
              "  1.4867225193896279,\n",
              "  1.4277452542806772,\n",
              "  1.35028849808504,\n",
              "  0.7560982446653928,\n",
              "  1.259040600296622,\n",
              "  1.13456827900627,\n",
              "  1.6549133695530214,\n",
              "  1.1204526724091788,\n",
              "  1.1176081573544434,\n",
              "  0.9153095762832032,\n",
              "  1.1639273497938836,\n",
              "  1.3066806149514323,\n",
              "  1.1529362882239027,\n",
              "  1.3047303442899274,\n",
              "  1.3066806149514323],\n",
              " [1.205090324956529,\n",
              "  0.8384260204079336,\n",
              "  1.1036708136496782,\n",
              "  1.81927989482726,\n",
              "  1.7242922245771728,\n",
              "  0.8618635137489332,\n",
              "  1.6381506765928395,\n",
              "  1.3291409708320387,\n",
              "  1.2619913149894948,\n",
              "  1.1327349037843122,\n",
              "  1.371683242704246,\n",
              "  1.0018636781609687,\n",
              "  0.9946293142898064,\n",
              "  1.6780783420626535,\n",
              "  1.6191059300953938,\n",
              "  1.6639681235610437,\n",
              "  1.5988409771648218,\n",
              "  1.323833206197312,\n",
              "  1.1125946815762238,\n",
              "  1.7316954169864684,\n",
              "  1.6014145527921897,\n",
              "  1.4624811677158458,\n",
              "  1.5089327612097767,\n",
              "  1.0292291406201666,\n",
              "  1.7623748405458368,\n",
              "  1.3605947245338244,\n",
              "  0.9500422141619796,\n",
              "  0.7769480733353719,\n",
              "  1.659652744526249,\n",
              "  1.591449659924093,\n",
              "  0.9919493381657625,\n",
              "  1.212374725711592,\n",
              "  1.3023430903286297,\n",
              "  1.1623604217008505,\n",
              "  1.0559152072936366,\n",
              "  1.4837825087667764,\n",
              "  0.9635840629674033,\n",
              "  1.5791898473741315]]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xS7NSM92s_8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "f5fff719-b6ac-492d-db55-65a3675d5a19"
      },
      "source": [
        " bins_list = [0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0]\n",
        " wt1 = np.ones(len(Diam1)) / len(Diam1)*100\n",
        " wt2 = np.ones(len(Diameter_All)) / len(Diameter_All)*100\n",
        " X = pd.DataFrame([Diam1,Diameter_All])\n",
        " wts = pd.DataFrame([wt1,wt2])\n",
        "plt.hist(X,weights=wts,bins = bins_list)\n",
        "plt.legend(['Image J','CNN'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f99187e7c10>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD80rFZs37Wm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "e763e7fb-445f-4f4f-dbbe-6d292e038f9a"
      },
      "source": [
        "yy = plt.hist(X,weights=wts,bins = bins_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPEUlEQVR4nO3df4xlZX3H8feny1JsQcDulGz50bHWX6QpCx2RVmMQawX8A0xMU9oiNTRrWzHYmIYtSSv2R4JJlaaxtVmEsjZWaxQLFbUlSkuMih1wWRa2FsTVQld2/I02sVn89o97No7DzN4798fceYb3K7mZc57znHO/T2bz2WfOPefcVBWSpPb8yLQLkCQNxwCXpEYZ4JLUKANckhplgEtSo45ayzfbsmVLzc7OruVbSlLz7r777q9W1czS9jUN8NnZWebn59fyLSWpeUm+tFy7p1AkqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRa3onpja22R23jf2Y+6995diPKW0UzsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSo/oGeJJjknw2yb1J7k/ylq79piRfTLK7e22bfLmSpMMGuQ78e8B5VfWdJJuBTyb5aLftD6rqA5MrT5K0kr4BXlUFfKdb3dy9apJFSZL6G+gceJJNSXYDB4Hbq+qubtOfJ9mT5LokP7rCvtuTzCeZX1hYGFPZkqSBAryqnqiqbcApwNlJfg74Q+B5wAuAZwBXrbDvzqqaq6q5mZknfamyJGlIq7oKpaq+CdwBnF9VB6rne8DfAWdPokBJ0vIGuQplJskJ3fLTgJcD/5lka9cW4GJg7yQLlST9sEGuQtkK7EqyiV7gv7+qPpzkE0lmgAC7gd+ZYJ2SpCUGuQplD3DmMu3nTaQiSdJAvBNTkhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJatQg30p/TJLPJrk3yf1J3tK1PzPJXUkeSvKPSY6efLmSpMMGmYF/Dzivqs4AtgHnJzkHeCtwXVX9LPAN4PLJlSlJWqpvgFfPd7rVzd2rgPOAD3Ttu4CLJ1KhJGlZA50DT7IpyW7gIHA78AXgm1V1qOvyCHDyCvtuTzKfZH5hYWEcNUuSGDDAq+qJqtoGnAKcDTxv0Deoqp1VNVdVczMzM0OWKUlaalVXoVTVN4E7gF8ETkhyVLfpFODRMdcmSTqCQa5CmUlyQrf8NODlwD56Qf7qrttlwC2TKlKS9GRH9e/CVmBXkk30Av/9VfXhJA8A70vyZ8DngBsmWKckaYm+AV5Ve4Azl2l/mN75cEnSFHgnpiQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktSoQb6V/tQkdyR5IMn9Sa7s2q9J8miS3d3rwsmXK0k6bJBvpT8EvKmq7klyHHB3ktu7bddV1V9MrjxJ0koG+Vb6A8CBbvnxJPuAkyddmCTpyFZ1DjzJLHAmcFfXdEWSPUluTHLiCvtsTzKfZH5hYWGkYiVJPzBwgCc5Fvgg8Maq+jbwTuBZwDZ6M/S3LbdfVe2sqrmqmpuZmRlDyZIkGDDAk2ymF97vqaqbAarqsap6oqq+D1wPnD25MiVJSw1yFUqAG4B9VfX2Re1bF3V7FbB3/OVJklYyyFUoLwIuBe5Lsrtruxq4JMk2oID9wOsmUqEkaVmDXIXySSDLbPrI+Mt5apndcdvYj7n/2leO/ZiS1ifvxJSkRhngktSoQc6BS9LKrjl+Asf81viPuQE5A5ekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUTyPU+uaT7qQVOQOXpEYZ4JLUqEG+lf7UJHckeSDJ/Umu7NqfkeT2JA92P0+cfLmSpMMGmYEfAt5UVacD5wCvT3I6sAP4eFU9G/h4ty5JWiN9A7yqDlTVPd3y48A+4GTgImBX120XcPGkipQkPdmqzoEnmQXOBO4CTqqqA92mrwAnrbDP9iTzSeYXFhZGKFWStNjAAZ7kWOCDwBur6tuLt1VVAbXcflW1s6rmqmpuZmZmpGIlST8wUIAn2UwvvN9TVTd3zY8l2dpt3wocnEyJkqTlDHIVSoAbgH1V9fZFm24FLuuWLwNuGX95kqSVDHIn5ouAS4H7kuzu2q4GrgXen+Ry4EvAr06mREnScvoGeFV9EsgKm1823nIkSYPyTkxJapQBLkmNMsAlqVE+Tnaj8fGr0lOGM3BJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1Kin9uNkffSqpsF/dxqTQb6V/sYkB5PsXdR2TZJHk+zuXhdOtkxJ0lKDnEK5CTh/mfbrqmpb9/rIeMuSJPXTN8Cr6k7g62tQiyRpFUb5EPOKJHu6UywnrtQpyfYk80nmFxYWRng7SdJiwwb4O4FnAduAA8DbVupYVTuraq6q5mZmZoZ8O0nSUkNdhVJVjx1eTnI98OGxVSStI7M7bhv7MfcfM/ZD6ilqqBl4kq2LVl8F7F2pryRpMvrOwJO8FzgX2JLkEeDNwLlJtgEF7AdeN8EaJUnL6BvgVXXJMs03TKAWSdIqeCu9JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1Ki+AZ7kxiQHk+xd1PaMJLcnebD7eeJky5QkLdX3S42Bm4B3AO9e1LYD+HhVXZtkR7d+1fjL+4HZHbeN/Zj7jxn7ISVpzfSdgVfVncDXlzRfBOzqlncBF4+5LklSH8OeAz+pqg50y18BThpTPZKkAY38IWZVFVArbU+yPcl8kvmFhYVR306S1Bk2wB9LshWg+3lwpY5VtbOq5qpqbmZmZsi3kyQtNWyA3wpc1i1fBtwynnIkSYMa5DLC9wKfBp6b5JEklwPXAi9P8iDwy926JGkN9b2MsKouWWHTy8ZciyRpFbwTU5IaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGjXIFzpI2iD8YpSNxRm4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEaNdCt9kv3A48ATwKGqmhtHUZKk/sbxLJSXVtVXx3AcSdIqeApFkho1aoAX8K9J7k6yfbkOSbYnmU8yv7CwMOLbSZIOGzXAX1xVZwEXAK9P8pKlHapqZ1XNVdXczMzMiG8nSTpspACvqke7nweBDwFnj6MoSVJ/Qwd4kh9PctzhZeBXgL3jKkySdGSjXIVyEvChJIeP8w9V9bGxVCVJ6mvoAK+qh4EzxliLJGkVvIxQkhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGjeNxspK0sVxz/ASO+a2xH9IZuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1KiRAjzJ+Uk+n+ShJDvGVZQkqb+hAzzJJuCvgQuA04FLkpw+rsIkSUc2ygz8bOChqnq4qv4PeB9w0XjKkiT1k6oabsfk1cD5VfXb3fqlwAur6ool/bYD27vV5wKfH+DwW4CvDlXY+rTRxgMbb0wbbTyw8ca00cYDg4/pp6tqZmnjxJ8HXlU7gZ2r2SfJfFXNTaikNbfRxgMbb0wbbTyw8ca00cYDo49plFMojwKnLlo/pWuTJK2BUQL8P4BnJ3lmkqOBXwNuHU9ZkqR+hj6FUlWHklwB/AuwCbixqu4fU12rOuXSgI02Hth4Y9po44GNN6aNNh4YcUxDf4gpSZou78SUpEYZ4JLUqKkGeL9b8ZOcluSOJJ9LsifJhdOoc1BJbkxyMMneFbYnyV91492T5Ky1rnE1BhjPb3TjuC/Jp5KcsdY1rla/MS3q94Ikh7r7HdatQcaT5Nwku5Pcn+Tf17K+1Rrg39zxSf45yb3deF671jWuVpJTuxx7oKv5ymX6DJcNVTWVF70PPr8A/AxwNHAvcPqSPjuB3+2WTwf2T6veAcf0EuAsYO8K2y8EPgoEOAe4a9o1jzieXwJO7JYvWO/jGWRMXZ9NwCeAjwCvnnbNI/6OTgAeAE7r1n9y2jWPOJ6rgbd2yzPA14Gjp113nzFtBc7qlo8D/muZrBsqG6Y5Ax/kVvwCnt4tHw/8zxrWt2pVdSe9f1AruQh4d/V8Bjghyda1qW71+o2nqj5VVd/oVj9D716AdW2A3xHAG4APAgcnX9FoBhjPrwM3V9WXu/7rekwDjKeA45IEOLbre2gtahtWVR2oqnu65ceBfcDJS7oNlQ3TDPCTgf9etP4ITx7UNcBvJnmE3mzoDWtT2sQMMuZWXU5vBtG0JCcDrwLeOe1axuQ5wIlJ/i3J3UleM+2CRvQO4Pn0JnP3AVdW1fenW9LgkswCZwJ3Ldk0VDas9w8xLwFuqqpT6P2J8fdJ1nvNTzlJXkovwK+adi1j8JfAVS2FQh9HAb8AvBJ4BfBHSZ4z3ZJG8gpgN/BTwDbgHUmefuRd1ockx9L7y+6NVfXtcRxz4s9COYJBbsW/HDgfoKo+neQYeg9/Wdd/Bh7Bhnv8QJKfB94FXFBVX5t2PWMwB7yv9xc6W4ALkxyqqn+abllDewT4WlV9F/hukjuBM+idh23Ra4Frq3fi+KEkXwSeB3x2umUdWZLN9ML7PVV18zJdhsqGac5mB7kV/8vAywCSPB84BlhY0yrH61bgNd0nzucA36qqA9MualhJTgNuBi6tqlYD4YdU1TOraraqZoEPAL/XcHgD3AK8OMlRSX4MeCG9c7CtWpwJJ9F7wunDU62oj+58/Q3Avqp6+wrdhsqGqc3Aa4Vb8ZP8CTBfVbcCbwKuT/L79D68+K3uf951Kcl7gXOBLd15+zcDmwGq6m/pnce/EHgI+F96s4l1a4Dx/DHwE8DfdDPWQ7XOnxY3wJia0m88VbUvyceAPcD3gXdV1REvoZymAX4/fwrclOQ+eldsXFVV6/0Rsy8CLgXuS7K7a7saOA1GywZvpZekRvmBoCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5Jjfp/Ik+Ua6ork1IAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edcwJoJP4GBs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1d212aa-4715-4828-af0f-ca4375739279"
      },
      "source": [
        "yy[0][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([10.52631579, 24.21052632, 36.84210526, 14.73684211,  7.36842105,\n",
              "        0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0zY-NBY6Rgx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81b645ad-1c8f-40e4-d2f3-8b92713c52b0"
      },
      "source": [
        "bins_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ujCjAa85RG5"
      },
      "source": [
        "k =0\n",
        "for kk in yy[0][0]:\n",
        "  name = str(bins_list[k])\n",
        "  df[name] = yy[0][1][k]\n",
        "  k = k+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMQRVn4D69RC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "422befb2-3efe-4837-b344-e288f8b45228"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>N1</th>\n",
              "      <th>N2</th>\n",
              "      <th>R^2</th>\n",
              "      <th>acc train</th>\n",
              "      <th>acc test</th>\n",
              "      <th>loss train</th>\n",
              "      <th>loss test</th>\n",
              "      <th>Details</th>\n",
              "      <th>0.8</th>\n",
              "      <th>1.0</th>\n",
              "      <th>1.2</th>\n",
              "      <th>1.4</th>\n",
              "      <th>1.6</th>\n",
              "      <th>1.8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>0.91907</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.965986</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.142768</td>\n",
              "      <td>3 layers of Convolution: 64, 128, 256</td>\n",
              "      <td>15.789474</td>\n",
              "      <td>18.421053</td>\n",
              "      <td>21.052632</td>\n",
              "      <td>15.789474</td>\n",
              "      <td>23.684211</td>\n",
              "      <td>2.631579</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   N1  N2      R^2  acc train  ...        1.2        1.4        1.6       1.8\n",
              "0  20  20  0.91907        1.0  ...  21.052632  15.789474  23.684211  2.631579\n",
              "\n",
              "[1 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMWpAwMq5Hw2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "c9698e6d-2923-465d-958f-e08bd6cd95da"
      },
      "source": [
        "Arq = \"output.xlsx\"\n",
        "df.to_excel(Arq)\n",
        "files.download(Arq)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_81bea790-16b5-48eb-be04-967c4175ef15\", \"output.xlsx\", 5275)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}