{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_deploy_neural_network_better_resolution_excel_maio_11_2021.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ucfilho/marquesgabi_paper_fev_2021/blob/main/ANN_%20better_resolution/ANN_deploy_neural_network_better_resolution_excel_maio_12_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sog7Z9pyhUD_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c7a8d0e-9514-490d-cb2b-920af2554c00"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import zipfile\n",
        "#import random\n",
        "from random import randint\n",
        "from PIL import Image\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "#import scikit-image\n",
        "import skimage\n",
        "import pandas as pd\n",
        "#import statsmodels.api as sm\n",
        "#import statsmodels.formula.api as smf\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import sklearn\n",
        "from sklearn.externals import joblib"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4ELNAEunkox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b6617fb-12d6-4b1d-9ecc-0efd8a62543c"
      },
      "source": [
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'MarquesGabi_Routines' already exists and is not an empty directory.\n",
            "/content/MarquesGabi_Routines\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WBboSx5TUCd"
      },
      "source": [
        "# leitura dos dados\n",
        "df1=pd.read_excel(\"ImgGrao_a.xlsx\")\n",
        "df2=pd.read_excel(\"ImgGrao_b.xlsx\")\n",
        "df3=pd.read_excel(\"ImgIndef.xlsx\")\n",
        "df4=pd.read_excel(\"ImgVarios.xlsx\")\n",
        "df5=pd.read_excel(\"ImgBuraco.xlsx\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juA6kckB5rBL"
      },
      "source": [
        "df = pd.concat([df1, df2, df3, df4, df5], ignore_index=True)\n",
        "df.head()\n",
        "df_all = df.copy()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOUmlVfN9B-1"
      },
      "source": [
        "# rede 1 G e B --> r1\n",
        "# rede 2 G e I --> r2\n",
        "# rede 3 G e V --> r3\n",
        "\n",
        "df_r1 = pd.concat([df1, df2, df5], ignore_index=True) # df5 buraco\n",
        "df_r2 = pd.concat([df1, df2, df3], ignore_index=True) # df3 indefinido\n",
        "df_r3 = pd.concat([df1, df2, df4], ignore_index=True) # df4 indefinido"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAbUxeV97OZR"
      },
      "source": [
        "w = df['Type']\n",
        "y = []\n",
        "for wi in w:\n",
        "  if(wi == 'G'):\n",
        "    y.append(1)\n",
        "  elif(wi == 'B'):\n",
        "    y.append(2)\n",
        "  elif(wi == 'I'):\n",
        "    y.append(3)\n",
        "  elif(wi == 'V'):\n",
        "    y.append(4)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6APDXw713SeK",
        "outputId": "ae51a6f1-0ad1-4815-f82a-cb06f52044d5"
      },
      "source": [
        " from collections import Counter\n",
        " Counter(y)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({1: 359, 2: 180, 3: 180, 4: 162})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nePBL2yA62DC",
        "outputId": "5711ed86-0e2c-45c5-ff7a-f65b47e7e994"
      },
      "source": [
        "Counter(y)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({1: 359, 2: 180, 3: 180, 4: 162})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXPBp_Mr7ODk",
        "outputId": "dd80679b-9ca9-4d18-8029-1383a4ff37e1"
      },
      "source": [
        "Counter(w)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'B': 180, 'G': 359, 'I': 180, 'V': 162})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6XWfn3XBAc3"
      },
      "source": [
        "w = df_r1['Type']\n",
        "y_r1 = []\n",
        "for wi in w:\n",
        "  if(wi == 'G'):\n",
        "    y_r1.append(1)\n",
        "  elif(wi == 'B'):\n",
        "    y_r1.append(2)\n",
        "  elif(wi == 'I'):\n",
        "    y_r1.append(3)\n",
        "  elif(wi == 'V'):\n",
        "    y_r1.append(4)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_XyU46lJeOL",
        "outputId": "0676e26e-2971-4c85-b277-1ee54016bb84"
      },
      "source": [
        "Counter(w)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'B': 180, 'G': 359})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRI4xaaLBJgP"
      },
      "source": [
        "\n",
        "w = df_r2['Type']\n",
        "y_r2 = []\n",
        "for wi in w:\n",
        "  if(wi == 'G'):\n",
        "    y_r2.append(1)\n",
        "  elif(wi == 'B'):\n",
        "    y_r2.append(2)\n",
        "  elif(wi == 'I'):\n",
        "    y_r2.append(3)\n",
        "  elif(wi == 'V'):\n",
        "    y_r2.append(4)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I8R6BRWBS73"
      },
      "source": [
        "\n",
        "w = df_r3['Type']\n",
        "y_r3 = []\n",
        "for wi in w:\n",
        "  if(wi == 'G'):\n",
        "    y_r3.append(1)\n",
        "  elif(wi == 'B'):\n",
        "    y_r3.append(2)\n",
        "  elif(wi == 'I'):\n",
        "    y_r3.append(3)\n",
        "  elif(wi == 'V'):\n",
        "    y_r3.append(4)\n",
        " "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TleL3cjSA0-2"
      },
      "source": [
        "df_r1.drop(['Unnamed: 0','Type'], axis='columns', inplace=True)\n",
        "\n",
        "df_r2.drop(['Unnamed: 0','Type'], axis='columns', inplace=True)\n",
        "df_r3.drop(['Unnamed: 0','Type'], axis='columns', inplace=True)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n62rt5Bb7OiO"
      },
      "source": [
        "\n",
        "df.drop(['Unnamed: 0','Type'], axis='columns', inplace=True)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "8-H9oT-HTcOr",
        "outputId": "0fa9a88f-c055-4ac5-b3f4-2f9e7d7207ee"
      },
      "source": [
        "\n",
        "df.head()\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>9960</th>\n",
              "      <th>9961</th>\n",
              "      <th>9962</th>\n",
              "      <th>9963</th>\n",
              "      <th>9964</th>\n",
              "      <th>9965</th>\n",
              "      <th>9966</th>\n",
              "      <th>9967</th>\n",
              "      <th>9968</th>\n",
              "      <th>9969</th>\n",
              "      <th>9970</th>\n",
              "      <th>9971</th>\n",
              "      <th>9972</th>\n",
              "      <th>9973</th>\n",
              "      <th>9974</th>\n",
              "      <th>9975</th>\n",
              "      <th>9976</th>\n",
              "      <th>9977</th>\n",
              "      <th>9978</th>\n",
              "      <th>9979</th>\n",
              "      <th>9980</th>\n",
              "      <th>9981</th>\n",
              "      <th>9982</th>\n",
              "      <th>9983</th>\n",
              "      <th>9984</th>\n",
              "      <th>9985</th>\n",
              "      <th>9986</th>\n",
              "      <th>9987</th>\n",
              "      <th>9988</th>\n",
              "      <th>9989</th>\n",
              "      <th>9990</th>\n",
              "      <th>9991</th>\n",
              "      <th>9992</th>\n",
              "      <th>9993</th>\n",
              "      <th>9994</th>\n",
              "      <th>9995</th>\n",
              "      <th>9996</th>\n",
              "      <th>9997</th>\n",
              "      <th>9998</th>\n",
              "      <th>9999</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001999</td>\n",
              "      <td>0.004410</td>\n",
              "      <td>0.007512</td>\n",
              "      <td>0.007597</td>\n",
              "      <td>0.001814</td>\n",
              "      <td>0.018416</td>\n",
              "      <td>0.006493</td>\n",
              "      <td>0.018636</td>\n",
              "      <td>0.025866</td>\n",
              "      <td>0.036456</td>\n",
              "      <td>0.089498</td>\n",
              "      <td>0.132715</td>\n",
              "      <td>0.182406</td>\n",
              "      <td>0.195022</td>\n",
              "      <td>0.192709</td>\n",
              "      <td>0.217273</td>\n",
              "      <td>0.248402</td>\n",
              "      <td>0.271295</td>\n",
              "      <td>0.301761</td>\n",
              "      <td>0.327257</td>\n",
              "      <td>0.349679</td>\n",
              "      <td>0.368218</td>\n",
              "      <td>0.379251</td>\n",
              "      <td>0.386623</td>\n",
              "      <td>0.392048</td>\n",
              "      <td>0.397745</td>\n",
              "      <td>0.401103</td>\n",
              "      <td>0.401025</td>\n",
              "      <td>0.404894</td>\n",
              "      <td>0.416580</td>\n",
              "      <td>0.434169</td>\n",
              "      <td>0.460933</td>\n",
              "      <td>0.493110</td>\n",
              "      <td>...</td>\n",
              "      <td>0.434994</td>\n",
              "      <td>0.389206</td>\n",
              "      <td>0.344270</td>\n",
              "      <td>0.293615</td>\n",
              "      <td>0.240478</td>\n",
              "      <td>0.220916</td>\n",
              "      <td>0.214827</td>\n",
              "      <td>0.230029</td>\n",
              "      <td>0.267516</td>\n",
              "      <td>0.303217</td>\n",
              "      <td>0.344269</td>\n",
              "      <td>0.368436</td>\n",
              "      <td>0.382597</td>\n",
              "      <td>0.407156</td>\n",
              "      <td>0.435826</td>\n",
              "      <td>0.475790</td>\n",
              "      <td>0.487651</td>\n",
              "      <td>0.479620</td>\n",
              "      <td>0.450575</td>\n",
              "      <td>0.439354</td>\n",
              "      <td>0.486182</td>\n",
              "      <td>0.543086</td>\n",
              "      <td>0.604724</td>\n",
              "      <td>0.637116</td>\n",
              "      <td>0.652283</td>\n",
              "      <td>0.658162</td>\n",
              "      <td>0.676809</td>\n",
              "      <td>0.679400</td>\n",
              "      <td>0.686197</td>\n",
              "      <td>0.687435</td>\n",
              "      <td>0.688788</td>\n",
              "      <td>0.691357</td>\n",
              "      <td>0.693293</td>\n",
              "      <td>0.694552</td>\n",
              "      <td>0.690781</td>\n",
              "      <td>0.686060</td>\n",
              "      <td>0.684924</td>\n",
              "      <td>0.690648</td>\n",
              "      <td>0.692724</td>\n",
              "      <td>0.695607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.590733</td>\n",
              "      <td>0.590733</td>\n",
              "      <td>0.593513</td>\n",
              "      <td>0.600688</td>\n",
              "      <td>0.602888</td>\n",
              "      <td>0.603884</td>\n",
              "      <td>0.606493</td>\n",
              "      <td>0.607812</td>\n",
              "      <td>0.607865</td>\n",
              "      <td>0.610737</td>\n",
              "      <td>0.606924</td>\n",
              "      <td>0.615330</td>\n",
              "      <td>0.633028</td>\n",
              "      <td>0.659495</td>\n",
              "      <td>0.684460</td>\n",
              "      <td>0.699325</td>\n",
              "      <td>0.714745</td>\n",
              "      <td>0.724019</td>\n",
              "      <td>0.712735</td>\n",
              "      <td>0.718909</td>\n",
              "      <td>0.739403</td>\n",
              "      <td>0.742262</td>\n",
              "      <td>0.748695</td>\n",
              "      <td>0.758599</td>\n",
              "      <td>0.767703</td>\n",
              "      <td>0.794826</td>\n",
              "      <td>0.832993</td>\n",
              "      <td>0.870705</td>\n",
              "      <td>0.914748</td>\n",
              "      <td>0.955046</td>\n",
              "      <td>0.984443</td>\n",
              "      <td>0.981314</td>\n",
              "      <td>0.982499</td>\n",
              "      <td>0.984577</td>\n",
              "      <td>0.983864</td>\n",
              "      <td>0.986575</td>\n",
              "      <td>0.986569</td>\n",
              "      <td>0.981710</td>\n",
              "      <td>0.982986</td>\n",
              "      <td>0.983163</td>\n",
              "      <td>...</td>\n",
              "      <td>0.504280</td>\n",
              "      <td>0.515158</td>\n",
              "      <td>0.521394</td>\n",
              "      <td>0.523707</td>\n",
              "      <td>0.525853</td>\n",
              "      <td>0.531329</td>\n",
              "      <td>0.532653</td>\n",
              "      <td>0.525593</td>\n",
              "      <td>0.519400</td>\n",
              "      <td>0.517106</td>\n",
              "      <td>0.522404</td>\n",
              "      <td>0.529931</td>\n",
              "      <td>0.527789</td>\n",
              "      <td>0.525735</td>\n",
              "      <td>0.515755</td>\n",
              "      <td>0.507206</td>\n",
              "      <td>0.503637</td>\n",
              "      <td>0.504476</td>\n",
              "      <td>0.505665</td>\n",
              "      <td>0.507559</td>\n",
              "      <td>0.506294</td>\n",
              "      <td>0.502238</td>\n",
              "      <td>0.504885</td>\n",
              "      <td>0.506160</td>\n",
              "      <td>0.506160</td>\n",
              "      <td>0.502238</td>\n",
              "      <td>0.502238</td>\n",
              "      <td>0.502238</td>\n",
              "      <td>0.501082</td>\n",
              "      <td>0.498856</td>\n",
              "      <td>0.494157</td>\n",
              "      <td>0.492460</td>\n",
              "      <td>0.497766</td>\n",
              "      <td>0.506807</td>\n",
              "      <td>0.512615</td>\n",
              "      <td>0.517496</td>\n",
              "      <td>0.535938</td>\n",
              "      <td>0.548059</td>\n",
              "      <td>0.551222</td>\n",
              "      <td>0.550831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.782922</td>\n",
              "      <td>0.567252</td>\n",
              "      <td>0.436217</td>\n",
              "      <td>0.422201</td>\n",
              "      <td>0.383646</td>\n",
              "      <td>0.408192</td>\n",
              "      <td>0.458177</td>\n",
              "      <td>0.534249</td>\n",
              "      <td>0.586286</td>\n",
              "      <td>0.623401</td>\n",
              "      <td>0.649196</td>\n",
              "      <td>0.649104</td>\n",
              "      <td>0.654247</td>\n",
              "      <td>0.653861</td>\n",
              "      <td>0.655389</td>\n",
              "      <td>0.679137</td>\n",
              "      <td>0.691348</td>\n",
              "      <td>0.701388</td>\n",
              "      <td>0.722229</td>\n",
              "      <td>0.741845</td>\n",
              "      <td>0.748453</td>\n",
              "      <td>0.754893</td>\n",
              "      <td>0.775516</td>\n",
              "      <td>0.785541</td>\n",
              "      <td>0.789540</td>\n",
              "      <td>0.788691</td>\n",
              "      <td>0.781585</td>\n",
              "      <td>0.778936</td>\n",
              "      <td>0.777410</td>\n",
              "      <td>0.770414</td>\n",
              "      <td>0.738796</td>\n",
              "      <td>0.701680</td>\n",
              "      <td>0.639025</td>\n",
              "      <td>0.620904</td>\n",
              "      <td>0.615012</td>\n",
              "      <td>0.628039</td>\n",
              "      <td>0.618398</td>\n",
              "      <td>0.613603</td>\n",
              "      <td>0.608772</td>\n",
              "      <td>0.594399</td>\n",
              "      <td>...</td>\n",
              "      <td>0.603981</td>\n",
              "      <td>0.619088</td>\n",
              "      <td>0.623804</td>\n",
              "      <td>0.626015</td>\n",
              "      <td>0.633530</td>\n",
              "      <td>0.638861</td>\n",
              "      <td>0.639104</td>\n",
              "      <td>0.635193</td>\n",
              "      <td>0.638450</td>\n",
              "      <td>0.638591</td>\n",
              "      <td>0.633140</td>\n",
              "      <td>0.627689</td>\n",
              "      <td>0.623316</td>\n",
              "      <td>0.625924</td>\n",
              "      <td>0.631474</td>\n",
              "      <td>0.641321</td>\n",
              "      <td>0.654669</td>\n",
              "      <td>0.665172</td>\n",
              "      <td>0.668211</td>\n",
              "      <td>0.668976</td>\n",
              "      <td>0.669088</td>\n",
              "      <td>0.669913</td>\n",
              "      <td>0.669249</td>\n",
              "      <td>0.669204</td>\n",
              "      <td>0.669204</td>\n",
              "      <td>0.670202</td>\n",
              "      <td>0.671024</td>\n",
              "      <td>0.676214</td>\n",
              "      <td>0.686301</td>\n",
              "      <td>0.692875</td>\n",
              "      <td>0.691104</td>\n",
              "      <td>0.683588</td>\n",
              "      <td>0.690719</td>\n",
              "      <td>0.696150</td>\n",
              "      <td>0.688000</td>\n",
              "      <td>0.686973</td>\n",
              "      <td>0.684969</td>\n",
              "      <td>0.695368</td>\n",
              "      <td>0.688670</td>\n",
              "      <td>0.690964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.755803</td>\n",
              "      <td>0.743160</td>\n",
              "      <td>0.726090</td>\n",
              "      <td>0.711844</td>\n",
              "      <td>0.699036</td>\n",
              "      <td>0.689467</td>\n",
              "      <td>0.681869</td>\n",
              "      <td>0.678469</td>\n",
              "      <td>0.674880</td>\n",
              "      <td>0.670235</td>\n",
              "      <td>0.668098</td>\n",
              "      <td>0.666438</td>\n",
              "      <td>0.664104</td>\n",
              "      <td>0.658069</td>\n",
              "      <td>0.653204</td>\n",
              "      <td>0.644293</td>\n",
              "      <td>0.640751</td>\n",
              "      <td>0.636079</td>\n",
              "      <td>0.625210</td>\n",
              "      <td>0.551342</td>\n",
              "      <td>0.418341</td>\n",
              "      <td>0.335526</td>\n",
              "      <td>0.298965</td>\n",
              "      <td>0.323055</td>\n",
              "      <td>0.380529</td>\n",
              "      <td>0.442372</td>\n",
              "      <td>0.499205</td>\n",
              "      <td>0.534366</td>\n",
              "      <td>0.550248</td>\n",
              "      <td>0.550190</td>\n",
              "      <td>0.554105</td>\n",
              "      <td>0.559937</td>\n",
              "      <td>0.557711</td>\n",
              "      <td>0.558275</td>\n",
              "      <td>0.560166</td>\n",
              "      <td>0.561812</td>\n",
              "      <td>0.560468</td>\n",
              "      <td>0.556880</td>\n",
              "      <td>0.552249</td>\n",
              "      <td>0.550054</td>\n",
              "      <td>...</td>\n",
              "      <td>0.348118</td>\n",
              "      <td>0.345031</td>\n",
              "      <td>0.348267</td>\n",
              "      <td>0.364107</td>\n",
              "      <td>0.380258</td>\n",
              "      <td>0.392402</td>\n",
              "      <td>0.399786</td>\n",
              "      <td>0.397017</td>\n",
              "      <td>0.403953</td>\n",
              "      <td>0.413527</td>\n",
              "      <td>0.416625</td>\n",
              "      <td>0.420546</td>\n",
              "      <td>0.424958</td>\n",
              "      <td>0.429501</td>\n",
              "      <td>0.438085</td>\n",
              "      <td>0.447563</td>\n",
              "      <td>0.449701</td>\n",
              "      <td>0.452459</td>\n",
              "      <td>0.456161</td>\n",
              "      <td>0.456150</td>\n",
              "      <td>0.452170</td>\n",
              "      <td>0.449687</td>\n",
              "      <td>0.445267</td>\n",
              "      <td>0.445230</td>\n",
              "      <td>0.441673</td>\n",
              "      <td>0.436899</td>\n",
              "      <td>0.433583</td>\n",
              "      <td>0.432096</td>\n",
              "      <td>0.431090</td>\n",
              "      <td>0.431001</td>\n",
              "      <td>0.435831</td>\n",
              "      <td>0.443050</td>\n",
              "      <td>0.443600</td>\n",
              "      <td>0.443600</td>\n",
              "      <td>0.441852</td>\n",
              "      <td>0.434194</td>\n",
              "      <td>0.427302</td>\n",
              "      <td>0.422302</td>\n",
              "      <td>0.419027</td>\n",
              "      <td>0.427234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.393078</td>\n",
              "      <td>0.386396</td>\n",
              "      <td>0.379635</td>\n",
              "      <td>0.369983</td>\n",
              "      <td>0.366430</td>\n",
              "      <td>0.364693</td>\n",
              "      <td>0.357674</td>\n",
              "      <td>0.352249</td>\n",
              "      <td>0.349484</td>\n",
              "      <td>0.339121</td>\n",
              "      <td>0.324988</td>\n",
              "      <td>0.312374</td>\n",
              "      <td>0.299256</td>\n",
              "      <td>0.280988</td>\n",
              "      <td>0.270648</td>\n",
              "      <td>0.259144</td>\n",
              "      <td>0.250210</td>\n",
              "      <td>0.248335</td>\n",
              "      <td>0.248335</td>\n",
              "      <td>0.246887</td>\n",
              "      <td>0.242802</td>\n",
              "      <td>0.240844</td>\n",
              "      <td>0.245782</td>\n",
              "      <td>0.263364</td>\n",
              "      <td>0.283730</td>\n",
              "      <td>0.299547</td>\n",
              "      <td>0.318943</td>\n",
              "      <td>0.332403</td>\n",
              "      <td>0.338516</td>\n",
              "      <td>0.348085</td>\n",
              "      <td>0.358274</td>\n",
              "      <td>0.363858</td>\n",
              "      <td>0.366182</td>\n",
              "      <td>0.370358</td>\n",
              "      <td>0.375173</td>\n",
              "      <td>0.375981</td>\n",
              "      <td>0.376692</td>\n",
              "      <td>0.382018</td>\n",
              "      <td>0.387508</td>\n",
              "      <td>0.393909</td>\n",
              "      <td>...</td>\n",
              "      <td>0.384657</td>\n",
              "      <td>0.403297</td>\n",
              "      <td>0.423077</td>\n",
              "      <td>0.447296</td>\n",
              "      <td>0.469999</td>\n",
              "      <td>0.486352</td>\n",
              "      <td>0.502705</td>\n",
              "      <td>0.513613</td>\n",
              "      <td>0.520715</td>\n",
              "      <td>0.526201</td>\n",
              "      <td>0.534967</td>\n",
              "      <td>0.542417</td>\n",
              "      <td>0.547844</td>\n",
              "      <td>0.552185</td>\n",
              "      <td>0.553289</td>\n",
              "      <td>0.554416</td>\n",
              "      <td>0.554841</td>\n",
              "      <td>0.553113</td>\n",
              "      <td>0.550441</td>\n",
              "      <td>0.551207</td>\n",
              "      <td>0.558669</td>\n",
              "      <td>0.569098</td>\n",
              "      <td>0.575768</td>\n",
              "      <td>0.579003</td>\n",
              "      <td>0.583544</td>\n",
              "      <td>0.588513</td>\n",
              "      <td>0.588513</td>\n",
              "      <td>0.592945</td>\n",
              "      <td>0.596948</td>\n",
              "      <td>0.597352</td>\n",
              "      <td>0.588352</td>\n",
              "      <td>0.582792</td>\n",
              "      <td>0.580079</td>\n",
              "      <td>0.596432</td>\n",
              "      <td>0.610145</td>\n",
              "      <td>0.616431</td>\n",
              "      <td>0.617803</td>\n",
              "      <td>0.618702</td>\n",
              "      <td>0.607442</td>\n",
              "      <td>0.600833</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 10000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0         1         2     ...      9997      9998      9999\n",
              "0  0.000000  0.000000  0.000000  ...  0.690648  0.692724  0.695607\n",
              "1  0.590733  0.590733  0.593513  ...  0.548059  0.551222  0.550831\n",
              "2  0.782922  0.567252  0.436217  ...  0.695368  0.688670  0.690964\n",
              "3  0.755803  0.743160  0.726090  ...  0.422302  0.419027  0.427234\n",
              "4  0.393078  0.386396  0.379635  ...  0.618702  0.607442  0.600833\n",
              "\n",
              "[5 rows x 10000 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aobZmEXHAxIP",
        "outputId": "8d5c0c4d-13c7-48a5-95eb-86aa6e988548"
      },
      "source": [
        "\n",
        "#X =np.array(df.copy())/255.0 \n",
        "X =np.array(df.copy())\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42)\n",
        "\n",
        "model = MLPClassifier(hidden_layer_sizes=(200,10), activation='tanh', \n",
        "                      solver='adam',random_state=1, max_iter=300).fit(X_train,y_train)\n",
        "  \n",
        "prediction = model.predict(X_test)\n",
        "  \n",
        "y =np.copy(y_test)\n",
        "data = {'y_true': y_test,'y_predict': prediction}  # este dado esta no formato de dicionario\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_true','y_predict'])\n",
        "\n",
        "\n",
        "confusion_matrix = pd.crosstab(df['y_true'], df['y_predict'], rownames=['Actual'], colnames=['Predict'])\n",
        "print(confusion_matrix)\n",
        "\n",
        "y_true = df['y_true']\n",
        "y_pred = df['y_predict']\n",
        "\n",
        "  \n",
        "METRICS=sklearn.metrics.classification_report(y_true, y_pred)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predict    1   2  3  4\n",
            "Actual                \n",
            "1        105   1  0  0\n",
            "2          0  51  0  0\n",
            "3         20  40  3  0\n",
            "4         26  15  3  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCe9ihVdBlNS",
        "outputId": "fe8eb150-f9a3-4c93-bd41-39dcbba2d666"
      },
      "source": [
        "#X =np.array(df.copy())/255.0 \n",
        "df = df_r1.copy()\n",
        "y = y_r1.copy()\n",
        "X =np.array(df.copy())\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42)\n",
        "\n",
        "model = MLPClassifier(hidden_layer_sizes=(200,10), activation='tanh', \n",
        "                      solver='adam',random_state=1, max_iter=300).fit(X_train,y_train)\n",
        "  \n",
        "prediction = model.predict(X_test)\n",
        "  \n",
        "y =np.copy(y_test)\n",
        "data = {'y_true': y_test,'y_predict': prediction}  # este dado esta no formato de dicionario\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_true','y_predict'])\n",
        "\n",
        "\n",
        "confusion_matrix = pd.crosstab(df['y_true'], df['y_predict'], rownames=['Actual'], colnames=['Predict'])\n",
        "print('rede 1 G e B --> r1') \n",
        "print(confusion_matrix)\n",
        "\n",
        "y_true = df['y_true']\n",
        "y_pred = df['y_predict']\n",
        "\n",
        "  \n",
        "METRICS=sklearn.metrics.classification_report(y_true, y_pred)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rede 1 G e B --> r1\n",
            "Predict    1\n",
            "Actual      \n",
            "1        106\n",
            "2         56\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GO6fwLGIB1eR",
        "outputId": "126da004-ada0-43ee-f73e-4220ef0f61fa"
      },
      "source": [
        "\n",
        "#X =np.array(df.copy())/255.0 \n",
        "df = df_r2.copy()\n",
        "y = y_r2.copy()\n",
        "X =np.array(df.copy())\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42)\n",
        "\n",
        "model = MLPClassifier(hidden_layer_sizes=(200,10), activation='tanh', \n",
        "                      solver='adam',random_state=1, max_iter=300).fit(X_train,y_train)\n",
        "  \n",
        "prediction = model.predict(X_test)\n",
        "  \n",
        "y =np.copy(y_test)\n",
        "data = {'y_true': y_test,'y_predict': prediction}  # este dado esta no formato de dicionario\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_true','y_predict'])\n",
        "\n",
        "\n",
        "confusion_matrix = pd.crosstab(df['y_true'], df['y_predict'], rownames=['Actual'], colnames=['Predict'])\n",
        "print(' rede 2 G e I --> r2')\n",
        "print(confusion_matrix)\n",
        "\n",
        "y_true = df['y_true']\n",
        "y_pred = df['y_predict']\n",
        "\n",
        "  \n",
        "METRICS=sklearn.metrics.classification_report(y_true, y_pred)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " rede 2 G e I --> r2\n",
            "Predict    1\n",
            "Actual      \n",
            "1        106\n",
            "3         56\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yE-qa5pVB5Dl",
        "outputId": "52ca2ca5-796c-4202-d4e1-adbfa266741c"
      },
      "source": [
        "\n",
        "#X =np.array(df.copy())/255.0 \n",
        "df = df_r3.copy()\n",
        "y = y_r3.copy()\n",
        "X =np.array(df.copy())\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42)\n",
        "\n",
        "model = MLPClassifier(hidden_layer_sizes=(200,10), activation='tanh', \n",
        "                      solver='adam',random_state=1, max_iter=300).fit(X_train,y_train)\n",
        "  \n",
        "prediction = model.predict(X_test)\n",
        "  \n",
        "y =np.copy(y_test)\n",
        "data = {'y_true': y_test,'y_predict': prediction}  # este dado esta no formato de dicionario\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_true','y_predict'])\n",
        "\n",
        "\n",
        "confusion_matrix = pd.crosstab(df['y_true'], df['y_predict'], rownames=['Actual'], colnames=['Predict'])\n",
        "print('rede 3 G e V --> r3')\n",
        "print(confusion_matrix)\n",
        "\n",
        "y_true = df['y_true']\n",
        "y_pred = df['y_predict']\n",
        "\n",
        "  \n",
        "METRICS=sklearn.metrics.classification_report(y_true, y_pred)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rede 3 G e V --> r3\n",
            "Predict    1\n",
            "Actual      \n",
            "1        110\n",
            "4         47\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-WgUqQhHeQp"
      },
      "source": [
        "# joblib.dump(model,'model_ANN_new.pkl')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jjpqjbw3_jQc",
        "outputId": "2da43c05-0996-4db6-cad4-d0ccb1baa7f9"
      },
      "source": [
        "'''\n",
        "Arq = 'model_ANN_new.pkl'\n",
        "from google.colab import files\n",
        "files.download(Arq)\n",
        "'''"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nArq = 'model_ANN_new.pkl'\\nfrom google.colab import files\\nfiles.download(Arq)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKgBk8efNkQP"
      },
      "source": [
        "w = df_all['Type']\n",
        "y = []\n",
        "for wi in w:\n",
        "  if(wi == 'G'):\n",
        "    y.append(1)\n",
        "  elif(wi == 'B'):\n",
        "    y.append(2)\n",
        "  elif(wi == 'I'):\n",
        "    y.append(2)\n",
        "  elif(wi == 'V'):\n",
        "    y.append(2)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrTH3pNpORyZ"
      },
      "source": [
        "df_all.drop(['Unnamed: 0','Type'], axis='columns', inplace=True)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqNPfdzqNjH8",
        "outputId": "446de6a1-ede4-4893-e0f5-2c184a3a478b"
      },
      "source": [
        "\n",
        "#X =np.array(df.copy())/255.0 \n",
        "X =np.array(df_all.copy())\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42)\n",
        "\n",
        "model = MLPClassifier(hidden_layer_sizes=(200,10), activation='tanh', \n",
        "                      solver='adam',random_state=1, max_iter=300).fit(X_train,y_train)\n",
        "  \n",
        "prediction = model.predict(X_test)\n",
        "  \n",
        "y =np.copy(y_test)\n",
        "data = {'y_true': y_test,'y_predict': prediction}  # este dado esta no formato de dicionario\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_true','y_predict'])\n",
        "\n",
        "\n",
        "confusion_matrix = pd.crosstab(df['y_true'], df['y_predict'], rownames=['Actual'], colnames=['Predict'])\n",
        "print(confusion_matrix)\n",
        "\n",
        "y_true = df['y_true']\n",
        "y_pred = df['y_predict']\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predict   1    2\n",
            "Actual          \n",
            "1        90   16\n",
            "2        11  148\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8jiK2YCN1ja"
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    }
  ]
}