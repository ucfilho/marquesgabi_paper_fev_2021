{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_deploy_neural_network_comparative_resolution_excel_maio_11_2021.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ucfilho/marquesgabi_paper_fev_2021/blob/main/ANN_%20better_resolution/ANN_deploy_neural_network_comparative_resolution_excel_maio_11_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sog7Z9pyhUD_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d11fd3c-dc07-43c4-9f7a-a1516a69b494"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import zipfile\n",
        "#import random\n",
        "from random import randint\n",
        "from PIL import Image\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "#import scikit-image\n",
        "import skimage\n",
        "import pandas as pd\n",
        "#import statsmodels.api as sm\n",
        "#import statsmodels.formula.api as smf\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import sklearn\n",
        "from sklearn.externals import joblib"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4ELNAEunkox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "794702f9-07c0-4717-e937-542ca842cbbd"
      },
      "source": [
        "!git clone https://github.com/ucfilho/MarquesGabi_Routines\n",
        "%cd MarquesGabi_Routines"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MarquesGabi_Routines'...\n",
            "remote: Enumerating objects: 102, done.\u001b[K\n",
            "remote: Counting objects: 100% (102/102), done.\u001b[K\n",
            "remote: Compressing objects: 100% (100/100), done.\u001b[K\n",
            "remote: Total 102 (delta 44), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (102/102), 124.74 MiB | 21.94 MiB/s, done.\n",
            "Resolving deltas: 100% (44/44), done.\n",
            "/content/MarquesGabi_Routines\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WBboSx5TUCd"
      },
      "source": [
        "# leitura dos dados\n",
        "df1=pd.read_excel(\"ImgGrao_a28.xlsx\")\n",
        "df2=pd.read_excel(\"ImgGrao_b28.xlsx\")\n",
        "df3=pd.read_excel(\"ImgIndef28.xlsx\")\n",
        "df4=pd.read_excel(\"ImgVarios28.xlsx\")\n",
        "df5=pd.read_excel(\"ImgBuraco28.xlsx\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juA6kckB5rBL"
      },
      "source": [
        "df = pd.concat([df1, df2, df3, df4, df5], ignore_index=True)\n",
        "df.head()\n",
        "df_all = df.copy()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOUmlVfN9B-1"
      },
      "source": [
        "# rede 1 G e B --> r1\n",
        "# rede 2 G e I --> r2\n",
        "# rede 3 G e V --> r3\n",
        "\n",
        "df_r1 = pd.concat([df1, df2, df5], ignore_index=True) # df5 buraco\n",
        "df_r2 = pd.concat([df1, df2, df3], ignore_index=True) # df3 indefinido\n",
        "df_r3 = pd.concat([df1, df2, df4], ignore_index=True) # df4 indefinido"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAbUxeV97OZR"
      },
      "source": [
        "w = df['Type']\n",
        "y = []\n",
        "for wi in w:\n",
        "  if(wi == 'G'):\n",
        "    y.append(1)\n",
        "  elif(wi == 'B'):\n",
        "    y.append(2)\n",
        "  elif(wi == 'I'):\n",
        "    y.append(3)\n",
        "  elif(wi == 'V'):\n",
        "    y.append(4)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6APDXw713SeK",
        "outputId": "cd387750-b5b6-4189-da2f-20c21284566a"
      },
      "source": [
        " from collections import Counter\n",
        " Counter(y)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({1: 359, 2: 180, 3: 180, 4: 162})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nePBL2yA62DC",
        "outputId": "b5fe83fa-9078-43d0-ec17-421c1a59f279"
      },
      "source": [
        "Counter(y)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({1: 359, 2: 180, 3: 180, 4: 162})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXPBp_Mr7ODk",
        "outputId": "0dd1bd98-6ce3-4b61-9c65-cd8996f7c370"
      },
      "source": [
        "Counter(w)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'B': 180, 'G': 359, 'I': 180, 'V': 162})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6XWfn3XBAc3"
      },
      "source": [
        "w = df_r1['Type']\n",
        "y_r1 = []\n",
        "for wi in w:\n",
        "  if(wi == 'G'):\n",
        "    y_r1.append(1)\n",
        "  elif(wi == 'B'):\n",
        "    y_r1.append(2)\n",
        "  elif(wi == 'I'):\n",
        "    y_r1.append(3)\n",
        "  elif(wi == 'V'):\n",
        "    y_r1.append(4)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_XyU46lJeOL",
        "outputId": "d521f132-8af7-49d8-abbb-a2862fd7dbb1"
      },
      "source": [
        "Counter(w)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'B': 180, 'G': 359})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRI4xaaLBJgP"
      },
      "source": [
        "\n",
        "w = df_r2['Type']\n",
        "y_r2 = []\n",
        "for wi in w:\n",
        "  if(wi == 'G'):\n",
        "    y_r2.append(1)\n",
        "  elif(wi == 'B'):\n",
        "    y_r2.append(2)\n",
        "  elif(wi == 'I'):\n",
        "    y_r2.append(3)\n",
        "  elif(wi == 'V'):\n",
        "    y_r2.append(4)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I8R6BRWBS73"
      },
      "source": [
        "\n",
        "w = df_r3['Type']\n",
        "y_r3 = []\n",
        "for wi in w:\n",
        "  if(wi == 'G'):\n",
        "    y_r3.append(1)\n",
        "  elif(wi == 'B'):\n",
        "    y_r3.append(2)\n",
        "  elif(wi == 'I'):\n",
        "    y_r3.append(3)\n",
        "  elif(wi == 'V'):\n",
        "    y_r3.append(4)\n",
        " "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TleL3cjSA0-2"
      },
      "source": [
        "df_r1.drop(['Unnamed: 0','Type'], axis='columns', inplace=True)\n",
        "\n",
        "df_r2.drop(['Unnamed: 0','Type'], axis='columns', inplace=True)\n",
        "df_r3.drop(['Unnamed: 0','Type'], axis='columns', inplace=True)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n62rt5Bb7OiO"
      },
      "source": [
        "\n",
        "df.drop(['Unnamed: 0','Type'], axis='columns', inplace=True)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "8-H9oT-HTcOr",
        "outputId": "100f3242-e961-4372-a511-8d432061894f"
      },
      "source": [
        "\n",
        "df.head()\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "      <th>769</th>\n",
              "      <th>770</th>\n",
              "      <th>771</th>\n",
              "      <th>772</th>\n",
              "      <th>773</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003151</td>\n",
              "      <td>0.008512</td>\n",
              "      <td>0.046079</td>\n",
              "      <td>0.161025</td>\n",
              "      <td>0.249250</td>\n",
              "      <td>0.341634</td>\n",
              "      <td>0.401510</td>\n",
              "      <td>0.423633</td>\n",
              "      <td>0.465140</td>\n",
              "      <td>0.524040</td>\n",
              "      <td>0.542127</td>\n",
              "      <td>0.529071</td>\n",
              "      <td>0.493682</td>\n",
              "      <td>0.476558</td>\n",
              "      <td>0.465347</td>\n",
              "      <td>0.442932</td>\n",
              "      <td>0.434578</td>\n",
              "      <td>0.549604</td>\n",
              "      <td>0.621820</td>\n",
              "      <td>0.654017</td>\n",
              "      <td>0.670046</td>\n",
              "      <td>0.684038</td>\n",
              "      <td>0.701010</td>\n",
              "      <td>0.721879</td>\n",
              "      <td>0.729558</td>\n",
              "      <td>0.725416</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000897</td>\n",
              "      <td>0.008161</td>\n",
              "      <td>0.041225</td>\n",
              "      <td>0.167225</td>\n",
              "      <td>0.280238</td>\n",
              "      <td>0.369286</td>\n",
              "      <td>0.435753</td>\n",
              "      <td>0.485960</td>\n",
              "      <td>0.527570</td>\n",
              "      <td>0.553342</td>\n",
              "      <td>...</td>\n",
              "      <td>0.688366</td>\n",
              "      <td>0.572467</td>\n",
              "      <td>0.505769</td>\n",
              "      <td>0.400344</td>\n",
              "      <td>0.420051</td>\n",
              "      <td>0.494477</td>\n",
              "      <td>0.540214</td>\n",
              "      <td>0.632394</td>\n",
              "      <td>0.669126</td>\n",
              "      <td>0.676557</td>\n",
              "      <td>0.676553</td>\n",
              "      <td>0.680999</td>\n",
              "      <td>0.001299</td>\n",
              "      <td>0.010381</td>\n",
              "      <td>0.015902</td>\n",
              "      <td>0.091375</td>\n",
              "      <td>0.492179</td>\n",
              "      <td>0.668307</td>\n",
              "      <td>0.698669</td>\n",
              "      <td>0.709305</td>\n",
              "      <td>0.707501</td>\n",
              "      <td>0.694637</td>\n",
              "      <td>0.676150</td>\n",
              "      <td>0.654286</td>\n",
              "      <td>0.650667</td>\n",
              "      <td>0.745061</td>\n",
              "      <td>0.726222</td>\n",
              "      <td>0.594198</td>\n",
              "      <td>0.536752</td>\n",
              "      <td>0.403542</td>\n",
              "      <td>0.287626</td>\n",
              "      <td>0.325233</td>\n",
              "      <td>0.406265</td>\n",
              "      <td>0.473597</td>\n",
              "      <td>0.507009</td>\n",
              "      <td>0.632702</td>\n",
              "      <td>0.673565</td>\n",
              "      <td>0.686423</td>\n",
              "      <td>0.686308</td>\n",
              "      <td>0.687691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.593498</td>\n",
              "      <td>0.595789</td>\n",
              "      <td>0.604417</td>\n",
              "      <td>0.629339</td>\n",
              "      <td>0.690502</td>\n",
              "      <td>0.723617</td>\n",
              "      <td>0.752180</td>\n",
              "      <td>0.807498</td>\n",
              "      <td>0.926054</td>\n",
              "      <td>0.979227</td>\n",
              "      <td>0.981462</td>\n",
              "      <td>0.981662</td>\n",
              "      <td>0.978794</td>\n",
              "      <td>0.969066</td>\n",
              "      <td>0.915592</td>\n",
              "      <td>0.648638</td>\n",
              "      <td>0.646689</td>\n",
              "      <td>0.697683</td>\n",
              "      <td>0.645514</td>\n",
              "      <td>0.564038</td>\n",
              "      <td>0.551704</td>\n",
              "      <td>0.526761</td>\n",
              "      <td>0.513103</td>\n",
              "      <td>0.523835</td>\n",
              "      <td>0.528594</td>\n",
              "      <td>0.538076</td>\n",
              "      <td>0.539289</td>\n",
              "      <td>0.544340</td>\n",
              "      <td>0.577254</td>\n",
              "      <td>0.576924</td>\n",
              "      <td>0.598542</td>\n",
              "      <td>0.617434</td>\n",
              "      <td>0.672270</td>\n",
              "      <td>0.722497</td>\n",
              "      <td>0.742164</td>\n",
              "      <td>0.749833</td>\n",
              "      <td>0.811081</td>\n",
              "      <td>0.934974</td>\n",
              "      <td>0.974534</td>\n",
              "      <td>0.975640</td>\n",
              "      <td>...</td>\n",
              "      <td>0.499430</td>\n",
              "      <td>0.512641</td>\n",
              "      <td>0.514502</td>\n",
              "      <td>0.513723</td>\n",
              "      <td>0.507830</td>\n",
              "      <td>0.497376</td>\n",
              "      <td>0.490627</td>\n",
              "      <td>0.486552</td>\n",
              "      <td>0.484075</td>\n",
              "      <td>0.487450</td>\n",
              "      <td>0.524998</td>\n",
              "      <td>0.540638</td>\n",
              "      <td>0.879749</td>\n",
              "      <td>0.911084</td>\n",
              "      <td>0.940911</td>\n",
              "      <td>0.921216</td>\n",
              "      <td>0.818403</td>\n",
              "      <td>0.564881</td>\n",
              "      <td>0.498511</td>\n",
              "      <td>0.508182</td>\n",
              "      <td>0.476045</td>\n",
              "      <td>0.422849</td>\n",
              "      <td>0.370371</td>\n",
              "      <td>0.307812</td>\n",
              "      <td>0.273039</td>\n",
              "      <td>0.244343</td>\n",
              "      <td>0.298105</td>\n",
              "      <td>0.404935</td>\n",
              "      <td>0.484637</td>\n",
              "      <td>0.514005</td>\n",
              "      <td>0.519816</td>\n",
              "      <td>0.520208</td>\n",
              "      <td>0.518087</td>\n",
              "      <td>0.502853</td>\n",
              "      <td>0.499150</td>\n",
              "      <td>0.500908</td>\n",
              "      <td>0.494672</td>\n",
              "      <td>0.493535</td>\n",
              "      <td>0.517529</td>\n",
              "      <td>0.543134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.587986</td>\n",
              "      <td>0.427366</td>\n",
              "      <td>0.589358</td>\n",
              "      <td>0.652953</td>\n",
              "      <td>0.687684</td>\n",
              "      <td>0.753252</td>\n",
              "      <td>0.804099</td>\n",
              "      <td>0.831786</td>\n",
              "      <td>0.807506</td>\n",
              "      <td>0.664805</td>\n",
              "      <td>0.633399</td>\n",
              "      <td>0.621664</td>\n",
              "      <td>0.600515</td>\n",
              "      <td>0.579862</td>\n",
              "      <td>0.533493</td>\n",
              "      <td>0.489556</td>\n",
              "      <td>0.463801</td>\n",
              "      <td>0.469392</td>\n",
              "      <td>0.503838</td>\n",
              "      <td>0.554225</td>\n",
              "      <td>0.576228</td>\n",
              "      <td>0.583792</td>\n",
              "      <td>0.589118</td>\n",
              "      <td>0.594311</td>\n",
              "      <td>0.576755</td>\n",
              "      <td>0.538420</td>\n",
              "      <td>0.514096</td>\n",
              "      <td>0.494460</td>\n",
              "      <td>0.663203</td>\n",
              "      <td>0.433938</td>\n",
              "      <td>0.594435</td>\n",
              "      <td>0.648392</td>\n",
              "      <td>0.682222</td>\n",
              "      <td>0.791105</td>\n",
              "      <td>0.865560</td>\n",
              "      <td>0.922267</td>\n",
              "      <td>0.932037</td>\n",
              "      <td>0.780094</td>\n",
              "      <td>0.638023</td>\n",
              "      <td>0.645592</td>\n",
              "      <td>...</td>\n",
              "      <td>0.654959</td>\n",
              "      <td>0.625850</td>\n",
              "      <td>0.612988</td>\n",
              "      <td>0.613666</td>\n",
              "      <td>0.622968</td>\n",
              "      <td>0.638038</td>\n",
              "      <td>0.651894</td>\n",
              "      <td>0.664243</td>\n",
              "      <td>0.681647</td>\n",
              "      <td>0.701033</td>\n",
              "      <td>0.704188</td>\n",
              "      <td>0.703184</td>\n",
              "      <td>0.548568</td>\n",
              "      <td>0.538412</td>\n",
              "      <td>0.525069</td>\n",
              "      <td>0.523385</td>\n",
              "      <td>0.466286</td>\n",
              "      <td>0.390800</td>\n",
              "      <td>0.372922</td>\n",
              "      <td>0.410038</td>\n",
              "      <td>0.440351</td>\n",
              "      <td>0.506673</td>\n",
              "      <td>0.554724</td>\n",
              "      <td>0.569067</td>\n",
              "      <td>0.615107</td>\n",
              "      <td>0.645189</td>\n",
              "      <td>0.622219</td>\n",
              "      <td>0.580629</td>\n",
              "      <td>0.582461</td>\n",
              "      <td>0.618082</td>\n",
              "      <td>0.627595</td>\n",
              "      <td>0.630058</td>\n",
              "      <td>0.626357</td>\n",
              "      <td>0.646389</td>\n",
              "      <td>0.661905</td>\n",
              "      <td>0.665701</td>\n",
              "      <td>0.678941</td>\n",
              "      <td>0.689788</td>\n",
              "      <td>0.695541</td>\n",
              "      <td>0.695541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.727229</td>\n",
              "      <td>0.687880</td>\n",
              "      <td>0.670692</td>\n",
              "      <td>0.660795</td>\n",
              "      <td>0.637017</td>\n",
              "      <td>0.488887</td>\n",
              "      <td>0.376375</td>\n",
              "      <td>0.524831</td>\n",
              "      <td>0.570277</td>\n",
              "      <td>0.573198</td>\n",
              "      <td>0.569857</td>\n",
              "      <td>0.559231</td>\n",
              "      <td>0.526318</td>\n",
              "      <td>0.497592</td>\n",
              "      <td>0.488839</td>\n",
              "      <td>0.480199</td>\n",
              "      <td>0.466926</td>\n",
              "      <td>0.460341</td>\n",
              "      <td>0.462675</td>\n",
              "      <td>0.482001</td>\n",
              "      <td>0.501951</td>\n",
              "      <td>0.507048</td>\n",
              "      <td>0.482857</td>\n",
              "      <td>0.457522</td>\n",
              "      <td>0.457101</td>\n",
              "      <td>0.434442</td>\n",
              "      <td>0.400832</td>\n",
              "      <td>0.386404</td>\n",
              "      <td>0.703582</td>\n",
              "      <td>0.673856</td>\n",
              "      <td>0.663522</td>\n",
              "      <td>0.656166</td>\n",
              "      <td>0.624028</td>\n",
              "      <td>0.423041</td>\n",
              "      <td>0.411778</td>\n",
              "      <td>0.572507</td>\n",
              "      <td>0.590737</td>\n",
              "      <td>0.585116</td>\n",
              "      <td>0.590082</td>\n",
              "      <td>0.589829</td>\n",
              "      <td>...</td>\n",
              "      <td>0.355051</td>\n",
              "      <td>0.364760</td>\n",
              "      <td>0.389176</td>\n",
              "      <td>0.414246</td>\n",
              "      <td>0.450312</td>\n",
              "      <td>0.490831</td>\n",
              "      <td>0.500149</td>\n",
              "      <td>0.477737</td>\n",
              "      <td>0.457269</td>\n",
              "      <td>0.461118</td>\n",
              "      <td>0.471348</td>\n",
              "      <td>0.477327</td>\n",
              "      <td>0.235094</td>\n",
              "      <td>0.113944</td>\n",
              "      <td>0.085397</td>\n",
              "      <td>0.250834</td>\n",
              "      <td>0.461685</td>\n",
              "      <td>0.494516</td>\n",
              "      <td>0.481737</td>\n",
              "      <td>0.407362</td>\n",
              "      <td>0.306164</td>\n",
              "      <td>0.288932</td>\n",
              "      <td>0.292907</td>\n",
              "      <td>0.321772</td>\n",
              "      <td>0.342878</td>\n",
              "      <td>0.353627</td>\n",
              "      <td>0.357084</td>\n",
              "      <td>0.353334</td>\n",
              "      <td>0.349745</td>\n",
              "      <td>0.355269</td>\n",
              "      <td>0.387140</td>\n",
              "      <td>0.412857</td>\n",
              "      <td>0.432040</td>\n",
              "      <td>0.455037</td>\n",
              "      <td>0.459986</td>\n",
              "      <td>0.447637</td>\n",
              "      <td>0.435232</td>\n",
              "      <td>0.442874</td>\n",
              "      <td>0.449708</td>\n",
              "      <td>0.449618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.346747</td>\n",
              "      <td>0.328336</td>\n",
              "      <td>0.316983</td>\n",
              "      <td>0.292060</td>\n",
              "      <td>0.260045</td>\n",
              "      <td>0.259185</td>\n",
              "      <td>0.274774</td>\n",
              "      <td>0.319253</td>\n",
              "      <td>0.352122</td>\n",
              "      <td>0.368492</td>\n",
              "      <td>0.383739</td>\n",
              "      <td>0.388587</td>\n",
              "      <td>0.382272</td>\n",
              "      <td>0.380055</td>\n",
              "      <td>0.370397</td>\n",
              "      <td>0.372779</td>\n",
              "      <td>0.454790</td>\n",
              "      <td>0.557607</td>\n",
              "      <td>0.577452</td>\n",
              "      <td>0.617980</td>\n",
              "      <td>0.710386</td>\n",
              "      <td>0.793994</td>\n",
              "      <td>0.844264</td>\n",
              "      <td>0.834000</td>\n",
              "      <td>0.772092</td>\n",
              "      <td>0.731631</td>\n",
              "      <td>0.699343</td>\n",
              "      <td>0.656586</td>\n",
              "      <td>0.301617</td>\n",
              "      <td>0.311780</td>\n",
              "      <td>0.316563</td>\n",
              "      <td>0.307221</td>\n",
              "      <td>0.282560</td>\n",
              "      <td>0.275510</td>\n",
              "      <td>0.292306</td>\n",
              "      <td>0.329139</td>\n",
              "      <td>0.349825</td>\n",
              "      <td>0.360148</td>\n",
              "      <td>0.380456</td>\n",
              "      <td>0.396704</td>\n",
              "      <td>...</td>\n",
              "      <td>0.476276</td>\n",
              "      <td>0.534314</td>\n",
              "      <td>0.574553</td>\n",
              "      <td>0.597715</td>\n",
              "      <td>0.617800</td>\n",
              "      <td>0.605077</td>\n",
              "      <td>0.607609</td>\n",
              "      <td>0.612715</td>\n",
              "      <td>0.591327</td>\n",
              "      <td>0.570459</td>\n",
              "      <td>0.557535</td>\n",
              "      <td>0.567326</td>\n",
              "      <td>0.667555</td>\n",
              "      <td>0.345705</td>\n",
              "      <td>0.353206</td>\n",
              "      <td>0.409876</td>\n",
              "      <td>0.440420</td>\n",
              "      <td>0.452865</td>\n",
              "      <td>0.455447</td>\n",
              "      <td>0.443904</td>\n",
              "      <td>0.421134</td>\n",
              "      <td>0.419620</td>\n",
              "      <td>0.416170</td>\n",
              "      <td>0.404058</td>\n",
              "      <td>0.369182</td>\n",
              "      <td>0.353626</td>\n",
              "      <td>0.338508</td>\n",
              "      <td>0.334283</td>\n",
              "      <td>0.375410</td>\n",
              "      <td>0.450229</td>\n",
              "      <td>0.517118</td>\n",
              "      <td>0.550337</td>\n",
              "      <td>0.558875</td>\n",
              "      <td>0.557515</td>\n",
              "      <td>0.557534</td>\n",
              "      <td>0.575872</td>\n",
              "      <td>0.584820</td>\n",
              "      <td>0.581976</td>\n",
              "      <td>0.592841</td>\n",
              "      <td>0.591267</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2    ...       781       782       783\n",
              "0  0.000000  0.000000  0.003151  ...  0.686423  0.686308  0.687691\n",
              "1  0.593498  0.595789  0.604417  ...  0.493535  0.517529  0.543134\n",
              "2  0.587986  0.427366  0.589358  ...  0.689788  0.695541  0.695541\n",
              "3  0.727229  0.687880  0.670692  ...  0.442874  0.449708  0.449618\n",
              "4  0.346747  0.328336  0.316983  ...  0.581976  0.592841  0.591267\n",
              "\n",
              "[5 rows x 784 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aobZmEXHAxIP",
        "outputId": "df181b57-b2c2-45b8-a49f-08b6081ff3a9"
      },
      "source": [
        "\n",
        "#X =np.array(df.copy())/255.0 \n",
        "X =np.array(df.copy())\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42)\n",
        "\n",
        "model = MLPClassifier(hidden_layer_sizes=(200,10), activation='tanh', \n",
        "                      solver='adam',random_state=1, max_iter=300).fit(X_train,y_train)\n",
        "  \n",
        "prediction = model.predict(X_test)\n",
        "  \n",
        "y =np.copy(y_test)\n",
        "data = {'y_true': y_test,'y_predict': prediction}  # este dado esta no formato de dicionario\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_true','y_predict'])\n",
        "\n",
        "\n",
        "confusion_matrix = pd.crosstab(df['y_true'], df['y_predict'], rownames=['Actual'], colnames=['Predict'])\n",
        "print(confusion_matrix)\n",
        "\n",
        "y_true = df['y_true']\n",
        "y_pred = df['y_predict']\n",
        "\n",
        "  \n",
        "METRICS=sklearn.metrics.classification_report(y_true, y_pred)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predict    1   2   3   4\n",
            "Actual                  \n",
            "1        104   0   1   1\n",
            "2          0  51   0   0\n",
            "3         21  11  19  12\n",
            "4         21   2   6  16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCe9ihVdBlNS",
        "outputId": "8ed27cc6-fbb9-4bb1-9040-67d72c189d8f"
      },
      "source": [
        "#X =np.array(df.copy())/255.0 \n",
        "df = df_r1.copy()\n",
        "y = y_r1.copy()\n",
        "X =np.array(df.copy())\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42)\n",
        "\n",
        "model = MLPClassifier(hidden_layer_sizes=(200,10), activation='tanh', \n",
        "                      solver='adam',random_state=1, max_iter=300).fit(X_train,y_train)\n",
        "  \n",
        "prediction = model.predict(X_test)\n",
        "  \n",
        "y =np.copy(y_test)\n",
        "data = {'y_true': y_test,'y_predict': prediction}  # este dado esta no formato de dicionario\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_true','y_predict'])\n",
        "\n",
        "\n",
        "confusion_matrix = pd.crosstab(df['y_true'], df['y_predict'], rownames=['Actual'], colnames=['Predict'])\n",
        "print('rede 1 G e B --> r1') \n",
        "print(confusion_matrix)\n",
        "\n",
        "y_true = df['y_true']\n",
        "y_pred = df['y_predict']\n",
        "\n",
        "  \n",
        "METRICS=sklearn.metrics.classification_report(y_true, y_pred)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rede 1 G e B --> r1\n",
            "Predict    1   2\n",
            "Actual          \n",
            "1        105   1\n",
            "2          1  55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GO6fwLGIB1eR",
        "outputId": "42b8ab0b-4478-444b-d0e0-6c5a6746d47b"
      },
      "source": [
        "\n",
        "#X =np.array(df.copy())/255.0 \n",
        "df = df_r2.copy()\n",
        "y = y_r2.copy()\n",
        "X =np.array(df.copy())\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42)\n",
        "\n",
        "model = MLPClassifier(hidden_layer_sizes=(200,10), activation='tanh', \n",
        "                      solver='adam',random_state=1, max_iter=300).fit(X_train,y_train)\n",
        "  \n",
        "prediction = model.predict(X_test)\n",
        "  \n",
        "y =np.copy(y_test)\n",
        "data = {'y_true': y_test,'y_predict': prediction}  # este dado esta no formato de dicionario\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_true','y_predict'])\n",
        "\n",
        "\n",
        "confusion_matrix = pd.crosstab(df['y_true'], df['y_predict'], rownames=['Actual'], colnames=['Predict'])\n",
        "print(' rede 2 G e I --> r2')\n",
        "print(confusion_matrix)\n",
        "\n",
        "y_true = df['y_true']\n",
        "y_pred = df['y_predict']\n",
        "\n",
        "  \n",
        "METRICS=sklearn.metrics.classification_report(y_true, y_pred)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " rede 2 G e I --> r2\n",
            "Predict   1   3\n",
            "Actual         \n",
            "1        94  12\n",
            "3         3  53\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yE-qa5pVB5Dl",
        "outputId": "06059344-0dca-4f2d-a900-4b14afc58d7f"
      },
      "source": [
        "\n",
        "#X =np.array(df.copy())/255.0 \n",
        "df = df_r3.copy()\n",
        "y = y_r3.copy()\n",
        "X =np.array(df.copy())\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42)\n",
        "\n",
        "model = MLPClassifier(hidden_layer_sizes=(200,10), activation='tanh', \n",
        "                      solver='adam',random_state=1, max_iter=300).fit(X_train,y_train)\n",
        "  \n",
        "prediction = model.predict(X_test)\n",
        "  \n",
        "y =np.copy(y_test)\n",
        "data = {'y_true': y_test,'y_predict': prediction}  # este dado esta no formato de dicionario\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_true','y_predict'])\n",
        "\n",
        "\n",
        "confusion_matrix = pd.crosstab(df['y_true'], df['y_predict'], rownames=['Actual'], colnames=['Predict'])\n",
        "print('rede 3 G e V --> r3')\n",
        "print(confusion_matrix)\n",
        "\n",
        "y_true = df['y_true']\n",
        "y_pred = df['y_predict']\n",
        "\n",
        "  \n",
        "METRICS=sklearn.metrics.classification_report(y_true, y_pred)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rede 3 G e V --> r3\n",
            "Predict   1   4\n",
            "Actual         \n",
            "1        98  12\n",
            "4        10  37\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-WgUqQhHeQp"
      },
      "source": [
        "# joblib.dump(model,'model_ANN_new.pkl')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jjpqjbw3_jQc",
        "outputId": "f0f28e9d-5cf4-418d-c536-5053e9ad3a3c"
      },
      "source": [
        "'''\n",
        "Arq = 'model_ANN_new.pkl'\n",
        "from google.colab import files\n",
        "files.download(Arq)\n",
        "'''"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nArq = 'model_ANN_new.pkl'\\nfrom google.colab import files\\nfiles.download(Arq)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKgBk8efNkQP"
      },
      "source": [
        "w = df_all['Type']\n",
        "y = []\n",
        "for wi in w:\n",
        "  if(wi == 'G'):\n",
        "    y.append(1)\n",
        "  elif(wi == 'B'):\n",
        "    y.append(2)\n",
        "  elif(wi == 'I'):\n",
        "    y.append(2)\n",
        "  elif(wi == 'V'):\n",
        "    y.append(2)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrTH3pNpORyZ"
      },
      "source": [
        "df_all.drop(['Unnamed: 0','Type'], axis='columns', inplace=True)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqNPfdzqNjH8",
        "outputId": "02a42e29-74a1-4745-9744-fed591eda232"
      },
      "source": [
        "\n",
        "#X =np.array(df.copy())/255.0 \n",
        "X =np.array(df_all.copy())\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42)\n",
        "\n",
        "model = MLPClassifier(hidden_layer_sizes=(200,10), activation='tanh', \n",
        "                      solver='adam',random_state=1, max_iter=300).fit(X_train,y_train)\n",
        "  \n",
        "prediction = model.predict(X_test)\n",
        "  \n",
        "y =np.copy(y_test)\n",
        "data = {'y_true': y_test,'y_predict': prediction}  # este dado esta no formato de dicionario\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_true','y_predict'])\n",
        "\n",
        "\n",
        "confusion_matrix = pd.crosstab(df['y_true'], df['y_predict'], rownames=['Actual'], colnames=['Predict'])\n",
        "print(confusion_matrix)\n",
        "\n",
        "y_true = df['y_true']\n",
        "y_pred = df['y_predict']\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predict   1    2\n",
            "Actual          \n",
            "1        98    8\n",
            "2        23  136\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8jiK2YCN1ja"
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    }
  ]
}