{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_classify_grain_feb_15_2021.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMUdjgn0RxgypPtDy0joyvo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ucfilho/marquesgabi_paper_fev_2021/blob/main/CNN_classify_grain_feb_15_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lslEyClmxM-Y"
      },
      "source": [
        "import pandas as pd\r\n",
        "import zipfile\r\n",
        "import numpy as np\r\n",
        "from PIL import Image\r\n",
        "import cv2\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Llk5HqgorBap"
      },
      "source": [
        "# https://www.kaggle.com/ppsheth91/92-5-accuracy-with-keras-tuner-fashionmnist-cnn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDlJAW1kn81K",
        "outputId": "fad523f6-cf0b-4650-87cd-897bb13dfcd6"
      },
      "source": [
        "!pip install visualkeras"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: visualkeras in /usr/local/lib/python3.6/dist-packages (0.0.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from visualkeras) (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0vRzrUZnZ3W"
      },
      "source": [
        "import os\r\n",
        "import seaborn as sns\r\n",
        "import tensorflow as tf\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras import layers\r\n",
        "import keras\r\n",
        "from keras.layers.core import Dense,Activation,Dropout\r\n",
        "from tensorflow.keras.utils import to_categorical\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense,Flatten,Dropout,Conv2D,MaxPooling2D, BatchNormalization\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "from keras.callbacks import EarlyStopping, Callback\r\n",
        "from keras.optimizers import Adam\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "import visualkeras\r\n",
        "from keras.utils import plot_model\r\n",
        "import math\r\n",
        "from keras.optimizers import RMSprop\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqabNK2Bxtm1",
        "outputId": "79af5a6c-7eee-4435-9600-3932f420042e"
      },
      "source": [
        "!git clone https://github.com/marquesgabi/Doutorado\r\n",
        "%cd Doutorado\r\n",
        "Transfere='FotosTreino882_and_Segm.zip'\r\n",
        "file_name = zipfile.ZipFile(Transfere, 'r')\r\n",
        "file_name.extractall()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Doutorado' already exists and is not an empty directory.\n",
            "/content/Doutorado\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWoojYEqjqdX"
      },
      "source": [
        "# y_pred,confusion_matrix,METRICS=AnnGrain(ANN_dat,df.drop('Width',axis=1))\r\n",
        "# def AnnGrain(df,df_class):\r\n",
        "def AnnGrain(df):\r\n",
        "  y_valor=df['Type']\r\n",
        "\r\n",
        "  quantidade= df.groupby('Type').size()\r\n",
        "\r\n",
        "  df_G = df[df[\"Type\"] == \"G\"] \r\n",
        "  Cut=['Unnamed: 0','Type','Width']\r\n",
        "  FotosG= df_G.drop(Cut,axis=1)\r\n",
        "\r\n",
        "\r\n",
        "  Size=28\r\n",
        "  img_G=[]\r\n",
        "\r\n",
        "  Num,cols=FotosG.shape\r\n",
        "  for i in range(Num):\r\n",
        "    data=np.array(FotosG.iloc[i]).reshape(Size,Size)\r\n",
        "    img = Image.fromarray(data.astype('uint8'), mode='L')\r\n",
        "    img=np.float32(img)\r\n",
        "    img28=cv2.resize(img,(Size,Size), interpolation = cv2.INTER_AREA)\r\n",
        "    img_G.append(img28)\r\n",
        "\r\n",
        "  df_Z = df[df[\"Type\"] == \"Z\"] \r\n",
        "  Cut=['Unnamed: 0','Type','Width']\r\n",
        "  FotosZ= df_Z.drop(Cut,axis=1)\r\n",
        "\r\n",
        "  # We'll choose which is grain and withdraw from 750 segmented photos\r\n",
        "\r\n",
        "  Size=28\r\n",
        "  img_Z=[]\r\n",
        "\r\n",
        "  Num,cols=FotosZ.shape\r\n",
        "  for i in range(Num):\r\n",
        "    data=np.array(FotosZ.iloc[i]).reshape(Size,Size)\r\n",
        "    img = Image.fromarray(data.astype('uint8'), mode='L')\r\n",
        "    img=np.float32(img)\r\n",
        "    img28=cv2.resize(img,(Size,Size), interpolation = cv2.INTER_AREA)\r\n",
        "    img_Z.append(img28)\r\n",
        "\r\n",
        "  GRAO=[0,146,149,166,217,222,223,257,268,286,455,482,538,612,644,647,651,677] # 0 ate 749\r\n",
        "  GRAO=np.array(GRAO)\r\n",
        "  Ind=FotosZ.index\r\n",
        "  FotosNG=FotosZ.copy()\r\n",
        "  for i in GRAO:\r\n",
        "    FotosNG=FotosNG.drop(Ind[i])\r\n",
        "\r\n",
        "  PERCENT=245.0/(len(FotosNG.index))\r\n",
        "  FotosNG=FotosNG.sample(frac=PERCENT, replace=True)\r\n",
        "\r\n",
        "  rows,col=FotosG.shape\r\n",
        "  y_total=[] # grao-->zero, nao grao-->1\r\n",
        "  for i in range(rows):\r\n",
        "    y_total.append(0) #  # grao-->zero\r\n",
        "  for i in range(rows,(2*rows)):\r\n",
        "    y_total.append(1) #  # nao grao-->zero\r\n",
        "\r\n",
        "  frames = [FotosG,FotosNG]\r\n",
        "  result = pd.concat(frames)\r\n",
        "\r\n",
        "  #Define data train and data test\r\n",
        "\r\n",
        "  W_train, W_test, yw_train, yw_test = train_test_split(np.array(result), np.array(y_total), \r\n",
        "                                                      test_size=0.30, shuffle=True, \r\n",
        "                                                      random_state=42)\r\n",
        "\r\n",
        "  train_images=W_train #imagens utilizadas para o treino\r\n",
        "  train_labels=yw_train # resposta esperada para o treino\r\n",
        "  test_images=W_test\r\n",
        "  test_labels=yw_test\r\n",
        "\r\n",
        "  return W_train, W_test, yw_train, yw_test"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSFHhE3YzP0b",
        "outputId": "acf966a8-e33a-4f42-ff20-f0dab0375b6a"
      },
      "source": [
        "!git clone https://github.com/marquesgabi/Doutorado\r\n",
        "%cd Doutorado\r\n",
        "Transfere='FotosTreino882_and_Segm.zip'\r\n",
        "file_name = zipfile.ZipFile(Transfere, 'r')\r\n",
        "file_name.extractall()\r\n",
        "\r\n",
        "\"\"\"# First step: get the segmented file (photos stored in csv file)\"\"\"\r\n",
        "\r\n",
        "labels = [] #name files\r\n",
        "\r\n",
        "with zipfile.ZipFile(Transfere, \"r\") as f:\r\n",
        "  for f in f.namelist():\r\n",
        "    labels.append(f)\r\n",
        "\r\n",
        "Num=len(labels)\r\n",
        "ANN_dat=pd.read_csv(labels[0])\r\n",
        "for i in range(1,Num):\r\n",
        "  df_new=pd.read_csv(labels[i])\r\n",
        "  df_new = df_new[~df_new['Type'].isin(['G'])] # drop grain row which is not in 882\r\n",
        "  frames = [ANN_dat, df_new]\r\n",
        "  ANN_dat= pd.concat(frames, ignore_index=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Doutorado' already exists and is not an empty directory.\n",
            "/content/Doutorado/Doutorado\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhostkU2y0IR"
      },
      "source": [
        "#W_train, W_test, yw_train, yw_test =AnnGrain(ANN_dat)\r\n",
        "X_train,X_val, Y_train, Y_val =AnnGrain(ANN_dat)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "287u8aVqxYYC"
      },
      "source": [
        "# Building the basic CNN Model without tuning any hyper parameters #\r\n",
        "\r\n",
        "model = tf.keras.Sequential()\r\n",
        "\r\n",
        "# First layer, which has a 2D Convolutional layer with kernel size as 3*3, Relu activation & Max pooling operation \r\n",
        "model.add(Conv2D(32, (3,3), padding='same', input_shape=(28,28,1),activation=tf.nn.relu))\r\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\r\n",
        "\r\n",
        "# Second layer, which has a 2D Convolutional layer with kernel size as 3*3, ReLU activation and Max pooling operation \r\n",
        "model.add(Conv2D(64, (3,3), padding='same', activation=tf.nn.relu))\r\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\r\n",
        "\r\n",
        "# Fully connected layer with ReLU activation function \r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(128, activation=tf.nn.relu))\r\n",
        "# Output layer with softmax activation function\r\n",
        "model.add(Dense(1, activation=tf.nn.softmax))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvFcCOSqo7OX",
        "outputId": "963700ca-81b1-4b51-e84b-257a355fc683"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               401536    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 420,481\n",
            "Trainable params: 420,481\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "pf2K8uWUpDV1",
        "outputId": "908c8d4e-5e4f-45f7-fd81-fd2de73b0737"
      },
      "source": [
        "visualkeras.layered_view(model)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGBA size=536x150 at 0x7FA3A3E37048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npm-HXcUpTP6"
      },
      "source": [
        "# Optimizer specified here is adam, loss is categorical crossentrophy and metric is accuracy\r\n",
        "model.compile(optimizer='adam',\r\n",
        "              loss=tf.keras.losses.categorical_crossentropy,\r\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "id": "ClpCJNNsqaGY",
        "outputId": "fe47447b-d16c-4892-ddba-7e286166e048"
      },
      "source": [
        "train_data = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\r\n",
        "valid_data = tf.data.Dataset.from_tensor_slices((X_val, Y_val))\r\n",
        "\r\n",
        "model.fit(train_data, epochs=128, validation_data=valid_data)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/128\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-a5f5cdc93f0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvalid_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:239 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (784, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uwqde2EpZ2i"
      },
      "source": [
        "'''\r\n",
        "train_model = model.fit(X_train, Y_train,\r\n",
        "                  batch_size=128,\r\n",
        "                  epochs=50,\r\n",
        "                  verbose=1,\r\n",
        "                  validation_data=(X_val, Y_val))\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}